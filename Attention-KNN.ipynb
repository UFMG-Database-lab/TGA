{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from TGA.utils import Dataset\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from TGA.utils import preprocessor\n",
    "import copy\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "from itertools import repeat\n",
    "from collections import Counter\n",
    "from segtok import tokenizer as tk\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as stop_words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('X_train', 'y_train', 'X_test', 'y_test', 'X_val', 'y_val'), 19907)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset('/home/datasets/acm/')\n",
    "fold = next(dataset.get_fold_instances(10, with_val=True))\n",
    "fold._fields, len(fold.X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, mindf=2, stopwords='remove', model='list', lan='english', k=25, verbose=False):\n",
    "        super(Tokenizer, self).__init__()\n",
    "        self.mindf = mindf\n",
    "        self.le = LabelEncoder()\n",
    "        self.verbose = verbose\n",
    "        self.stopwords = stopwords\n",
    "        self.stopwordsSet = stop_words\n",
    "        self.lan = lan\n",
    "        self.k = k\n",
    "        self.model = model\n",
    "        self.analyzer = TfidfVectorizer(preprocessor=preprocessor)#.build_analyzer()\n",
    "        #self.analyzer = tk.web_tokenizer\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.N = len(X)\n",
    "        y = self.le.fit_transform( y )\n",
    "        self.n_class = len(self.le.classes_)\n",
    "        \n",
    "\n",
    "        self.term_freqs = Counter()\n",
    "        local_analyzer  = self.analyzer.build_analyzer()\n",
    "        docs = map(local_analyzer, X)\n",
    "        for doc_in_terms in tqdm(docs, total=self.N, disable=not self.verbose):\n",
    "            doc_in_terms = list(map( self._filter_fit_, doc_in_terms ))\n",
    "            self.term_freqs.update(list(set(doc_in_terms)))\n",
    "        self.node_mapper      = {'<BLANK>': 0}\n",
    "        self.term_freqs       = { term:v for (term,v) in self.term_freqs.items() if v >= self.mindf }    \n",
    "        self.node_mapper      = { term:self._get_idx_(term) for term in self.term_freqs.keys() if self._isrel_(term) }\n",
    "        self.node_mapper['<UNK>'] = len(self.node_mapper)\n",
    "        self.node_mapper['<BLANK>'] = 0\n",
    "        self.vocab_size = len(self.node_mapper)\n",
    "        \n",
    "        if self.model == 'topk' or self.model == 'sample':\n",
    "            from multiprocessing import cpu_count\n",
    "            from sklearn.ensemble import RandomForestClassifier\n",
    "            \n",
    "            self.rf = RandomForestClassifier(n_jobs=cpu_count(), verbose=self.verbose>0)\n",
    "            self.rf.fit(self.analyzer.fit_transform(X), y)\n",
    "            imps = tokenizer.rf.feature_importances_\n",
    "            self.fi_ = { term: imps[idterm] for (term, idterm) in tokenizer.analyzer.vocabulary_.items() }\n",
    "            self.fi_['<BLANK>'] = 0.\n",
    "            self.fi_['<UNK>'] = 0.\n",
    "            \n",
    "        return self\n",
    "    def _isrel_(self, term):\n",
    "        if self.stopwords == 'remove' and term in self.stopwordsSet:\n",
    "            return False\n",
    "        # put here your filter_functions\n",
    "        return True\n",
    "    def _get_idx_(self, term):\n",
    "        # put here your idx_set_functions\n",
    "        if self.stopwords == 'mark' and term in self.stopwordsSet:\n",
    "            return self.node_mapper.setdefault('<STPW>', len(self.node_mapper))\n",
    "        return self.node_mapper.setdefault(term, len(self.node_mapper))\n",
    "    def _filter_transform_(self, term):\n",
    "        if self.stopwords == 'mark' and term in self.stopwordsSet:\n",
    "            return '<STPW>'\n",
    "        if term not in self.node_mapper:\n",
    "            return '<UNK>'\n",
    "        return term\n",
    "    def _filter_fit_(self, term):\n",
    "        if self.stopwords == 'mark' and term in self.stopwordsSet:\n",
    "            return '<STPW>'\n",
    "        return term\n",
    "    def _model_(self, doc):\n",
    "        if self.model == 'set':\n",
    "            return set(doc)\n",
    "        if self.model == 'topk':\n",
    "            doc = np.array(list(set(doc)))\n",
    "            weigths = np.array([ self.fi_[t] for t in doc ])\n",
    "            doc = doc[(-weigths).argsort()[:self.k]]\n",
    "            return doc\n",
    "        if self.model == 'sample':\n",
    "            doc = np.array(list(set(doc)))\n",
    "            if len(doc) > self.k:\n",
    "                weigths = np.array([ self.fi_[t] for t in doc ])\n",
    "                weigths = softmax(weigths)\n",
    "                doc = np.random.choice(doc, size=self.k, replace=False, p=weigths)\n",
    "            return doc\n",
    "        return list(doc)\n",
    "    def transform(self, X, verbose=None):\n",
    "        verbose = verbose if verbose is not None else self.verbose\n",
    "        n = len(X)\n",
    "        doc_off = [0]\n",
    "        terms_idx = []\n",
    "        local_analyzer  = self.analyzer.build_analyzer()\n",
    "        for i,doc_in_terms in tqdm(enumerate(map(local_analyzer, X)), total=n, disable=not verbose):\n",
    "            doc_in_terms = filter( self._isrel_, doc_in_terms )\n",
    "            doc_in_terms = map( self._filter_transform_, doc_in_terms )\n",
    "            doc_in_terms = self._model_(doc_in_terms)\n",
    "            doc_in_terms = [ self.node_mapper[tid] for tid in doc_in_terms ]\n",
    "            if self.model == 'sorted':\n",
    "                doc_in_terms = sorted(doc_in_terms)\n",
    "            doc_off.append( len(doc_in_terms) )\n",
    "            terms_idx.extend( doc_in_terms )\n",
    "        return np.array( terms_idx ), np.array(doc_off)[:-1].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c798a234f4c24d0f9437221184eccd3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19907 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=12)]: Using backend ThreadingBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=12)]: Done 100 out of 100 | elapsed:    9.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tokenizer(k=128, mindf=1, model='sample', stopwords='keep', verbose=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(mindf=1, stopwords='keep', model='sample', k=128, verbose=True)\n",
    "tokenizer.fit(fold.X_train, fold.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_in_terms = tokenizer.analyzer.build_analyzer()(fold.X_val[0])\n",
    "doc_in_terms = filter( tokenizer._isrel_, doc_in_terms )\n",
    "doc_in_terms = map( tokenizer._filter_transform_, doc_in_terms )\n",
    "#doc_in_terms = tokenizer._model_(doc_in_terms)\n",
    "\n",
    "doc = np.array(list(set(doc_in_terms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tokenizer.le.transform( fold.y_train )\n",
    "y_val   = tokenizer.le.transform( fold.y_val )\n",
    "y_test  = tokenizer.le.transform( fold.y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " 'how do computer science lecturers create modules? (poster) john traxler  \\n')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.node_mapper['<BLANK>'], fold.X_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_train(param):\n",
    "    X, y = zip(*param)\n",
    "    terms_ids, docs_offsets = tokenizer.transform(X, verbose=False)\n",
    "    return torch.LongTensor(terms_ids), torch.LongTensor(docs_offsets), torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mask(nn.Module):\n",
    "    def __init__(self, negative_slope=1000, kappa=2.):\n",
    "        super(Mask, self).__init__()\n",
    "        self.negative_slope = negative_slope\n",
    "        self.kappa = kappa\n",
    "        self.sig = nn.Sigmoid()\n",
    "    def forward(self, h):\n",
    "        w = F.leaky_relu( h, negative_slope=self.negative_slope)\n",
    "        w = self.sig(w-self.kappa)\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function embedding_bag:\n",
      "\n",
      "embedding_bag(...)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.embedding_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAttentionBag(nn.Module):\n",
    "    def __init__(self, vocab_size, hiddens, nclass, drop=.5, initrange=.5, negative_slope=99.):\n",
    "        super(SimpleAttentionBag, self).__init__()\n",
    "        self.hiddens        = hiddens\n",
    "        self.dt_emb         = nn.Embedding(vocab_size, hiddens)\n",
    "        self.tt_source_map  = nn.Linear(hiddens, hiddens)\n",
    "        self.tt_target_map  = nn.Linear(hiddens, hiddens)\n",
    "        self.fc             = nn.Linear(hiddens, nclass)\n",
    "        self.initrange      = initrange \n",
    "        self.negative_slope = negative_slope\n",
    "        self.drop           = nn.Dropout(drop)\n",
    "        self.drop_          = drop\n",
    "        self.sig            = nn.Sigmoid()\n",
    "        self.init_weights()\n",
    "    def forward(self, terms_idx, docs_offsets, return_mask=False):\n",
    "        n = terms_idx.shape[0]\n",
    "        batch_size = docs_offsets.shape[0]\n",
    "        \n",
    "        k         = [ terms_idx[ docs_offsets[i-1]:docs_offsets[i] ] for i in range(1, batch_size) ]\n",
    "        k.append( terms_idx[ docs_offsets[-1]: ] )\n",
    "        x_packed  = pad_sequence(k, batch_first=True, padding_value=0)\n",
    "\n",
    "        bx_packed = x_packed == 0\n",
    "        doc_sizes = bx_packed.logical_not().sum(dim=1).view(batch_size, 1)\n",
    "        pad_mask  = bx_packed.logical_not()\n",
    "        pad_mask  = pad_mask.view(*bx_packed.shape, 1)\n",
    "        pad_mask  = pad_mask.logical_and(pad_mask.transpose(1, 2))\n",
    "        \n",
    "        dt_h     = self.dt_emb( x_packed )\n",
    "        dt_h     = F.dropout( dt_h, p=self.drop_, training=self.training )\n",
    "        \n",
    "        source_h = self.tt_source_map( dt_h )\n",
    "        source_h = F.tanh(source_h)\n",
    "        #source_h = F.leaky_relu(source_h, negative_slope=self.negative_slope)\n",
    "        source_h = F.dropout( source_h, p=self.drop_, training=self.training )\n",
    "        \n",
    "        target_h = self.tt_target_map( dt_h )\n",
    "        target_h = F.tanh(target_h)\n",
    "        #target_h = F.leaky_relu(target_h, negative_slope=self.negative_slope)\n",
    "        target_h = F.dropout( target_h, p=self.drop_, training=self.training )\n",
    "\n",
    "        co_weights = torch.bmm( source_h, target_h.transpose( 1, 2 ) )\n",
    "        co_weights = F.leaky_relu( co_weights, negative_slope=self.negative_slope)\n",
    "        \n",
    "        co_weights[pad_mask.logical_not()] = float('-inf') # Set the 3D-pad mask values to -inf (=0 in sigmoid)\n",
    "        co_weights = F.sigmoid(co_weights)\n",
    "        #co_weights = torch.where(torch.isnan(co_weights), torch.zeros_like(co_weights), co_weights) #replace nan to zero\n",
    "        \n",
    "        weights = co_weights.sum(axis=2) / doc_sizes\n",
    "        weights[bx_packed] = float('-inf') # Set the 2D-pad mask values to -inf  (=0 in softmax)\n",
    "        weights = F.softmax(weights, dim=1)\n",
    "        weights = torch.where(torch.isnan(weights), torch.zeros_like(weights), weights)\n",
    "        weights = weights.view( *weights.shape, 1 )\n",
    "        \n",
    "        docs_h = dt_h * weights\n",
    "        docs_h = docs_h.sum(axis=1)\n",
    "        docs_h = F.dropout( docs_h, p=self.drop_, training=self.training )\n",
    "        return self.fc(docs_h), weights, co_weights\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.dt_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        #self.tt_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.tt_source_map.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.tt_target_map.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.fc.weight.data.uniform_(-self.initrange, self.initrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs = 1000\n",
    "max_epochs = 20\n",
    "drop=0.3\n",
    "device = torch.device('cuda:0')\n",
    "batch_size = 64\n",
    "k = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f879c14c3b0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc = SimpleClassifier(tokenizer.vocab_size, 300, tokenizer.n_class, dropout=drop).to( device )\n",
    "ab = SimpleAttentionBag(tokenizer.vocab_size, 300, tokenizer.n_class, drop=drop).to( device )\n",
    "tokenizer.k = k\n",
    "optimizer = optim.AdamW( ab.parameters(), lr=6e-3, weight_decay=5e-3)\n",
    "loss_func_cel = nn.CrossEntropyLoss().to( device )\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=.95,\n",
    "                                                       patience=10, verbose=True)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=.98, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38d201a0107442794b3edf3004b1729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939b8d5fbed6424c878f79ec9f27f8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.9769/1.9188 ACC: 0.61792                                                                                                     \n",
      "drop: 0.23594\n",
      "Val loss: 1.832 ACC: 0.73106                                                                                                     \n",
      "New Best Val loss: 1.832                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92dd0816aef943a686df940db3b1d87a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.754/1.5847 ACC: 0.81072                                                                                                     \n",
      "drop: 0.53286\n",
      "Val loss: 1.8024 ACC: 0.75311                                                                                                    \n",
      "New Best Val loss: 1.8024                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b727bc134dd46c1ab9a552e1bd9f00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.7212/1.6644 ACC: 0.8383                                                                                                     \n",
      "drop: 0.58911\n",
      "Val loss: 1.7933 ACC: 0.75631                                                                                                    \n",
      "New Best Val loss: 1.7933                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf05782e80143b38ab204911e7dba91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.705/1.5451 ACC: 0.84945                                                                                                     \n",
      "drop: 0.61293\n",
      "Val loss: 1.7853 ACC: 0.76954                                                                                                    \n",
      "New Best Val loss: 1.7853                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a952a96a12d644749049bf9f89c4f77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.695/1.8232 ACC: 0.8602                                                                                                      \n",
      "drop: 0.6365\n",
      "Val loss: 1.7849 ACC: 0.76473                                                                                                    \n",
      "New Best Val loss: 1.7849                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6438cfd1a8334bf0b16fde8e4fe87498",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6891/1.543 ACC: 0.86392                                                                                                     \n",
      "drop: 0.64479\n",
      "Val loss: 1.7846 ACC: 0.76353                                                                                                    \n",
      "New Best Val loss: 1.7846                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e149ea97793942df9feefa69f446ee71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6829/1.543 ACC: 0.86819                                                                                                     \n",
      "drop: 0.65439\n",
      "Val loss: 1.7862 ACC: 0.75711                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bec9ab61c8c4d8a90303e60469b001e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6807/1.7649 ACC: 0.87025                                                                                                    \n",
      "drop: 0.65906\n",
      "Val loss: 1.7811 ACC: 0.76513                                                                                                    \n",
      "New Best Val loss: 1.7811                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "821e2936c1f14f468cde1894c82172e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6777/1.5438 ACC: 0.87271                                                                                                    \n",
      "drop: 0.66467\n",
      "Val loss: 1.7861 ACC: 0.75752                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa50f7a71194ac38803934224b4f330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6715/1.5445 ACC: 0.87738                                                                                                    \n",
      "drop: 0.6754\n",
      "Val loss: 1.782 ACC: 0.76192                                                                                                     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e25da3c7b7402ab4c74c021a51f0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6723/1.8613 ACC: 0.87738                                                                                                    \n",
      "drop: 0.6754\n",
      "Val loss: 1.7831 ACC: 0.76152                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d1743f8d24147f8aa2a1cd83f2460c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6665/1.5433 ACC: 0.8814                                                                                                     \n",
      "drop: 0.68473\n",
      "Val loss: 1.7798 ACC: 0.76353                                                                                                    \n",
      "New Best Val loss: 1.7798                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d775b87cc14581961ac4bd5cb4c558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6665/1.6186 ACC: 0.88185                                                                                                    \n",
      "drop: 0.68578\n",
      "Val loss: 1.7823 ACC: 0.76393                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3804cdc3788148c6a2d50076ff6c966a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.666/1.8845 ACC: 0.8827                                                                                                      \n",
      "drop: 0.68777\n",
      "Val loss: 1.7825 ACC: 0.75912                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765763c4dd4d42089fcc8ce7433ef7ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6642/1.8758 ACC: 0.88301                                                                                                    \n",
      "drop: 0.68848\n",
      "Val loss: 1.7821 ACC: 0.76032                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c988bd1ae70e4288bca700aab18f0bf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6622/1.8644 ACC: 0.88532                                                                                                    \n",
      "drop: 0.6939\n",
      "Val loss: 1.7815 ACC: 0.76032                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf513d9a526a477ab6a4ca297a0401f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6606/1.543 ACC: 0.88692                                                                                                     \n",
      "drop: 0.69769\n",
      "Val loss: 1.7816 ACC: 0.76072                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58084714fa3a4129ac723005cb59988f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6599/1.5953 ACC: 0.88662                                                                                                    \n",
      "drop: 0.69697\n",
      "Val loss: 1.7806 ACC: 0.75952                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebbcc2e078a64b38942310bb24842d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6584/1.5498 ACC: 0.88833                                                                                                    \n",
      "drop: 0.70101\n",
      "Val loss: 1.7772 ACC: 0.76673                                                                                                    \n",
      "New Best Val loss: 1.7772                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e39e0523ec471598ffd391b5ae4593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6587/1.8856 ACC: 0.88949                                                                                                    \n",
      "drop: 0.70375\n",
      "Val loss: 1.778 ACC: 0.76393                                                                                                     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a512119b2e11423a8e373624bcf10fc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6557/1.545 ACC: 0.89089                                                                                                     \n",
      "drop: 0.70709\n",
      "Val loss: 1.7798 ACC: 0.76192                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58c94f488d88417989c206ff88662813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6564/1.5441 ACC: 0.89099                                                                                                    \n",
      "drop: 0.70733\n",
      "Val loss: 1.7788 ACC: 0.76633                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04979949f4dd406ca8fd57491bed5cf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6556/1.5568 ACC: 0.89014                                                                                                    \n",
      "drop: 0.7053\n",
      "Val loss: 1.7796 ACC: 0.76473                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3017426e4e94466b962e1f20ebe084ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6555/1.543 ACC: 0.89124                                                                                                     \n",
      "drop: 0.70793\n",
      "Val loss: 1.7789 ACC: 0.76553                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca80939b2d4440cdb53b761068ab2135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6545/1.894 ACC: 0.8923                                                                                                      \n",
      "drop: 0.71045\n",
      "Val loss: 1.7797 ACC: 0.76273                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2de2d66d7b0f45e89888300925eadfdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6529/1.543 ACC: 0.89335                                                                                                     \n",
      "drop: 0.71297\n",
      "Val loss: 1.7802 ACC: 0.76553                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9041f0dabf7943049e4e4ce8eb721de3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6518/1.5432 ACC: 0.89386                                                                                                    \n",
      "drop: 0.71417\n",
      "Val loss: 1.7809 ACC: 0.76393                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "050fabb5657340d292b27a86fe4ec362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6502/1.5451 ACC: 0.89572                                                                                                    \n",
      "drop: 0.71864\n",
      "Val loss: 1.7796 ACC: 0.76553                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cf78d46ee45466bbe57756c470c8aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6527/1.5433 ACC: 0.89406                                                                                                    \n",
      "drop: 0.71465\n",
      "Val loss: 1.7766 ACC: 0.76754                                                                                                    \n",
      "New Best Val loss: 1.7766                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353e8f25ed44451f9696e7ea880304cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6528/1.8398 ACC: 0.89381                                                                                                    \n",
      "drop: 0.71405\n",
      "Val loss: 1.7784 ACC: 0.76473                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75067cb9977e41008e6505c73582bb3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6526/1.5431 ACC: 0.8932                                                                                                     \n",
      "drop: 0.71261\n",
      "Val loss: 1.7767 ACC: 0.76513                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec00afadd484b078ae07622f9d1925e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6511/1.5431 ACC: 0.89516                                                                                                    \n",
      "drop: 0.71731\n",
      "Val loss: 1.7783 ACC: 0.76553                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ebc6601b3eb4ca9a3aa119f3b828d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6499/1.543 ACC: 0.89531                                                                                                     \n",
      "drop: 0.71767\n",
      "Val loss: 1.7776 ACC: 0.76433                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef0fa527bf84ee396c710fa2a271e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6491/1.5431 ACC: 0.89667                                                                                                    \n",
      "drop: 0.72094\n",
      "Val loss: 1.7774 ACC: 0.76473                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406c3991f2884b418926e52a34f81642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6481/1.5432 ACC: 0.89717                                                                                                    \n",
      "drop: 0.72215\n",
      "Val loss: 1.7781 ACC: 0.76393                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16791e71bcb84c69892d37c9f342774c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6501/1.5433 ACC: 0.89602                                                                                                    \n",
      "drop: 0.71936\n",
      "Val loss: 1.777 ACC: 0.76794                                                                                                     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55037bff4afa4336a3f576d5b6a6b71d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6487/1.543 ACC: 0.89662                                                                                                     \n",
      "drop: 0.72082\n",
      "Val loss: 1.7762 ACC: 0.76954                                                                                                    \n",
      "New Best Val loss: 1.7762                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06aaeda9cf304a4499f7fbf559585df1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6484/1.5432 ACC: 0.89813                                                                                                    \n",
      "drop: 0.72446\n",
      "Val loss: 1.7749 ACC: 0.76874                                                                                                    \n",
      "New Best Val loss: 1.7749                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3893e6061baa4cc8b7d49527edac04ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6468/1.7646 ACC: 0.89883                                                                                                    \n",
      "drop: 0.72616\n",
      "Val loss: 1.7779 ACC: 0.76754                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2192fc8216be4d6d8c5fd5a3930d60ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6475/1.543 ACC: 0.89677                                                                                                     \n",
      "drop: 0.72118\n",
      "Val loss: 1.7757 ACC: 0.76834                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f95191583f384a179b7d30422ab8c82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6457/1.5491 ACC: 0.89928                                                                                                    \n",
      "drop: 0.72726\n",
      "Val loss: 1.7761 ACC: 0.76794                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ffded7a1e9453995e06a41cea108eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6459/1.5706 ACC: 0.89933                                                                                                    \n",
      "drop: 0.72738\n",
      "Val loss: 1.7753 ACC: 0.76633                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21e8b15b739e41d9b9bb80ed2c47c6fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6454/1.543 ACC: 0.89948                                                                                                     \n",
      "drop: 0.72774\n",
      "Val loss: 1.7748 ACC: 0.77074                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87d7affe2d304e5893a20b4aa5672876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6458/1.543 ACC: 0.89923                                                                                                     \n",
      "drop: 0.72713\n",
      "Val loss: 1.7731 ACC: 0.76954                                                                                                    \n",
      "New Best Val loss: 1.7731                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9d5878f7b0497bbc5a50260f03dea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6461/1.543 ACC: 0.89888                                                                                                     \n",
      "drop: 0.72628\n",
      "Val loss: 1.7715 ACC: 0.77074                                                                                                    \n",
      "New Best Val loss: 1.7715                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03aa361fc1584255bf785e235525df70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6456/1.543 ACC: 0.89933                                                                                                     \n",
      "drop: 0.72738\n",
      "Val loss: 1.7707 ACC: 0.77275                                                                                                    \n",
      "New Best Val loss: 1.7707                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08e60cbf9384f48927e9aa1dbb2f9b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6457/1.5431 ACC: 0.89978                                                                                                    \n",
      "drop: 0.72848\n",
      "Val loss: 1.7705 ACC: 0.77275                                                                                                    \n",
      "New Best Val loss: 1.7705                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adddd71306c94435865909c112f3e69b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6451/1.5522 ACC: 0.90029                                                                                                    \n",
      "drop: 0.7297\n",
      "Val loss: 1.7724 ACC: 0.76994                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a98d9c62254c9ea06bfea82cceb07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6438/1.543 ACC: 0.90184                                                                                                     \n",
      "drop: 0.73349\n",
      "Val loss: 1.7703 ACC: 0.77275                                                                                                    \n",
      "New Best Val loss: 1.7703                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e06a5628ea34e08a0acb3d51a42b472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6453/1.7218 ACC: 0.90029                                                                                                    \n",
      "drop: 0.7297\n",
      "Val loss: 1.7732 ACC: 0.76874                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e6fe7126794676b62f6cf73bb2ccc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 51:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6457/1.8764 ACC: 0.90029                                                                                                    \n",
      "drop: 0.7297\n",
      "Val loss: 1.7727 ACC: 0.77034                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afca6cb15d374aabbb1f48df46434564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 52:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6441/1.5859 ACC: 0.90089                                                                                                    \n",
      "drop: 0.73116\n",
      "Val loss: 1.775 ACC: 0.76794                                                                                                     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db4618d084f45eaab99258984a0e5ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 53:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6445/1.8908 ACC: 0.90154                                                                                                    \n",
      "drop: 0.73275\n",
      "Val loss: 1.7723 ACC: 0.76834                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732c23f17a8b42638d567e77c56634d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 54:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6425/1.5643 ACC: 0.9024                                                                                                     \n",
      "drop: 0.73484\n",
      "Val loss: 1.7719 ACC: 0.77154                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff550bf34de4d1eb4d250eb5b8e3054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 55:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6426/1.5443 ACC: 0.90285                                                                                                    \n",
      "drop: 0.73594\n",
      "Val loss: 1.7692 ACC: 0.77355                                                                                                    \n",
      "New Best Val loss: 1.7692                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1319c41006b9494fb2ddaf87105038f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 56:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.643/1.543 ACC: 0.9025                                                                                                       \n",
      "drop: 0.73508\n",
      "Val loss: 1.7712 ACC: 0.77154                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e91fa2241c4575a5c1a51f11a86b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 57:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6429/1.543 ACC: 0.90204                                                                                                     \n",
      "drop: 0.73398\n",
      "Val loss: 1.7709 ACC: 0.77515                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2a60f6fce44189ba66f7008d5ead32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 58:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6429/1.543 ACC: 0.9027                                                                                                      \n",
      "drop: 0.73557\n",
      "Val loss: 1.7718 ACC: 0.77034                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f833dd0531fb4dd689f8ee37db211f74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 59:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6441/1.8573 ACC: 0.90265                                                                                                    \n",
      "drop: 0.73545\n",
      "Val loss: 1.7724 ACC: 0.77154                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7658decf1ebd4f35beedf23e24c1ea11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 60:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.642/1.543 ACC: 0.9038                                                                                                       \n",
      "drop: 0.73828\n",
      "Val loss: 1.7697 ACC: 0.77475                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f623c9a7bd84e9ea4f9dfe651cf47e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 61:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6412/1.5438 ACC: 0.9035                                                                                                     \n",
      "drop: 0.73754\n",
      "Val loss: 1.7699 ACC: 0.77275                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e19775b22c94b0f8a61b6d0d5622d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 62:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6434/1.543 ACC: 0.90144                                                                                                     \n",
      "drop: 0.73251\n",
      "Val loss: 1.7723 ACC: 0.77114                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d40cfb91ee449caad9c4d368c8302d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 63:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6452/2.2097 ACC: 0.90174                                                                                                    \n",
      "drop: 0.73324\n",
      "Val loss: 1.7724 ACC: 0.77114                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff4ddc6f7a94c8689d2cc11bce3b9b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 64:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6419/1.5441 ACC: 0.90345                                                                                                    \n",
      "drop: 0.73742\n",
      "Val loss: 1.7704 ACC: 0.77194                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9880f74aa0042279a24fd04719a0b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 65:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6408/1.5431 ACC: 0.90451                                                                                                    \n",
      "drop: 0.74\n",
      "Val loss: 1.7695 ACC: 0.77034                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46fccff90c3492d8aebf03897a85550",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 66:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6414/1.543 ACC: 0.9032                                                                                                      \n",
      "drop: 0.7368\n",
      "Val loss: 1.7684 ACC: 0.77595                                                                                                    \n",
      "New Best Val loss: 1.7684                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3a80b9cb364992960dce7ac4a63c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 67:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.641/1.6873 ACC: 0.90466                                                                                                     \n",
      "drop: 0.74037\n",
      "Val loss: 1.7688 ACC: 0.77154                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23dc6e6dd484617a382995472450796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 68:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6433/1.8341 ACC: 0.9031                                                                                                     \n",
      "drop: 0.73656\n",
      "Val loss: 1.7704 ACC: 0.77315                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1b50494a5a401087f15b63e0d56c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 69:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6417/1.8764 ACC: 0.90425                                                                                                    \n",
      "drop: 0.73939\n",
      "Val loss: 1.7682 ACC: 0.77355                                                                                                    \n",
      "New Best Val loss: 1.7682                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c716d0809a4a8690273096b89934bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 70:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6412/1.5487 ACC: 0.90405                                                                                                    \n",
      "drop: 0.7389\n",
      "Val loss: 1.7674 ACC: 0.77595                                                                                                    \n",
      "New Best Val loss: 1.7674                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6b26cddf57483c9e0d49febf6486d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 71:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6406/1.543 ACC: 0.9041                                                                                                      \n",
      "drop: 0.73902\n",
      "Val loss: 1.7679 ACC: 0.77595                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88412827b19f4bff94e9950597e6fbc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 72:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6413/1.8764 ACC: 0.90451                                                                                                    \n",
      "drop: 0.74\n",
      "Val loss: 1.7672 ACC: 0.77715                                                                                                    \n",
      "New Best Val loss: 1.7672                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f7279cedb54894aacd87b0fda5304d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 73:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6416/1.543 ACC: 0.90325                                                                                                     \n",
      "drop: 0.73693\n",
      "Val loss: 1.7669 ACC: 0.77555                                                                                                    \n",
      "New Best Val loss: 1.7669                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d40085d2ff446f5b00dfc2ca3c56801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 74:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6404/1.8473 ACC: 0.90516                                                                                                    \n",
      "drop: 0.74161\n",
      "Val loss: 1.7689 ACC: 0.77475                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f28230afa64d6a8b7ad00f16a6d31c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 75:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6407/1.8759 ACC: 0.90546                                                                                                    \n",
      "drop: 0.74235\n",
      "Val loss: 1.7697 ACC: 0.77194                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dd1195352e44e8c816e0194364cbf8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 76:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6401/1.543 ACC: 0.90486                                                                                                     \n",
      "drop: 0.74087\n",
      "Val loss: 1.7672 ACC: 0.77395                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8677018f9e974a57bc005c678b178ada",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 77:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6406/1.5453 ACC: 0.90551                                                                                                    \n",
      "drop: 0.74247\n",
      "Val loss: 1.7668 ACC: 0.77595                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c05b51971a494c8d62505f09afe0bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 78:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6416/1.8156 ACC: 0.9037                                                                                                     \n",
      "drop: 0.73803\n",
      "Val loss: 1.7662 ACC: 0.77635                                                                                                    \n",
      "New Best Val loss: 1.7662                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6371d59d5d6f4e6eaa25ca8ab1e7adf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 79:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6396/1.5431 ACC: 0.90486                                                                                                    \n",
      "drop: 0.74087\n",
      "Val loss: 1.7645 ACC: 0.77836                                                                                                    \n",
      "New Best Val loss: 1.7645                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebb818aeecd4ae48716064506e5731f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 80:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6404/1.543 ACC: 0.90491                                                                                                     \n",
      "drop: 0.74099\n",
      "Val loss: 1.7691 ACC: 0.77315                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1036ff42b3fa4b69b2c9a8858565214c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 81:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6391/1.5464 ACC: 0.90611                                                                                                    \n",
      "drop: 0.74396\n",
      "Val loss: 1.7699 ACC: 0.77114                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9701d22c89c849a0b6e2e0f4f959aae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 82:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6413/1.8764 ACC: 0.90456                                                                                                    \n",
      "drop: 0.74013\n",
      "Val loss: 1.7715 ACC: 0.77275                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7720b27eda047a8ade1315e2dbc1c3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 83:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6397/1.5553 ACC: 0.90541                                                                                                    \n",
      "drop: 0.74223\n",
      "Val loss: 1.771 ACC: 0.77154                                                                                                     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e084605f6e294f00b833d84074f9b8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 84:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6393/1.877 ACC: 0.90692                                                                                                     \n",
      "drop: 0.74594\n",
      "Val loss: 1.7722 ACC: 0.77154                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992cf2b236894722ba1720f27151fbdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 85:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6413/1.8708 ACC: 0.9041                                                                                                     \n",
      "drop: 0.73902\n",
      "Val loss: 1.7764 ACC: 0.76593                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c986746b2e534a34ad33c4e54e30a6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 86:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6396/1.543 ACC: 0.90571                                                                                                     \n",
      "drop: 0.74297\n",
      "Val loss: 1.7752 ACC: 0.76713                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d15384f9ba04219bf28f8d78af7e782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 87:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6388/1.8747 ACC: 0.90662                                                                                                    \n",
      "drop: 0.74519\n",
      "Val loss: 1.7745 ACC: 0.76713                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4b7dfcf46d40c3854caedde4a00efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 88:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6386/1.543 ACC: 0.90521                                                                                                     \n",
      "drop: 0.74173\n",
      "Val loss: 1.773 ACC: 0.76994                                                                                                     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78ede0d876e41fcb1cb826781e03ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 89:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6378/1.5431 ACC: 0.90737                                                                                                    \n",
      "drop: 0.74705\n",
      "Val loss: 1.7719 ACC: 0.77154                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3d6993d04ec49719c8ce10044dc75d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 90:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6406/1.8764 ACC: 0.90471                                                                                                    \n",
      "drop: 0.7405\n",
      "Val loss: 1.7713 ACC: 0.77034                                                                                                    \n",
      "Epoch    90: reducing learning rate of group 0 to 5.7000e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a477004fe4cf48658e76b2b8664953f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 91:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6379/1.543 ACC: 0.90682                                                                                                     \n",
      "drop: 0.74569\n",
      "Val loss: 1.7715 ACC: 0.77114                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d41d0bea5bb4819a31927fb272a6d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 92:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6385/1.6764 ACC: 0.90712                                                                                                    \n",
      "drop: 0.74643\n",
      "Val loss: 1.7689 ACC: 0.77154                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ce2ec0f37d4ccdbc3c4c4e0f426277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 93:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6388/1.5645 ACC: 0.90601                                                                                                    \n",
      "drop: 0.74371\n",
      "Val loss: 1.77 ACC: 0.77275                                                                                                      \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78edb37afb0345559aea3ed99e3b9c66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 94:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6388/1.5431 ACC: 0.90566                                                                                                    \n",
      "drop: 0.74284\n",
      "Val loss: 1.7715 ACC: 0.77114                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d08089a82474b6fa86a6ae6d7c2da6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 95:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6396/1.8764 ACC: 0.90621                                                                                                    \n",
      "drop: 0.7442\n",
      "Val loss: 1.7695 ACC: 0.77435                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d037ad23b6d44df97fcba7227cc1a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 96:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6376/1.5431 ACC: 0.90677                                                                                                    \n",
      "drop: 0.74557\n",
      "Val loss: 1.7704 ACC: 0.77194                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f01ca98d41459c9fbd28f7ccd45dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 97:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6388/1.8839 ACC: 0.90697                                                                                                    \n",
      "drop: 0.74606\n",
      "Val loss: 1.7695 ACC: 0.77315                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac6502bfc1446df9e4065618b99ff22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 98:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6395/1.8077 ACC: 0.90616                                                                                                    \n",
      "drop: 0.74408\n",
      "Val loss: 1.7685 ACC: 0.77355                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b73152cb2ae44de94094d7cb5d5be6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 99:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6371/1.5431 ACC: 0.90807                                                                                                    \n",
      "drop: 0.74879\n",
      "Val loss: 1.7689 ACC: 0.77515                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb33b38be6b64d83a6f9b7a4393bebe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 100:   0%|          | 0/22402 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 1.6373/1.9691 ACC: 0.90842                                                                                                    \n",
      "drop: 0.74966\n",
      "Val loss: 1.7704 ACC: 0.77355                                                                                                    \n",
      "Best Val loss: 1.7645                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "best = 99999.\n",
    "counter = 1\n",
    "loss_val = 1.\n",
    "eps = .9\n",
    "dl_val = DataLoader(list(zip(fold.X_val, y_val)), batch_size=batch_size,\n",
    "                         shuffle=False, collate_fn=collate_train, num_workers=12)\n",
    "for e in tqdm(range(nepochs), total=nepochs):\n",
    "    dl_train = DataLoader(list(zip(fold.X_train, y_train)), batch_size=batch_size,\n",
    "                             shuffle=True, collate_fn=collate_train, num_workers=12)\n",
    "    loss_train  = 0.\n",
    "    with tqdm(total=len(y_train)+len(y_val), smoothing=0., desc=f\"Epoch {e+1}\") as pbar:\n",
    "        total = 0\n",
    "        correct  = 0\n",
    "        ab.train()\n",
    "        tokenizer.model = 'sample'\n",
    "        for i, (terms_idx, docs_offsets, y) in enumerate(dl_train):\n",
    "            terms_idx    = terms_idx.to( device )\n",
    "            docs_offsets = docs_offsets.to( device )\n",
    "            y            = y.to( device )\n",
    "            \n",
    "            pred_docs,_,_ = ab( terms_idx, docs_offsets)\n",
    "            pred_docs = F.softmax(pred_docs)\n",
    "            loss = loss_func_cel(pred_docs, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            total      += len(y)\n",
    "            y_pred      = pred_docs.argmax(axis=1)\n",
    "            correct    += (y_pred == y).sum().item()\n",
    "            #ab.drop_ =  np.power((correct/total),loss_val)\n",
    "            ab.drop_ =  np.power((correct/total),3.)\n",
    "            \n",
    "            toprint  = f\"Train loss: {loss_train/(i+1):.5}/{loss.item():.5} \"\n",
    "            toprint += f'ACC: {correct/total:.5}'\n",
    "            \n",
    "            print(toprint, end=f\"{' '*100}\\r\")\n",
    "            \n",
    "            pbar.update( len(y) )\n",
    "            del pred_docs, loss\n",
    "            del terms_idx, docs_offsets, y\n",
    "            del y_pred\n",
    "        loss_train = loss_train/(i+1)\n",
    "        print()\n",
    "        print(f'drop: {ab.drop_:.5}')\n",
    "        total = 0\n",
    "        correct  = 0\n",
    "        ab.eval()\n",
    "        tokenizer.model = 'topk'\n",
    "        with torch.no_grad():\n",
    "            loss_val = 0.\n",
    "            for i, (terms_idx, docs_offsets, y) in enumerate(dl_val):\n",
    "                terms_idx    = terms_idx.to( device )\n",
    "                docs_offsets = docs_offsets.to( device )\n",
    "                y            = y.to( device )\n",
    "\n",
    "                pred_docs,weights,co_weights = ab( terms_idx, docs_offsets )\n",
    "                pred_docs   = F.softmax(pred_docs)\n",
    "\n",
    "                y_pred      = pred_docs.argmax(axis=1)\n",
    "                correct    += (y_pred == y).sum().item()\n",
    "                total      += len(y)\n",
    "                loss2       = loss_func_cel(pred_docs, y)\n",
    "                loss_val   += loss2\n",
    "\n",
    "                print(f'Val loss: {loss_val.item()/(i+1):.5} ACC: {correct/total:.5}', end=f\"{' '*100}\\r\")\n",
    "   \n",
    "                pbar.update( len(y) )\n",
    "            print()\n",
    "\n",
    "            del terms_idx, docs_offsets, y\n",
    "            del y_pred\n",
    "            \n",
    "            loss_val   = (loss_val/(i+1)).cpu()\n",
    "            scheduler.step(loss_val)\n",
    "\n",
    "            if best-loss_val > 0.0001 :\n",
    "                best = loss_val.item()\n",
    "                counter = 1\n",
    "                print(f'New Best Val loss: {best:.5}', end=f\"{' '*100}\\n\")\n",
    "                best_model = copy.deepcopy(ab).to('cpu')\n",
    "            elif counter > max_epochs:\n",
    "                print(f'Best Val loss: {best:.5}', end=f\"{' '*100}\\n\")\n",
    "                break\n",
    "            else:\n",
    "                counter += 1\n",
    "            del pred_docs, loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.7705 ACC: 0.77475                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "ab = copy.deepcopy(best_model).to(device)\n",
    "loss_total = 0\n",
    "correct_t = 0\n",
    "total_t = 0\n",
    "dl_test = DataLoader(list(zip(fold.X_test, y_test)), batch_size=batch_size,\n",
    "                         shuffle=False, collate_fn=collate_train, num_workers=2)\n",
    "for i, (terms_idx_t, docs_offsets_t, y_t) in enumerate(dl_test):\n",
    "    terms_idx_t    = terms_idx_t.to( device )\n",
    "    docs_offsets_t = docs_offsets_t.to( device )\n",
    "    y_t            = y_t.to( device )\n",
    "\n",
    "    pred_docs_t,weigths,coweights = ab( terms_idx_t, docs_offsets_t )\n",
    "    pred_docs_t = F.softmax(pred_docs_t)\n",
    "\n",
    "    y_pred_t    = pred_docs_t.argmax(axis=1)\n",
    "    correct_t  += (y_pred_t == y_t).sum().item()\n",
    "    total_t    += len(y_t)\n",
    "    loss_total += loss_func_cel(pred_docs_t, y_t)\n",
    "\n",
    "print(f'Test loss: {loss_total.item()/(i+1):.5} ACC: {correct_t/total_t:.5}', end=f\"{' '*100}\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 63, 0.4126984126984127)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred_t == y_t).sum().item(), len(y_t), (y_pred_t == y_t).sum().item()/len(y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([63, 100]), torch.Size([63, 100, 100]), torch.Size([63, 11]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weigths[:,:,0].shape, coweights.shape, pred_docs_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1169, 0.1110, 0.0961,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0085, 0.0114, 0.0101,  ..., 0.0115, 0.0092, 0.0113],\n",
       "        [0.1655, 0.1046, 0.1434,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0990, 0.1927, 0.1301,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.2272, 0.1201, 0.3264,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.2211, 0.1816, 0.2994,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weigths[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000e+00, 9.6085e-01, 1.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [1.0000e+00, 8.1252e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 9.9999e-01, 1.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 1.0000e+00, 9.9994e-01,  ..., 1.0000e+00,\n",
       "          0.0000e+00, 1.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 9.0235e-01,\n",
       "          0.0000e+00, 1.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0000e+00,\n",
       "          9.9959e-01, 1.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          7.0351e-27, 9.9991e-01],\n",
       "         [0.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 9.9721e-01,\n",
       "          1.0000e+00, 1.0000e+00]],\n",
       "\n",
       "        [[1.0000e+00, 2.7173e-32, 1.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 7.8736e-01, 1.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 1.0000e+00, 9.9999e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 9.7731e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[1.0000e+00, 5.5216e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]],\n",
       "\n",
       "        [[7.8736e-01, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 9.9999e-01,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [9.9925e-01, 9.9975e-01, 1.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]]], device='cuda:0',\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coweights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nacm ####################################################################################\\nTrain loss: 1.6009/1.6089 ACC: 0.94886                                                                                                    \\nVal loss: 1.7718 ACC: 0.77475                                                                                                    \\nNew Best Val loss: 1.7718                                                                                                    \\nTest loss: 1.7678 ACC: 0.78557  79.92\\n\\nTrain loss: 1.7209/1.6095 ACC: 0.82338                                                                                                    \\nVal loss: 1.7595 ACC: 0.78236                                                                                                    \\nNew Best Val loss: 1.7595                                                                                             \\nTest loss: 1.7585 ACC: 0.78557                                                                                                    \\n\\n20ng ####################################################################################\\nTrain loss: 2.0907/2.0787 ACC: 0.98845                                                                                                    \\nVal loss: 2.1869 ACC: 0.90803                                                                                                    \\nNew Best Val loss: 2.1869                                                                                                    \\nTest loss: 2.178 ACC: 0.91068   92.65\\n\\nTrain loss: 2.1603/2.1249 ACC: 0.92511                                                                                                    \\nVal loss: 2.1842 ACC: 0.90645                                                                                                    \\ndrop: 0.8436\\nNew Best Val loss: 2.1842                                                                                                   \\nTest loss: 2.1705 ACC: 0.91226                                                                                                    \\n\\nreut ####################################################################################\\nTrain loss: 3.7735/3.5191 ACC: 0.74734                                                                                                    \\nVal loss: 3.8554 ACC: 0.6763                                                                                                    \\nNew Best Val loss: 3.8554                                                                                                    \\nTest loss: 3.8493 ACC: 0.6837  72.67\\n\\nTrain loss: 3.7443/3.8521 ACC: 0.77727                                                                                                    \\nVal loss: 3.808 ACC: 0.71037                                                                                                     \\nNew Best Val loss: 3.808\\nTest loss: 3.8461 ACC: 0.70444                                                                                                    \\n\\nwebkb ####################################################################################\\nTrain loss: 1.2228/1.2037 ACC: 0.9504                                                                                                     \\nVal loss: 1.3787 ACC: 0.80316                                                                                                    \\nNew Best Val loss: 1.3787                                                                                                    \\nTest loss: 1.3857 ACC: 0.78858   81.53\\n\\nEpoch: 45\\nTrain loss: 1.2392/1.2909 ACC: 0.9295                                                                                                     \\nVal loss: 1.3838 ACC: 0.78736                                                                                                    \\nNew Best Val loss: 1.3838\\nTest loss: 1.3814 ACC: 0.78372                                                                                                    \\n\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "acm ####################################################################################\n",
    "Train loss: 1.6009/1.6089 ACC: 0.94886                                                                                                    \n",
    "Val loss: 1.7718 ACC: 0.77475                                              ou eu ou a ca                                                      \n",
    "New Best Val loss: 1.7718                                                                                                    \n",
    "Test loss: 1.7678 ACC: 0.78557  79.92\n",
    "\n",
    "Train loss: 1.7209/1.6095 ACC: 0.82338                                                                                                    \n",
    "Val loss: 1.7595 ACC: 0.78236                                                                                                    \n",
    "New Best Val loss: 1.7595                                                                                             \n",
    "Test loss: 1.7585 ACC: 0.78557                                                                                                    \n",
    "\n",
    "20ng ####################################################################################\n",
    "Train loss: 2.0907/2.0787 ACC: 0.98845                                                                                                    \n",
    "Val loss: 2.1869 ACC: 0.90803                                                                                                    \n",
    "New Best Val loss: 2.1869                                                                                                    \n",
    "Test loss: 2.178 ACC: 0.91068   92.65\n",
    "\n",
    "Train loss: 2.1603/2.1249 ACC: 0.92511                                                                                                    \n",
    "Val loss: 2.1842 ACC: 0.90645                                                                                                    \n",
    "drop: 0.8436\n",
    "New Best Val loss: 2.1842                                                                                                   \n",
    "Test loss: 2.1705 ACC: 0.91226                                                                                                    \n",
    "\n",
    "reut ####################################################################################\n",
    "Train loss: 3.7735/3.5191 ACC: 0.74734                                                                                                    \n",
    "Val loss: 3.8554 ACC: 0.6763                                                                                                    \n",
    "New Best Val loss: 3.8554                                                                                                    \n",
    "Test loss: 3.8493 ACC: 0.6837  72.67\n",
    "\n",
    "Train loss: 3.7443/3.8521 ACC: 0.77727                                                                                                    \n",
    "Val loss: 3.808 ACC: 0.71037                                                                                                     \n",
    "New Best Val loss: 3.808\n",
    "Test loss: 3.8461 ACC: 0.70444                                                                                                    \n",
    "\n",
    "webkb ####################################################################################\n",
    "Train loss: 1.2228/1.2037 ACC: 0.9504                                                                                                     \n",
    "Val loss: 1.3787 ACC: 0.80316                                                                                                    \n",
    "New Best Val loss: 1.3787                                                                                                    \n",
    "Test loss: 1.3857 ACC: 0.78858   81.53\n",
    "\n",
    "Epoch: 45\n",
    "Train loss: 1.2392/1.2909 ACC: 0.9295                                                                                                     \n",
    "Val loss: 1.3838 ACC: 0.78736                                                                                                    \n",
    "New Best Val loss: 1.3838\n",
    "Test loss: 1.3814 ACC: 0.78372                                                                                                    \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBag(nn.Module):\n",
    "    def __init__(self, vocab_size, hiddens, nclass, drop=.5, initrange=.5):\n",
    "        super(AttentionBag, self).__init__()\n",
    "        self.hiddens    = hiddens\n",
    "        self.mask       = Mask()\n",
    "        self.dt_emb     = nn.Embedding(vocab_size, hiddens)\n",
    "        self.dt_dir_map = nn.Linear(hiddens, hiddens)\n",
    "        self.drop       = nn.Dropout(drop)\n",
    "        self.ma_term    = nn.MultiheadAttention(hiddens, 1)\n",
    "        self.fc         = nn.Linear(hiddens, nclass)\n",
    "        self.initrange  = initrange \n",
    "        self.init_weights()\n",
    "    def forward(self, terms_idx, docs_offsets):\n",
    "        n = terms_idx.shape[0]\n",
    "        batch_size = docs_offsets.shape[0]\n",
    "        \n",
    "        k         = [ terms_idx[ docs_offsets[i-1]:docs_offsets[i] ] for i in range(1, batch_size) ]\n",
    "        k.append( terms_idx[ docs_offsets[-1]: ] )\n",
    "        x_packed  = pad_sequence(k, batch_first=True, padding_value=0)\n",
    "\n",
    "        bx_packed = x_packed == 0\n",
    "        pad_mask  = bx_packed.logical_not()\n",
    "        pad_mask  = pad_mask.view(*bx_packed.shape, 1)\n",
    "        pad_mask  = pad_mask.logical_and(pad_mask.transpose(1, 2))\n",
    "        \n",
    "        dt_h      = self.dt_emb( x_packed )\n",
    "        dt_h      = self.drop(dt_h)\n",
    "        dir_dt_h  = self.dt_dir_map( dt_h )\n",
    "\n",
    "        weights = torch.bmm( dt_h, dir_dt_h.transpose( 1, 2 ) )\n",
    "        weights = self.mask(weights)\n",
    "        \n",
    "        weights_disc = (weights * pad_mask)\n",
    "        weights_disc = weights_disc.sum(axis=1)\n",
    "        weights_disc = F.softmax(weights_disc, dim=1)\n",
    "        weights_disc = weights_disc.view( *weights_disc.shape, 1 )\n",
    "        \n",
    "        attn_mask = weights != 0\n",
    "        attn_mask = attn_mask.logical_and( pad_mask ).logical_not()\n",
    "        \n",
    "        dt_h     = dt_h.transpose(0,1)\n",
    "        dir_dt_h = dir_dt_h.transpose(0,1)\n",
    "        docs_att, weigths_att = self.ma_term( dt_h, dir_dt_h, dt_h,\n",
    "                                  key_padding_mask=bx_packed, \n",
    "                                  attn_mask=attn_mask )\n",
    "\n",
    "        weigths_att = torch.where(torch.isnan(weigths_att), torch.zeros_like(weigths_att), weigths_att)\n",
    "        weigths_att = (weigths_att * pad_mask)\n",
    "        weigths_att = weigths_att.sum(axis=1)\n",
    "        weigths_att = F.softmax(weigths_att, dim=1)\n",
    "        weigths_att = weigths_att.view( *weigths_att.shape, 1 )\n",
    "        \n",
    "        weigths = weights_disc + weigths_att\n",
    "\n",
    "        docs_att = docs_att.transpose(0,1)\n",
    "        docs_att = torch.where(torch.isnan(docs_att), torch.zeros_like(docs_att), docs_att)\n",
    "        \n",
    "        docs_h = docs_att * weigths\n",
    "        docs_h = docs_h.sum(axis=1)\n",
    "        docs_h = docs_h / bx_packed.logical_not().sum(dim=1).view(batch_size, 1)\n",
    "        docs_h = torch.where(torch.isnan(docs_h), torch.zeros_like(docs_h), docs_h)\n",
    "        docs_h = self.drop(docs_h)\n",
    "        return self.fc(docs_h)\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.dt_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.dt_dir_map.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.fc.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.ma_term.in_proj_weight.data.uniform_(-self.initrange, self.initrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4126984126984127"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_t      = pred_docs_t.argmax(axis=1)\n",
    "correct_t     = (y_pred_t == y_t).sum().item()\n",
    "total_t       = len(y_t)\n",
    "correct_t/total_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   0,   10,  342,  349,  358,  375,  379,  383,  387,  391,  395,  502,\n",
       "         505,  509,  519,  522,  533,  575,  579,  590,  593,  597,  601,  607,\n",
       "         610,  616,  620,  624,  634,  650,  654,  661,  665,  969,  973,  983,\n",
       "         985,  990,  996, 1046, 1049, 1053, 1183, 1187, 1191, 1194, 1198, 1202,\n",
       "        1206, 1211, 1215, 1219, 1231, 1249, 1422, 1426, 1430, 1433, 1437, 1450,\n",
       "        1454, 1460, 1464], device='cuda:0')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_offsets_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 64 is out of bounds for dimension 0 with size 63",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-6de26dbd6e30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mterms_idx_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdocs_offsets_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 64 is out of bounds for dimension 0 with size 63"
     ]
    }
   ],
   "source": [
    "terms_idx_t[:docs_offsets_t[batch_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_off_test  = docs_offsets_t[batch_size]\n",
    "batch_tidx_test = terms_idx_t[:batch_off_test]\n",
    "h_terms_test    = sc.tt_emb( batch_tidx_test )\n",
    "dirh_terms_test = sc.tt_dir_map( h_terms_test )\n",
    "\n",
    "W = torch.matmul( h_terms_test, dirh_terms_test.T )\n",
    "W = F.leaky_relu( W, negative_slope=sc.mask.negative_slope)\n",
    "W = F.sigmoid(W)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [ batch_tidx_test[ docs_offsets_t[i-1]:docs_offsets_t[i] ] for i in range(1, batch_size) ]\n",
    "k.append( batch_tidx_test[ docs_offsets_t[batch_size-1]:docs_offsets_t[batch_size] ] )\n",
    "x_packed = pad_sequence(k, batch_first=True, padding_value=0)\n",
    "tt_emb = sc.tt_emb( x_packed )\n",
    "len(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_packed = pad_sequence(k, batch_first=True, padding_value=0)\n",
    "tt_emb = sc.tt_emb( x_packed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_emb.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [terms_idx, terms_idx]\n",
    "torch.stack(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "F.softmax(pred_docs_t).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_t == F.softmax(pred_docs_t).argmax(axis=1)).sum().item()/y_t.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_idx_t, docs_offsets_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts = sc._get_shift_(docs_offsets_t, terms_idx_t.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipado = zip(docs_offsets_t, shifts)\n",
    "#next(zipado)\n",
    "start,size = next(zipado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sc.tt_emb( terms_idx_t[start:start+size] )\n",
    "w1 = sc.tt_dir_map( w )\n",
    "w = torch.matmul( w, w1.T )\n",
    "w = F.leaky_relu( w, negative_slope=sc.negative_slope)\n",
    "w = F.sigmoid(w)\n",
    "#w = F.tanh(w)\n",
    "#w = F.relu(w)\n",
    "#w = w.mean(axis=1)\n",
    "#w = F.softmax(w)\n",
    "w,w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.round().sum() / (w.shape[0]*w.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_mapper = { v:k for (k,v) in tokenizer.node_mapper.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_idx[start:start+size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold.X_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = w.mean(axis=1)\n",
    "bla = F.softmax(bla)\n",
    "#bla = bla/torch.clamp(bla.sum(), 0.0001)\n",
    "bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ (i, tid.item(),inv_mapper[tid.item()], wei.item()) for i, (tid, wei) in enumerate(zip(terms_idx[start:start+size], bla)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = nn.BatchNorm1d(num_features=1).to(device)\n",
    "\n",
    "bla2 = norm(bla.view(-1, 1)).squeeze()\n",
    "bla2 = F.sigmoid(bla2)\n",
    "bla2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = nn.MultiheadAttention(300, 300).to(device)\n",
    "ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = w.shape\n",
    "w_ = w.view(a,1,b)\n",
    "w1_ = w1.view(a,1,b)\n",
    "\n",
    "attn_output = ma(w_, w1_, w_, need_weights=False)\n",
    "\n",
    "attn_output.view(a,b)\n",
    "attn_output_weights.view(a,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output.view(a,b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output_weights.view(a,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(torch.Tensor([[0.0718, 0.0716, 0.0712, 0.0714, 0.0721, 0.0710, 0.0712, 0.0714, 0.0710,\n",
    "         0.0719, 0.0711, 0.0712, 0.0718, 0.0714],\n",
    "        [0.0722, 0.0709, 0.0710, 0.0709, 0.0728, 0.0723, 0.0709, 0.0709, 0.0719,\n",
    "         0.0712, 0.0709, 0.0707, 0.0725, 0.0707],\n",
    "        [0.0711, 0.0715, 0.0710, 0.0713, 0.0710, 0.0712, 0.0718, 0.0713, 0.0709,\n",
    "         0.0725, 0.0716, 0.0719, 0.0710, 0.0719],\n",
    "        [0.0721, 0.0717, 0.0714, 0.0713, 0.0717, 0.0714, 0.0711, 0.0710, 0.0713,\n",
    "         0.0717, 0.0710, 0.0712, 0.0720, 0.0711],\n",
    "        [0.0722, 0.0711, 0.0710, 0.0710, 0.0737, 0.0716, 0.0709, 0.0705, 0.0714,\n",
    "         0.0719, 0.0707, 0.0707, 0.0731, 0.0702],\n",
    "        [0.0714, 0.0716, 0.0708, 0.0711, 0.0718, 0.0713, 0.0712, 0.0717, 0.0712,\n",
    "         0.0724, 0.0713, 0.0712, 0.0716, 0.0714],\n",
    "        [0.0712, 0.0714, 0.0713, 0.0713, 0.0722, 0.0716, 0.0709, 0.0714, 0.0714,\n",
    "         0.0717, 0.0713, 0.0713, 0.0716, 0.0713],\n",
    "        [0.0716, 0.0707, 0.0712, 0.0714, 0.0717, 0.0715, 0.0714, 0.0715, 0.0712,\n",
    "         0.0721, 0.0711, 0.0714, 0.0717, 0.0715],\n",
    "        [0.0717, 0.0713, 0.0708, 0.0710, 0.0725, 0.0717, 0.0714, 0.0709, 0.0712,\n",
    "         0.0712, 0.0712, 0.0717, 0.0720, 0.0714],\n",
    "        [0.0709, 0.0712, 0.0713, 0.0712, 0.0713, 0.0713, 0.0714, 0.0719, 0.0712,\n",
    "         0.0724, 0.0715, 0.0715, 0.0717, 0.0713],\n",
    "        [0.0715, 0.0716, 0.0712, 0.0708, 0.0725, 0.0717, 0.0712, 0.0714, 0.0714,\n",
    "         0.0717, 0.0713, 0.0706, 0.0718, 0.0712],\n",
    "        [0.0726, 0.0711, 0.0713, 0.0706, 0.0737, 0.0721, 0.0709, 0.0707, 0.0714,\n",
    "         0.0708, 0.0706, 0.0705, 0.0730, 0.0707],\n",
    "        [0.0718, 0.0711, 0.0714, 0.0715, 0.0725, 0.0707, 0.0707, 0.0711, 0.0712,\n",
    "         0.0728, 0.0711, 0.0713, 0.0719, 0.0709],\n",
    "        [0.0712, 0.0716, 0.0713, 0.0712, 0.0717, 0.0707, 0.0708, 0.0721, 0.0709,\n",
    "         0.0728, 0.0713, 0.0716, 0.0711, 0.0715]]).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotTooSimpleClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_l, nclass, dropout1=0.1, dropout2=0.1, negative_slope=99,\n",
    "                 initrange = 0.5, scale_grad_by_freq=False, device='cuda:0'):\n",
    "        super(NotTooSimpleClassifier, self).__init__()\n",
    "        \n",
    "        self.dt_emb = nn.Embedding(vocab_size, hidden_l, scale_grad_by_freq=scale_grad_by_freq)\n",
    "        self.tt_emb = nn.Embedding(vocab_size, hidden_l, scale_grad_by_freq=scale_grad_by_freq)\n",
    "        \n",
    "        self.undirected_map = nn.Linear(hidden_l, hidden_l)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_l, nclass)\n",
    "        self.drop1 = nn.Dropout(dropout1)\n",
    "        self.drop2 = nn.Dropout(dropout2)\n",
    "        \n",
    "        self.norm = nn.BatchNorm1d(1)\n",
    "        \n",
    "        self.initrange = initrange\n",
    "        self.nclass = nclass\n",
    "        self.negative_slope = negative_slope\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "        #self.labls_emb = nn.Embedding(graph_builder.n_class, 300)\n",
    "    \n",
    "    def forward(self, terms_idxs, docs_offsets):\n",
    "        n = terms_idxs.shape[0]\n",
    "        weights = []\n",
    "        shifts = self._get_shift_(docs_offsets, n)\n",
    "        \n",
    "        terms_h1 = self.tt_emb(terms_idxs)\n",
    "        terms_h1 = self.drop1(terms_h1)\n",
    "        \n",
    "        terms_h2 = self.undirected_map( terms_h1 )\n",
    "        #terms_h2 = self.drop1( terms_h2 )\n",
    "        for start,size in zip(docs_offsets, shifts):\n",
    "            w  = terms_h1[start:start+size]\n",
    "            w1 = terms_h2[start:start+size]\n",
    "            w = torch.matmul( w, w1.T )\n",
    "            w = F.leaky_relu( w, negative_slope=self.negative_slope)\n",
    "            w = F.sigmoid(w-5.5)\n",
    "            w = w.mean(axis=1)\n",
    "            w = F.softmax(w)\n",
    "            #w = w / torch.clamp(w.sum(), 0.0001)\n",
    "            weights.append( w )\n",
    "        \n",
    "        weights = torch.cat(weights)\n",
    "        #weights = self.norm(weights.view(-1, 1)).squeeze()\n",
    "        #weights = F.sigmoid(weights)\n",
    "        \n",
    "        h_docs  = F.embedding_bag(self.dt_emb.weight, terms_idxs, docs_offsets, per_sample_weights=weights, mode='sum')\n",
    "        h_docs = self.drop2( h_docs )\n",
    "        pred_docs = self.fc( h_docs )\n",
    "        return pred_docs\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.dt_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.tt_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        \n",
    "    def _get_shift_(self, offsets, lenght):\n",
    "        shifts = offsets[1:] - offsets[:-1]\n",
    "        last = torch.LongTensor([lenght - offsets[-1]]).to( offsets.device )\n",
    "        return torch.cat([shifts, last])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
