{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b406ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from multiprocessing import Pool\n",
    "from collections import namedtuple\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import networkx as nx\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as stop_words\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords as stopwords_by_lang\n",
    "import copy\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "import scipy.sparse as sp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea4cb19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TGA.utils import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f80b142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('X_train', 'y_train', 'X_test', 'y_test', 'X_val', 'y_val'), 15062)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset('/home/Documents/datasets/20ng/')\n",
    "fold = next(dataset.get_fold_instances(10, with_val=True))\n",
    "fold._fields, len(fold.X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67f03afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "replace_patterns = [\n",
    "    ('<[^>]*>', ''),                                    # remove HTML tags\n",
    "    ('(\\D)\\d\\d:\\d\\d:\\d\\d(\\D)', '\\\\1 ParsedTime \\\\2'),\n",
    "    ('(\\D)\\d\\d:\\d\\d(\\D)', '\\\\1 ParsedTime \\\\2'),\n",
    "    ('(\\D)\\d:\\d\\d:\\d\\d(\\D)', '\\\\1 ParsedTime \\\\2'),\n",
    "    ('(\\D)\\d:\\d\\d(\\D)', '\\\\1 ParsedTime \\\\2'),\n",
    "    ('(\\D)\\d\\d\\d\\-\\d\\d\\d\\d(\\D)', '\\\\1 ParsedPhoneNum \\\\2'),\n",
    "    ('(\\D)\\d\\d\\d\\D\\d\\d\\d\\-\\d\\d\\d\\d(\\D)', '\\\\1 ParsedPhoneNum \\\\2'),\n",
    "    ('(\\D\\D)\\d\\d\\d\\D\\D\\d\\d\\d\\-\\d\\d\\d\\d(\\D)', '\\\\1 ParsedPhoneNum \\\\2'),\n",
    "    ('(\\D)\\d\\d\\d\\d\\d\\-\\d\\d\\d\\d(\\D)', '\\\\1 ParsedZipcodePlusFour \\\\2'),\n",
    "    ('(\\D)\\d(\\D)', '\\\\1ParsedOneDigit\\\\2'),\n",
    "    ('(\\D)\\d\\d(\\D)', '\\\\1ParsedTwoDigits\\\\2'),\n",
    "    ('(\\D)\\d\\d\\d(\\D)', '\\\\1ParsedThreeDigits\\\\2'),\n",
    "    ('(\\D)\\d\\d\\d\\d(\\D)', '\\\\1ParsedFourDigits\\\\2'),\n",
    "    ('(\\D)\\d\\d\\d\\d\\d(\\D)', '\\\\1ParsedFiveDigits\\\\2'),\n",
    "    ('(\\D)\\d\\d\\d\\d\\d\\d(\\D)', '\\\\1ParsedSixDigits\\\\2'),\n",
    "    ('\\d+', 'ParsedDigits')\n",
    "]\n",
    "\n",
    "compiled_replace_patterns = [(re.compile(p[0]), p[1]) for p in replace_patterns]\n",
    "\n",
    "def generate_preprocessor(replace_patterns):\n",
    "    compiled_replace_patterns = [(re.compile(p[0]), p[1]) for p in replace_patterns]\n",
    "    def preprocessor(text):\n",
    "        for pattern, replace in compiled_replace_patterns:\n",
    "            text = re.sub(pattern, replace, text)\n",
    "        text = text.lower()\n",
    "        return text\n",
    "    return preprocessor\n",
    "\n",
    "generated_patters=generate_preprocessor(replace_patterns)\n",
    "\n",
    "def preprocessor(text):\n",
    "    # For each pattern, replace it with the appropriate string\n",
    "    for pattern, replace in compiled_replace_patterns:\n",
    "        text = re.sub(pattern, replace, text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "class Tokenizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, mindf=2, lan='english', model='topk', k=500, verbose=False):\n",
    "        super(Tokenizer, self).__init__()\n",
    "        self.mindf = mindf\n",
    "        self.le = LabelEncoder()\n",
    "        self.verbose = verbose\n",
    "        self.stopwordsSet = stop_words\n",
    "        self.model =  model\n",
    "        self.k     = k\n",
    "        self.lan = lan\n",
    "        self.analyzer = TfidfVectorizer(preprocessor=preprocessor, min_df=mindf)#.build_analyzer()\n",
    "        self.local_analyzer = self.analyzer.build_analyzer()\n",
    "        self.analyzer.set_params( analyzer=self.local_analyzer )\n",
    "        self.node_mapper      = {}\n",
    "        \n",
    "    def analyzer_doc(self, doc):\n",
    "        return self.local_analyzer(doc)\n",
    "    def fit(self, X, y):\n",
    "        self.N = len(X)\n",
    "        y = self.le.fit_transform( y )\n",
    "        self.n_class = len(self.le.classes_)\n",
    "        docs_in_terms = []\n",
    "        \n",
    "        with Pool(processes=18) as p:\n",
    "            #docs = map(self.local_analyzer, X)\n",
    "            for doc_in_terms in tqdm(p.imap(self.analyzer_doc, X), total=self.N, disable=not self.verbose):\n",
    "                doc_in_terms = list(set(map( self._filter_fit_, list(doc_in_terms) ))) \n",
    "                docs_in_terms.extend(doc_in_terms)\n",
    "        \n",
    "        self.term_freqs       = Counter(docs_in_terms)\n",
    "        self.term_freqs       = { term:v for (term,v) in self.term_freqs.items() if v >= self.mindf }\n",
    "        self.node_mapper      = { term: self.node_mapper.setdefault(term, len(self.node_mapper)+1)\n",
    "                                 for term in self.term_freqs.keys() }\n",
    "        self.node_mapper['<BLANK>'] = 0\n",
    "        self.term_freqs['<BLANK>']  = self.N\n",
    "        \n",
    "        self.node_mapper['<UNK>']   = len(self.node_mapper)\n",
    "        self.term_freqs['<UNK>']  = self.N\n",
    "        self.vocab_size = len(self.node_mapper)\n",
    "        \n",
    "        self.term_array = [ term for (term,term_id) in sorted(self.node_mapper.items(), key=lambda x: x[1]) ]\n",
    "        \n",
    "        self.fi_ = np.array([ np.log2( (self.N+1)/(self.term_freqs[term]+1) ) for term in self.term_array ])\n",
    "            \n",
    "        return self\n",
    "    def _get_idx_(self, term):\n",
    "        return \n",
    "    def _filter_transform_(self, term):\n",
    "        if term in self.stopwordsSet:\n",
    "            return '<STPW>'\n",
    "        if term not in self.node_mapper:\n",
    "            return '<UNK>'\n",
    "        return term\n",
    "    def _filter_fit_(self, term):\n",
    "        if term in self.stopwordsSet:\n",
    "            return '<STPW>'\n",
    "        return term\n",
    "    def _model_(self, doc):\n",
    "        doc_counter = Counter(doc)\n",
    "        doc = np.array(list(doc_counter.keys()))\n",
    "        if len(doc) > self.k:\n",
    "            weigths = np.array([ self.fi_[t] for t in doc ])\n",
    "            weigths = softmax(weigths)\n",
    "            if self.model == 'topk':\n",
    "                doc = doc[(-weigths).argsort()[:self.k]]\n",
    "            elif self.model == 'sample':\n",
    "                doc = np.random.choice(doc, size=self.k, replace=False, p=weigths)\n",
    "        return doc, np.array([ doc_counter[t] for t in doc ])\n",
    "    def transform(self, X, verbose=None):\n",
    "        verbose = verbose if verbose is not None else self.verbose\n",
    "        n = len(X)\n",
    "        doc_off = [0]\n",
    "        terms_idx = []\n",
    "        terms_frq = []\n",
    "        for i,doc_in_terms in tqdm(enumerate(map(self.analyzer_doc, X)), total=n, disable=not verbose):\n",
    "            doc_in_terms = map( self._filter_transform_, doc_in_terms )\n",
    "            doc_in_terms = filter( lambda x: x != '<STPW>', doc_in_terms )\n",
    "            doc_in_terms = [ self.node_mapper[tid] for tid in doc_in_terms ]\n",
    "            doc_in_terms, freqs = self._model_(doc_in_terms)\n",
    "            doc_off.append( len(doc_in_terms) )\n",
    "            terms_idx.extend( doc_in_terms )\n",
    "            terms_frq.extend( freqs )\n",
    "        return np.array( terms_idx ), np.array( terms_frq ), np.array(doc_off)[:-1].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1066fc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38c3b2f3e3a24f6c8048f83bda73cc08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15062 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(98702, 15062)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(mindf=1, verbose=True)\n",
    "tokenizer.fit(fold.X_train, fold.y_train)\n",
    "tokenizer.vocab_size, tokenizer.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88ea1fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468560ce7e6047608f23d91aa7fc385d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([  127, 34792,   172, ..., 10369,  5056,  7184])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terms_idx, terms_frq, doc_offs = tokenizer.transform( fold.X_val )\n",
    "terms_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9afbeaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tokenizer.le.transform( fold.y_train )\n",
    "y_val   = tokenizer.le.transform( fold.y_val )\n",
    "y_test  = tokenizer.le.transform( fold.y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75973e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_train(param):\n",
    "    X, y = zip(*param)\n",
    "    terms_ids, terms_frq, docs_offsets = tokenizer.transform(X, verbose=False)\n",
    "    return torch.LongTensor(terms_ids), torch.LongTensor(terms_frq), torch.LongTensor(docs_offsets), torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f5b3c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAttentionBagO(nn.Module):\n",
    "    def __init__(self, vocab_size, hiddens, nclass, drop=.5, maxfreq=10, initrange=.5, negative_slope=99.):\n",
    "        super(SimpleAttentionBag, self).__init__()\n",
    "        self.hiddens        = hiddens\n",
    "        self.maxfreq        = maxfreq\n",
    "        self.dt_emb         = nn.Embedding(vocab_size, hiddens, scale_grad_by_freq=True, padding_idx=0)\n",
    "        self.tt_s_emb       = nn.Embedding(vocab_size, hiddens, scale_grad_by_freq=True, padding_idx=0)\n",
    "        self.tt_t_emb       = nn.Embedding(vocab_size, hiddens, scale_grad_by_freq=True, padding_idx=0)\n",
    "        self.freq_emb       = nn.Embedding(maxfreq, hiddens, scale_grad_by_freq=True, padding_idx=0)\n",
    "        self.fc             = nn.Linear(hiddens, nclass)\n",
    "        self.initrange      = initrange \n",
    "        self.negative_slope = negative_slope\n",
    "        self.drop           = nn.Dropout(drop)\n",
    "        self.norm           = nn.BatchNorm1d(hiddens)\n",
    "        self.drop_          = drop\n",
    "        self.sig            = nn.Sigmoid()\n",
    "        self.init_weights()\n",
    "    def forward(self, terms_idx, docs_offsets, terms_frq=None):\n",
    "        n = terms_idx.shape[0]\n",
    "        batch_size = docs_offsets.shape[0]\n",
    "        \n",
    "        k         = [ terms_idx[ docs_offsets[i-1]:docs_offsets[i] ] for i in range(1, batch_size) ]\n",
    "        k.append( terms_idx[ docs_offsets[-1]: ] )\n",
    "        x_packed  = pad_sequence(k, batch_first=True, padding_value=0)\n",
    "        if terms_frq is not None:\n",
    "            j           = [ terms_frq[ docs_offsets[i-1]:docs_offsets[i] ] for i in range(1, batch_size) ]\n",
    "            j.append( terms_frq[ docs_offsets[-1]: ] )\n",
    "            terms_frq   = pad_sequence(j, batch_first=True, padding_value=0)\n",
    "            terms_frq   = torch.clamp(terms_frq, 0, self.maxfreq-1)\n",
    "            terms_frq_h = self.freq_emb(terms_frq)\n",
    "\n",
    "        bx_packed = x_packed == 0\n",
    "        doc_sizes = bx_packed.logical_not().sum(dim=1).view(batch_size, 1)\n",
    "        pad_mask  = bx_packed.logical_not()\n",
    "        pad_mask  = pad_mask.view(*bx_packed.shape, 1)\n",
    "        pad_mask  = pad_mask.logical_and(pad_mask.transpose(1, 2))\n",
    "        \n",
    "        tt_h     = self.tt_s_emb( x_packed )\n",
    "        tt_dir_h = self.tt_t_emb( x_packed ) + terms_frq_h\n",
    "        \n",
    "        dt_h     = tt_dir_h + terms_frq_h\n",
    "        dt_h     = F.dropout( dt_h, p=self.drop_, training=self.training )\n",
    "        \n",
    "        tt_h = torch.tanh(tt_h)\n",
    "        tt_h = F.dropout( tt_h, p=self.drop_, training=self.training )\n",
    "        \n",
    "        tt_dir_h = torch.tanh(tt_dir_h)\n",
    "        tt_dir_h = F.dropout( tt_dir_h, p=self.drop_, training=self.training )\n",
    "        \n",
    "        co_weights = torch.bmm( tt_h, tt_dir_h.transpose( 1, 2 ) )\n",
    "        co_weights = F.leaky_relu( co_weights, negative_slope=self.negative_slope)\n",
    "        \n",
    "        co_weights[pad_mask.logical_not()] = float('-inf') # Set the 3D-pad mask values to -inf (=0 in sigmoid)\n",
    "        co_weights = F.sigmoid(co_weights)\n",
    "        \n",
    "        weights = co_weights.sum(axis=2) / doc_sizes\n",
    "        weights[bx_packed] = float('-inf') # Set the 2D-pad mask values to -inf  (=0 in softmax)\n",
    "        \n",
    "        weights = torch.softmax(weights, dim=1)\n",
    "        weights = torch.where(torch.isnan(weights), torch.zeros_like(weights), weights)\n",
    "        weights = weights.view( *weights.shape, 1 )\n",
    "        #if terms_frq is not None:\n",
    "        #    terms_frq = terms_frq.view( *terms_frq.shape, 1 )\n",
    "        #    weights = weights * terms_frq\n",
    "        \n",
    "        docs_h = dt_h * weights\n",
    "        docs_h = docs_h.sum(axis=1)\n",
    "        docs_h = F.dropout( docs_h, p=self.drop_, training=self.training )\n",
    "        docs_h = self.fc(docs_h)\n",
    "        return docs_h, weights, co_weights\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.freq_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.dt_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.tt_s_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.tt_t_emb.weight.data.uniform_(-self.initrange, self.initrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f26c0aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAttentionBag(nn.Module):\n",
    "    def __init__(self, vocab_size, hiddens, nclass, drop=.5, maxfreq=10, initrange=.5, negative_slope=99.):\n",
    "        super(SimpleAttentionBag, self).__init__()\n",
    "        self.hiddens        = hiddens\n",
    "        self.maxfreq        = maxfreq\n",
    "        self.term_query_emb = nn.Embedding(vocab_size, hiddens, scale_grad_by_freq=True, padding_idx=0)\n",
    "        self.term_key_emb   = nn.Embedding(vocab_size, hiddens, scale_grad_by_freq=True, padding_idx=0)\n",
    "        self.term_value_emb = nn.Embedding(vocab_size, hiddens, scale_grad_by_freq=True, padding_idx=0)\n",
    "        self.freq_emb       = nn.Embedding(maxfreq, hiddens, scale_grad_by_freq=True, padding_idx=0)\n",
    "        self.repr_          = nn.Linear(hiddens, hiddens)\n",
    "        self.fc             = nn.Linear(hiddens, nclass)\n",
    "        self.initrange      = initrange \n",
    "        self.negative_slope = negative_slope\n",
    "        self.drop_          = drop\n",
    "        self.init_weights()\n",
    "    def forward(self, terms_idx, docs_offsets, terms_frq):\n",
    "        n = terms_idx.shape[0]\n",
    "        batch_size = docs_offsets.shape[0]\n",
    "        \n",
    "        k         = [ terms_idx[ docs_offsets[i-1]:docs_offsets[i] ] for i in range(1, batch_size) ]\n",
    "        k.append( terms_idx[ docs_offsets[-1]: ] )\n",
    "        x_packed  = pad_sequence(k, batch_first=True, padding_value=0)\n",
    "        \n",
    "        j           = [ terms_frq[ docs_offsets[i-1]:docs_offsets[i] ] for i in range(1, batch_size) ]\n",
    "        j.append( terms_frq[ docs_offsets[-1]: ] )\n",
    "        \n",
    "        terms_frq   = pad_sequence(j, batch_first=True, padding_value=0)\n",
    "        terms_frq   = torch.clamp(terms_frq, 0, self.maxfreq)\n",
    "        terms_frq_h = self.freq_emb(terms_frq)\n",
    "        \n",
    "        bx_packed = x_packed == 0\n",
    "        doc_sizes = bx_packed.logical_not().sum(dim=1).view(batch_size, 1)\n",
    "        \n",
    "        pad_mask  = bx_packed.logical_not()\n",
    "        \n",
    "        pad_mask  = pad_mask.view(*bx_packed.shape, 1)\n",
    "        \n",
    "        pad_mask  = pad_mask.logical_and(pad_mask.transpose(1, 2))\n",
    "        \n",
    "        query_hidden = self.term_query_emb( x_packed )\n",
    "        query_hidden = query_hidden + terms_frq_h\n",
    "        query_hidden = torch.tanh(query_hidden)\n",
    "        query_hidden = F.dropout( query_hidden, p=self.drop_, training=self.training )\n",
    "        \n",
    "        key_hidden   = self.term_key_emb( x_packed )\n",
    "        key_hidden   = key_hidden + terms_frq_h\n",
    "        key_hidden   = torch.tanh(key_hidden)\n",
    "        key_hidden   = F.dropout( key_hidden, p=self.drop_, training=self.training )\n",
    "        \n",
    "        trmdc_hidden = self.term_value_emb( x_packed )\n",
    "        trmdc_hidden = trmdc_hidden + terms_frq_h\n",
    "        #trmdc_hidden = F.leaky_relu( trmdc_hidden, negative_slope=self.negative_slope)\n",
    "        trmdc_hidden = F.dropout( trmdc_hidden, p=self.drop_, training=self.training )\n",
    "        \n",
    "        co_weights = torch.bmm( key_hidden, query_hidden.transpose( 1, 2 ) )\n",
    "        co_weights = F.leaky_relu( co_weights, negative_slope=self.negative_slope)\n",
    "        \n",
    "        co_weights[pad_mask.logical_not()] = float('-inf') # Set the 3D-pad mask values to -inf (=0 in sigmoid)\n",
    "        co_weights = torch.sigmoid(co_weights)\n",
    "        \n",
    "        weights = co_weights.sum(axis=2) / doc_sizes\n",
    "        weights[bx_packed] = float('-inf') # Set the 2D-pad mask values to -inf  (=0 in softmax)\n",
    "        \n",
    "        weights = torch.softmax(weights, dim=1)\n",
    "        #weights = torch.sigmoid(weights)\n",
    "        weights = torch.where(torch.isnan(weights), torch.zeros_like(weights), weights)\n",
    "        weights = weights.view( *weights.shape, 1 )\n",
    "        \n",
    "        docs_h = trmdc_hidden * weights\n",
    "        docs_h = docs_h.sum(axis=1)\n",
    "        docs_h = F.dropout( docs_h, p=self.drop_, training=self.training )\n",
    "        docs_h = self.fc(docs_h)\n",
    "        return docs_h, weights, co_weights\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.term_query_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.term_key_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.freq_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.repr_.weight.data.uniform_(-self.initrange, self.initrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e62d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs = 1000\n",
    "max_epochs = 30\n",
    "drop=0.7\n",
    "max_drop=0.75\n",
    "device = torch.device('cuda:0')\n",
    "batch_size = 64\n",
    "k = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e53a2b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa7bcf87070>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "282a450c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a0756a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc = SimpleClassifier(tokenizer.vocab_size, 300, tokenizer.n_class, dropout=drop).to( device )\n",
    "ab = SimpleAttentionBag(tokenizer.vocab_size, 300, tokenizer.n_class, drop=drop).to( device )\n",
    "#ab = AttentionBag(tokenizer.vocab_size, 300, tokenizer.n_class, drop=drop).to( device )\n",
    "#ab = NotTooSimpleClassifier(tokenizer.vocab_size, 300, tokenizer.n_class, dropout1=drop, dropout2=drop).to( device )\n",
    "tokenizer.k = k\n",
    "optimizer = optim.AdamW( ab.parameters(), lr=5e-3, weight_decay=5e-3)\n",
    "loss_func_cel = nn.CrossEntropyLoss().to( device )\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=.95,\n",
    "                                                       patience=10, verbose=True)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=.98, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8736bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e497917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9c178d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3bc799d7874a9f9aaf62f5202afe66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373b7cfe3e6e411b96031204fc464366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-17f3ce5771da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mterms_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterms_frq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs_offsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdl_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0mterms_idx\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mterms_idx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mdocs_offsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdocs_offsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mterms_frq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterms_frq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered"
     ]
    }
   ],
   "source": [
    "best = 99999.\n",
    "counter = 1\n",
    "loss_val = 1.\n",
    "eps = .9\n",
    "dl_val = DataLoader(list(zip(fold.X_val, y_val)), batch_size=batch_size,\n",
    "                         shuffle=False, collate_fn=collate_train, num_workers=num_workers)\n",
    "for e in tqdm(range(nepochs), total=nepochs):\n",
    "    dl_train = DataLoader(list(zip(fold.X_train, y_train)), batch_size=batch_size,\n",
    "                             shuffle=True, collate_fn=collate_train, num_workers=num_workers)\n",
    "    loss_train  = 0.\n",
    "    with tqdm(total=len(y_train)+len(y_val), smoothing=0., desc=f\"Epoch {e+1}\") as pbar:\n",
    "        total = 0\n",
    "        correct  = 0\n",
    "        ab.train()\n",
    "        tokenizer.model = 'sample'\n",
    "        tokenizer.k = k\n",
    "        for i, (terms_idx, terms_frq, docs_offsets, y) in enumerate(dl_train):\n",
    "            terms_idx    = terms_idx.to( device )\n",
    "            docs_offsets = docs_offsets.to( device )\n",
    "            terms_frq = terms_frq.to( device )\n",
    "            y            = y.to( device )\n",
    "            \n",
    "            pred_docs,_,_ = ab( terms_idx, docs_offsets, terms_frq)\n",
    "            pred_docs     = torch.softmax(pred_docs, dim=1)\n",
    "            loss          = loss_func_cel(pred_docs, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            total      += len(y)\n",
    "            y_pred      = pred_docs.argmax(axis=1)\n",
    "            correct    += (y_pred == y).sum().item()\n",
    "            #ab.drop_ =  np.power((correct/total),loss_val)\n",
    "            #ab.drop_ =  np.power((correct/total),4)\n",
    "            ab.drop_ =  (correct/total)*max_drop\n",
    "            \n",
    "            toprint  = f\"Train loss: {loss_train/(i+1):.5}/{loss.item():.5} \"\n",
    "            toprint += f'Drop: {ab.drop_:.5} '\n",
    "            toprint += f'ACC: {correct/total:.5} '\n",
    "            \n",
    "            print(toprint, end=f\"{' '*100}\\r\")\n",
    "            \n",
    "            pbar.update( len(y) )\n",
    "            del pred_docs, loss\n",
    "            del terms_idx, docs_offsets, y\n",
    "            del y_pred\n",
    "        loss_train = loss_train/(i+1)\n",
    "        print()\n",
    "        #print(ab.drop_)\n",
    "        total = 0\n",
    "        correct  = 0\n",
    "        ab.eval()\n",
    "        tokenizer.model = 'topk'\n",
    "        tokenizer.k = 512\n",
    "        with torch.no_grad():\n",
    "            loss_val = 0.\n",
    "            for i, (terms_idx, terms_frq, docs_offsets, y) in enumerate(dl_val):\n",
    "                terms_idx    = terms_idx.to( device )\n",
    "                docs_offsets = docs_offsets.to( device )\n",
    "                y            = y.to( device )\n",
    "                terms_frq = terms_frq.to( device )\n",
    "\n",
    "                pred_docs, weights, co_weights = ab( terms_idx, docs_offsets, terms_frq)\n",
    "                pred_docs   = torch.softmax(pred_docs, dim=1)\n",
    "\n",
    "                y_pred      = pred_docs.argmax(axis=1)\n",
    "                correct    += (y_pred == y).sum().item()\n",
    "                total      += len(y)\n",
    "                loss2       = loss_func_cel(pred_docs, y)\n",
    "                loss_val   += loss2\n",
    "\n",
    "                print(f'Val loss: {loss_val.item()/(i+1):.5} ACC: {correct/total:.5}', end=f\"{' '*100}\\r\")\n",
    "   \n",
    "                pbar.update( len(y) )\n",
    "            print()\n",
    "\n",
    "            del terms_idx, docs_offsets, y\n",
    "            del y_pred\n",
    "            \n",
    "            loss_val   = (loss_val/(i+1)).cpu()\n",
    "            scheduler.step(loss_val)\n",
    "\n",
    "            if best-loss_val > 0.0001 :\n",
    "                best = loss_val.item()\n",
    "                counter = 1\n",
    "                print(f'New Best Val loss: {best:.5}', end=f\"{' '*100}\\n\")\n",
    "                best_model = copy.deepcopy(ab).to('cpu')\n",
    "            elif counter > max_epochs:\n",
    "                print(f'Best Val loss: {best:.5}', end=f\"{' '*100}\\n\")\n",
    "                break\n",
    "            else:\n",
    "                counter += 1\n",
    "            del pred_docs, loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f311b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device_test = 'cpu'\n",
    "ab = copy.deepcopy(best_model).to(device_test)\n",
    "ab.eval()\n",
    "loss_total = 0\n",
    "correct_t = 0\n",
    "total_t = 0\n",
    "dl_test = DataLoader(list(zip(fold.X_test, y_test)), batch_size=128,\n",
    "                         shuffle=False, collate_fn=collate_train, num_workers=num_workers)\n",
    "tokenizer.k = 512\n",
    "for i, (terms_idx_t, terms_frq_t, docs_offsets_t, y_t) in enumerate(dl_test):\n",
    "    terms_idx_t    = terms_idx_t.to( device_test )\n",
    "    docs_offsets_t = docs_offsets_t.to( device_test )\n",
    "    terms_frq_t = terms_frq_t.to( device_test )\n",
    "    y_t            = y_t.to( device_test )\n",
    "\n",
    "    pred_docs_t,weigths,coweights = ab( terms_idx_t, docs_offsets_t, terms_frq_t )\n",
    "    sofmax_docs_t = torch.softmax(pred_docs_t, dim=1)\n",
    "\n",
    "    y_pred_t    = sofmax_docs_t.argmax(axis=1)\n",
    "    correct_t  += (y_pred_t == y_t).sum().item()\n",
    "    total_t    += len(y_t)\n",
    "    loss_total += loss_func_cel(sofmax_docs_t, y_t)\n",
    "\n",
    "    print(f'Test loss: {loss_total.item()/(i+1):.5} ACC: {correct_t/total_t:.5}', end=f\"{' '*100}\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73e593",
   "metadata": {},
   "outputs": [],
   "source": [
    "j           = [ terms_frq_t[ docs_offsets_t[i-1]:docs_offsets_t[i] ] for i in range(1, docs_offsets_t.shape[0]) ]\n",
    "j.append( terms_frq_t[ docs_offsets_t[-1]: ] )\n",
    "terms_frq   = pad_sequence(j, batch_first=True, padding_value=0)\n",
    "terms_frq   = torch.clamp(terms_frq, 0, ab.maxfreq-1)\n",
    "terms_frq_h = ab.freq_emb(terms_frq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177ca812",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_frq_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362066a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_frq_h.transpose(0,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3c35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat([terms_frq_h.transpose(0,2), terms_frq_h.transpose(0,2)]).transpose(0,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c4eea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
