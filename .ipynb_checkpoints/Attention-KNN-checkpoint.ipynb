{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from TGA.utils import Dataset\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from TGA.utils import preprocessor\n",
    "import copy\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "from itertools import repeat\n",
    "from collections import Counter\n",
    "from segtok import tokenizer as tk\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.7.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('X_train', 'y_train', 'X_test', 'y_test', 'X_val', 'y_val'), 10627)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset('/home/Documentos/datasets/classification/datasets/reut/')\n",
    "fold = next(dataset.get_fold_instances(10, with_val=True))\n",
    "fold._fields, len(fold.X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, mindf=2, stopwords='remove', model='list', lan='english', verbose=False):\n",
    "        super(Tokenizer, self).__init__()\n",
    "        self.mindf = mindf\n",
    "        self.le = LabelEncoder()\n",
    "        self.verbose = verbose\n",
    "        self.stopwords = stopwords\n",
    "        self.stopwordsSet = set(stop_words.ENGLISH_STOP_WORDS)\n",
    "        self.lan = lan\n",
    "        self.model = model\n",
    "        self.analyzer = TfidfVectorizer(preprocessor=preprocessor).build_analyzer()\n",
    "        #self.analyzer = tk.web_tokenizer\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.N = len(X)\n",
    "        self.le.fit( y )\n",
    "        self.n_class = len(self.le.classes_)\n",
    "\n",
    "        self.term_freqs = Counter()\n",
    "        docs = map(self.analyzer, X)\n",
    "        for doc_in_terms in tqdm(docs, total=self.N, disable=not self.verbose):\n",
    "            doc_in_terms = list(map( self._filter_fit_, doc_in_terms ))\n",
    "            self.term_freqs.update(list(set(doc_in_terms)))\n",
    "        self.node_mapper      = {'<BLANK>': 0}\n",
    "        self.term_freqs       = { term:v for (term,v) in self.term_freqs.items() if v >= self.mindf }    \n",
    "        self.node_mapper      = { term:self._get_idx_(term) for term in self.term_freqs.keys() if self._isrel_(term) }\n",
    "        self.node_mapper['<UNK>'] = len(self.node_mapper)\n",
    "        self.node_mapper['<BLANK>'] = 0\n",
    "        self.vocab_size = len(self.node_mapper)\n",
    "        \n",
    "        return self\n",
    "    def _isrel_(self, term):\n",
    "        if self.stopwords == 'remove' and term in self.stopwordsSet:\n",
    "            return False\n",
    "        # put here your filter_functions\n",
    "        return True\n",
    "    def _get_idx_(self, term):\n",
    "        # put here your idx_set_functions\n",
    "        if self.stopwords == 'mark' and term in self.stopwordsSet:\n",
    "            print('is stop', term)\n",
    "            return self.node_mapper.setdefault('<STPW>', len(self.node_mapper))\n",
    "        return self.node_mapper.setdefault(term, len(self.node_mapper))\n",
    "    def _filter_transform_(self, term):\n",
    "        if self.stopwords == 'mark' and term in self.stopwordsSet:\n",
    "            return '<STPW>'\n",
    "        if term not in self.node_mapper:\n",
    "            return '<UNK>'\n",
    "        return term\n",
    "    def _filter_fit_(self, term):\n",
    "        if self.stopwords == 'mark' and term in self.stopwordsSet:\n",
    "            return '<STPW>'\n",
    "        return term\n",
    "    def _model_(self, doc):\n",
    "        if self.model == 'set':\n",
    "            return set(doc)\n",
    "        return list(doc)\n",
    "    def transform(self, X, verbose=None):\n",
    "        verbose = verbose if verbose is not None else self.verbose\n",
    "        n = len(X)\n",
    "        doc_off = [0]\n",
    "        terms_idx = []\n",
    "        for i,doc_in_terms in tqdm(enumerate(map(self.analyzer, X)), total=n, disable=not verbose):\n",
    "            doc_in_terms = filter( self._isrel_, doc_in_terms )\n",
    "            doc_in_terms = map( self._filter_transform_, doc_in_terms )\n",
    "            doc_in_terms = self._model_(doc_in_terms)\n",
    "            doc_in_terms = [ self.node_mapper[tid] for tid in doc_in_terms ]\n",
    "            if self.model == 'sorted':\n",
    "                doc_in_terms = sorted(doc_in_terms)\n",
    "            doc_off.append( len(doc_in_terms) )\n",
    "            terms_idx.extend( doc_in_terms )\n",
    "        return np.array( terms_idx ), np.array(doc_off)[:-1].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8a48354cc364db6800ba075374b29be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10627.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tokenizer(mindf=1, model='set', stopwords='keep', verbose=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(mindf=1, stopwords='keep', model='set', verbose=True)\n",
    "tokenizer.fit(fold.X_train, fold.y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tokenizer.le.transform( fold.y_train )\n",
    "y_val   = tokenizer.le.transform( fold.y_val )\n",
    "y_test  = tokenizer.le.transform( fold.y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bc58c09276421f9d010f8ca86fd9d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  568, 13239,    73,    75,  1550,     7,    83,   692,  2783,\n",
       "          579,   300,  3358,  1914,  2871,   967,   100,  1813,   826,\n",
       "           23,   102,   696,  1558,   108,  1715,   110,   111,   590,\n",
       "          346,   115,  1975,   116,   594,   117,   118,  1661,  1164,\n",
       "          837,  3559,   122,  6624,    40,  3984,   842,   600,  1273,\n",
       "            9,    11, 17510,  5174,  1569,  2331,    14,  2301,   142,\n",
       "         1812, 10220,  2303,  6054,  6783,  1123,   848,   150,  2393,\n",
       "         1217,  1992,   155,  2895,   157,  3565,  1574,  4815,  2797,\n",
       "         5635,  3345,  3191,   386,  4418,  3755,  1223,  2176,   172,\n",
       "         1513,  5771, 25857, 18131,  2240,   183,   186,   404, 16547,\n",
       "         2245,  4605,   869,  3460,    20,   929,  1447,   875,   316,\n",
       "         1585,  6548,    33,   413,   207,  3390,  2314,  3362,    38,\n",
       "         1473,  1331,   218,   219,  5648,  1333,  3273,  2258,     1,\n",
       "         2068,   231,   533,  1242,  4365,   661,   302,   664,   240,\n",
       "          770,   434,   304,   669,  2260,  2437,  2072,   308,   254,\n",
       "         5596,   310,   801,  5836,  5095,  7858,  1600,   257,  1195,\n",
       "          259,    35,  5739,  1461,   263,  2664,   686,   271,    69,\n",
       "         3363,  3364,  4495,  1928,    41,   568,    79,  1305,  3595,\n",
       "         3596,   333,  3597,  1616,  3598,   110,   111,   115,   116,\n",
       "          117,   697,  3557,   348,   838,   842,   469,     2,   128,\n",
       "           50,  1067,     9,  1537,    11,   479,    14,   141,   363,\n",
       "         1386,  1072,  1217,   919,   154,  2514,  3599,   615,   157,\n",
       "          972,   620,  1441,  3600,   386,   923,  1008,  3601,   860,\n",
       "         3602,    15,   497,   404,   196,  3603,  2971,   929,   873,\n",
       "          202,  2315,   709,    38,  3604,   975,    39,   219,   882,\n",
       "         1292,  3605,     1,  2976,     4,  3606,  1811,   240,   432,\n",
       "          245,  3607,   940,    58,   254,  2458,   257,  3608,   263,\n",
       "           68,   810,   811,   323,  1076,    41]),\n",
       " array([  0, 158]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.transform(fold.X_val[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " '\\r cocoa consumers narrow gap on buffer stock issue\\r london march 16 representatives of cocoa consuming\\r countries at an international cocoa organization icco council\\r meeting here have edged closer to a unified stance on buffer\\r stock rules delegates said \\r while consumers do not yet have a common position an\\r observer said after a consumer meeting they are much more\\r fluid and the tone is positive \\r european community consumers were split on the question of\\r how the cocoa buffer stock should be operated when the icco met\\r in january to put the new international cocoa agreement into\\r effect delegates said \\r at the january meeting france sided with producers on how\\r the buffer stock should operate delegates said that meeting\\r ended without agreement on new buffer stock rules \\r the ec commission met in brussels on friday to see whether\\r the 12 ec cocoa consuming nations could narrow their\\r differences at this month s meeting \\r the commissioners came away from the friday meeting with an\\r informal agreement to respond to signs of flexibility among\\r producers on the key buffer stock issues delegates said \\r the key issues to be addressed at this council session\\r which divide icco members are whether non member cocoa should\\r be eligible for buffer stock purchases and what price\\r differentials the buffer stock should pay for different types\\r of cocoa delegates said \\r a consumer delegate said producers and consumers should be\\r able to compromise on the non member cocoa question \\r a working group comprising delegates from all producing and\\r consuming member countries met briefly this morning then broke\\r up into a producer meeting and an ec meeting followed by a\\r consumer meeting \\r producers who are in favour of the buffer stock buying a\\r variety of grades of cocoa and oppose non member cocoa being\\r accepted reviewed their position ahead of the working group\\r meeting this afternoon \\r we are waiting to see what consumers say a producer\\r delegate said we hope they will be flexible or it will be\\r difficult to negotiate \\r the icco comprises 33 member countries non \\r members include the u s a consumer and malaysia an\\r increasingly important producer \\r \\r \\n')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.node_mapper['<BLANK>'], fold.X_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_train(param):\n",
    "    X, y = zip(*param)\n",
    "    terms_ids, docs_offsets = tokenizer.transform(X, verbose=False)\n",
    "    return torch.LongTensor(terms_ids), torch.LongTensor(docs_offsets), torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mask(nn.Module):\n",
    "    def __init__(self, negative_slope=1000, kappa=2.):\n",
    "        super(Mask, self).__init__()\n",
    "        self.negative_slope = negative_slope\n",
    "        self.kappa = kappa\n",
    "        self.sig = nn.Sigmoid()\n",
    "    def forward(self, h):\n",
    "        w = F.leaky_relu( h, negative_slope=self.negative_slope)\n",
    "        w = self.sig(w-self.kappa)\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function embedding_bag:\n",
      "\n",
      "embedding_bag(...)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.embedding_bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAttentionBag(nn.Module):\n",
    "    def __init__(self, vocab_size, hiddens, nclass, drop=.5, initrange=.5, negative_slope=99.):\n",
    "        super(SimpleAttentionBag, self).__init__()\n",
    "        self.hiddens    = hiddens\n",
    "        self.dt_emb     = nn.Embedding(vocab_size, hiddens)\n",
    "        self.tt_emb     = nn.Embedding(vocab_size, hiddens)\n",
    "        self.tt_dir_map = nn.Linear(hiddens, hiddens)\n",
    "        self.fc         = nn.Linear(hiddens, nclass)\n",
    "        self.initrange  = initrange \n",
    "        self.negative_slope = negative_slope\n",
    "        self.drop       = nn.Dropout(drop)\n",
    "        self.self.drop_ = drop\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.init_weights()\n",
    "    def forward(self, terms_idx, docs_offsets, return_mask=False):\n",
    "        n = terms_idx.shape[0]\n",
    "        batch_size = docs_offsets.shape[0]\n",
    "        \n",
    "        k         = [ terms_idx[ docs_offsets[i-1]:docs_offsets[i] ] for i in range(1, batch_size) ]\n",
    "        k.append( terms_idx[ docs_offsets[-1]: ] )\n",
    "        x_packed  = pad_sequence(k, batch_first=True, padding_value=0)\n",
    "\n",
    "        bx_packed = x_packed == 0\n",
    "        doc_sizes = bx_packed.logical_not().sum(dim=1).view(batch_size, 1)\n",
    "        pad_mask  = bx_packed.logical_not()\n",
    "        pad_mask  = pad_mask.view(*bx_packed.shape, 1)\n",
    "        pad_mask  = pad_mask.logical_and(pad_mask.transpose(1, 2))\n",
    "        \n",
    "        dt_h     = self.dt_emb( x_packed )\n",
    "        dt_h     = F.dropout( dt_h, p=self.drop_, training=self.training )\n",
    "        #dt_h     = self.drop(dt_h)\n",
    "        \n",
    "        tt_h     = self.tt_emb( x_packed )\n",
    "        tt_h     = F.dropout( tt_h, p=self.drop_, training=self.training )\n",
    "        #tt_h     = self.drop(tt_h)\n",
    "        dir_tt_h = self.tt_dir_map( tt_h )\n",
    "\n",
    "        weights = torch.bmm( tt_h, dir_tt_h.transpose( 1, 2 ) )\n",
    "        weights = F.leaky_relu( weights, negative_slope=self.negative_slope)\n",
    "        \n",
    "        weights[pad_mask.logical_not()] = float('-inf') # Set the 3D-pad mask values to -inf (=0 in softmax)\n",
    "        weights = F.sigmoid(weights)\n",
    "        #weights = F.softmax(weights, dim=2) # Normalize the neighbors weights\n",
    "        #weights = torch.where(torch.isnan(weights), torch.zeros_like(weights), weights) #replace nan to zero\n",
    "        weights = weights.sum(axis=2) / doc_sizes\n",
    "        weights[bx_packed] = float('-inf') # Set the 2D-pad mask values to -inf  (=0 in softmax)\n",
    "        weights = F.softmax(weights, dim=1)\n",
    "        #weights = F.sigmoid(weights)\n",
    "        weights = weights.view( *weights.shape, 1 )\n",
    "        \n",
    "        docs_h = dt_h * weights\n",
    "        docs_h = docs_h.sum(axis=1)\n",
    "        docs_h = F.dropout( docs_h, p=self.drop_, training=self.training )\n",
    "        #docs_h = self.drop(docs_h)\n",
    "        return self.fc(docs_h), weights\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.dt_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.tt_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.tt_dir_map.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.fc.weight.data.uniform_(-self.initrange, self.initrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs = 1000\n",
    "max_epochs = 50\n",
    "drop=0.95\n",
    "device = torch.device('cuda:0')\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa4d8b86270>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc = SimpleClassifier(tokenizer.vocab_size, 300, tokenizer.n_class, dropout=drop).to( device )\n",
    "ab = SimpleAttentionBag(tokenizer.vocab_size, 300, tokenizer.n_class, drop=drop).to( device )\n",
    "\n",
    "optimizer = optim.AdamW( ab.parameters(), lr=6e-3, weight_decay=5e-3)\n",
    "loss_func_cel = nn.CrossEntropyLoss().to( device )\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=.95,\n",
    "                                                       patience=10, verbose=True)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=.98, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba59056dee004de98840985ad8bb4c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7630e9335b17407ca6dcabef722d4e45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 1', max=11977.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.4438/4.5093 ACC: 0.08102                                                                                                      \n",
      "Val loss: 4.2002 ACC: 0.32519                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.2002                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46dd3f64405e48f1be0c04ba67518db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 2', max=11977.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.2832/4.2443 ACC: 0.24795                                                                                                    \n",
      "Val loss: 4.1204 ACC: 0.42444                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.1204                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1fb3c0a229048bdb27e51c89d18dd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 3', max=11977.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.2123/4.1839 ACC: 0.31411                                                                                                    \n",
      "Val loss: 4.085 ACC: 0.44296                                                                                                                                                                                                         \n",
      "\n",
      "New Best Val loss: 4.085                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c10caf731f2d431b820c516ad9d070c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 4', max=11977.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.1823/3.9524 ACC: 0.34092                                                                                                    \n",
      "Val loss: 4.0717 ACC: 0.44889                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0717                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d4b51404de44179ad82de87a0ce7f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 5', max=11977.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.1717/4.2971 ACC: 0.35099                                                                                                    \n",
      "Val loss: 4.0711 ACC: 0.44593                                                                                                                                                                                                        \n",
      "\n",
      "New Best Val loss: 4.0711                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "801df55226dd4b53b69833f7fed822af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 6', max=11977.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.1554/4.514 ACC: 0.36652                                                                                                     \n",
      "Val loss: 4.0694 ACC: 0.44593                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0694                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8158c2a5ffa442f98f71a6f6a7914ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 7', max=11977.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.1417/3.8801 ACC: 0.37828                                                                                                    \n",
      "Val loss: 4.064 ACC: 0.45407                                                                                                     \n",
      "\n",
      "New Best Val loss: 4.064                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f04921b9685845f1bc5a3132b509fb34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 8', max=11977.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.1402/4.1465 ACC: 0.3812                                                                                                     \n",
      "Val loss: 4.06 ACC: 0.4563                                                                                                       \n",
      "\n",
      "New Best Val loss: 4.06                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67d4b111b684188b5d283b15c1ef0a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 9', max=11977.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.1312/3.7701 ACC: 0.38844                                                                                                    \n",
      "Val loss: 4.0554 ACC: 0.46296                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0554                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685750612c4043669215bc211413a778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 10', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.1266/4.1842 ACC: 0.39343                                                                                                    \n",
      "Val loss: 4.0502 ACC: 0.47037                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0502                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d741cc707574b34a1ca4a6979610d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 11', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.1233/3.8525 ACC: 0.39597                                                                                                    \n",
      "Val loss: 4.0483 ACC: 0.47111                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0483                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a8668cd14ac48cbb77185ab995f1878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 12', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.118/4.5186 ACC: 0.40303                                                                                                     \n",
      "Val loss: 4.0466 ACC: 0.47185                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0466                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f493362eda3149b3907dbd4618863e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 13', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.1092/3.8513 ACC: 0.40924                                                                                                    \n",
      "Val loss: 4.0386 ACC: 0.4837                                                                                                     \n",
      "\n",
      "New Best Val loss: 4.0386                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a91d27754284d38889fa047e0218dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 14', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.1125/4.1852 ACC: 0.40689                                                                                                    \n",
      "Val loss: 4.0307 ACC: 0.48963                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0307                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc756cb4ee24088b8b62f1f7768cbca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 15', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.1061/3.8498 ACC: 0.41188                                                                                                    \n",
      "Val loss: 4.0298 ACC: 0.48889                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0298                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d401df971164c38b6e3f05fa1d7de5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 16', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.1026/3.852 ACC: 0.41583                                                                                                     \n",
      "Val loss: 4.0309 ACC: 0.48963                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7303018e778453f848fcbbf8734f7e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 17', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.1057/4.5186 ACC: 0.41545                                                                                                    \n",
      "Val loss: 4.0296 ACC: 0.48815                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0296                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f2e0bfd7fa4303b34f38c47e2bd755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 18', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0962/3.5187 ACC: 0.42166                                                                                                    \n",
      "Val loss: 4.0273 ACC: 0.49259                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0273                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2bc385ba3b4015bb3ccef4fa4ce9d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 19', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.1017/4.2025 ACC: 0.41715                                                                                                    \n",
      "Val loss: 4.0262 ACC: 0.49333                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0262                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84b1282492834b64979ab2b396e01095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 20', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0973/4.1854 ACC: 0.42213                                                                                                    \n",
      "Val loss: 4.0248 ACC: 0.49333                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0248                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7df45b7fa994a14ab810a13c74cc422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 21', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0962/3.9235 ACC: 0.42279                                                                                                    \n",
      "Val loss: 4.024 ACC: 0.49333                                                                                                     \n",
      "\n",
      "New Best Val loss: 4.024                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "181f9002ea6247d481cf6627018a576d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 22', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0934/3.852 ACC: 0.42543                                                                                                     \n",
      "Val loss: 4.0227 ACC: 0.49556                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0227                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a4617ad6c04abe89250b18582d57a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 23', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0884/3.852 ACC: 0.43041                                                                                                     \n",
      "Val loss: 4.023 ACC: 0.49481                                                                                                     \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9caa44d1c304d4f80138b556987423c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 24', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0912/4.1851 ACC: 0.42919                                                                                                    \n",
      "Val loss: 4.0207 ACC: 0.49926                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0207                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b870ece7c6014d65ab0830bd9cd5332d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 25', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0854/3.8563 ACC: 0.4322                                                                                                     \n",
      "Val loss: 4.018 ACC: 0.50296                                                                                                     \n",
      "\n",
      "New Best Val loss: 4.018                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429a3f87f89e4f89ba16d69f6225da96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 26', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0878/3.8518 ACC: 0.42994                                                                                                    \n",
      "Val loss: 4.015 ACC: 0.50444                                                                                                     \n",
      "\n",
      "New Best Val loss: 4.015                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efe9f75149f14f308f43f5783be1baa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 27', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0874/4.1781 ACC: 0.43117                                                                                                    \n",
      "Val loss: 4.0148 ACC: 0.50593                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0148                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13c76a4751140528c029bc6b119f9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 28', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0849/3.5202 ACC: 0.4323                                                                                                     \n",
      "Val loss: 4.0155 ACC: 0.50444                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530aaf3e2e3445b5baaf997d6d264f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 29', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0841/3.8751 ACC: 0.43484                                                                                                    \n",
      "Val loss: 4.0147 ACC: 0.50519                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc7b8e6377d4ce3a39fdbf5fd656c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 30', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0833/4.1835 ACC: 0.43578                                                                                                    \n",
      "Val loss: 4.014 ACC: 0.50519                                                                                                     \n",
      "\n",
      "New Best Val loss: 4.014                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ea86cb797f450fa8d4224761877eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 31', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.083/4.1852 ACC: 0.43549                                                                                                     \n",
      "Val loss: 4.0143 ACC: 0.50519                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6cbfdc8fa24aae92092b25d502bef4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 32', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0877/4.1828 ACC: 0.43192                                                                                                    \n",
      "Val loss: 4.0127 ACC: 0.50667                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0127                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e60be79c18834e6f9bc1e1feeeb2245d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 33', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0794/4.1844 ACC: 0.4402                                                                                                     \n",
      "Val loss: 4.0133 ACC: 0.50519                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7723c4d7451a43c88a86581388a790c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 34', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0768/3.8504 ACC: 0.44189                                                                                                    \n",
      "Val loss: 4.0131 ACC: 0.50519                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a2862e6bb245989a409964aa275dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 35', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0751/4.1851 ACC: 0.44434                                                                                                    \n",
      "Val loss: 4.0125 ACC: 0.50593                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0125                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884968fa17154b97ac3e6bc86e37b621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 36', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.077/3.852 ACC: 0.44114                                                                                                      \n",
      "Val loss: 4.0127 ACC: 0.50519                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add95591f876419f834d9c6158209caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 37', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0785/4.0756 ACC: 0.44133                                                                                                    \n",
      "Val loss: 4.0108 ACC: 0.50815                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0108                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a12aede09694b7a9777575f72532174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 38', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.078/3.853 ACC: 0.44011                                                                                                      \n",
      "Val loss: 4.0105 ACC: 0.50815                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0105                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d0da46deb4b44deb43566461ecd3607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 39', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0743/4.5187 ACC: 0.44632                                                                                                    \n",
      "Val loss: 4.0099 ACC: 0.50963                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0099                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661a946269fe469c911fc80f939dce54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 40', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0715/4.1852 ACC: 0.44754                                                                                                    \n",
      "Val loss: 4.0098 ACC: 0.50963                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0098                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f2975975c643c488d591902691ee29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 41', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0778/4.5176 ACC: 0.44255                                                                                                    \n",
      "Val loss: 4.0099 ACC: 0.50963                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0823f781e94fbe943cda9db0a534b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 42', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0768/4.5176 ACC: 0.44312                                                                                                    \n",
      "Val loss: 4.009 ACC: 0.50963                                                                                                     \n",
      "\n",
      "New Best Val loss: 4.009                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf012284317458b9d959bda6fcb8968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 43', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0735/4.1854 ACC: 0.44603                                                                                                    \n",
      "Val loss: 4.0091 ACC: 0.50963                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37c654bbf4d4f618c3d6d3c0322ae5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 44', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0681/3.8498 ACC: 0.45074                                                                                                    \n",
      "Val loss: 4.0095 ACC: 0.50889                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9729e4a557304743bc6105a820479be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 45', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0692/3.8519 ACC: 0.4481                                                                                                     \n",
      "Val loss: 4.0086 ACC: 0.50963                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0086                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfad595ff06540bc80c114603689ef04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 46', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0687/4.5161 ACC: 0.4514                                                                                                     \n",
      "Val loss: 4.0086 ACC: 0.50963                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185adbaac3494bcbadd1732909155517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 47', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0678/4.4607 ACC: 0.45177                                                                                                    \n",
      "Val loss: 4.0088 ACC: 0.50963                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b0da1735cad438b8370faa228435fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 48', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0678/3.852 ACC: 0.45036                                                                                                     \n",
      "Val loss: 4.0089 ACC: 0.50963                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf9415a1317489e8846ade7cd61c035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 49', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0687/4.5187 ACC: 0.45149                                                                                                    \n",
      "Val loss: 4.0093 ACC: 0.50963                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52731a6b2e254ff49977efbfc8f82e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 50', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0699/4.5165 ACC: 0.45008                                                                                                    \n",
      "Val loss: 4.0083 ACC: 0.50963                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0083                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac16a73b55d24424a69316032c9cca06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 51', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0692/3.85 ACC: 0.44942                                                                                                      \n",
      "Val loss: 4.0094 ACC: 0.50963                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0af342437794c038342318349661521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 52', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0651/4.5187 ACC: 0.45516                                                                                                    \n",
      "Val loss: 4.0072 ACC: 0.51111                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0072                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "810e5c652d754301ba7f9ea6707d2f69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 53', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0693/3.8507 ACC: 0.44886                                                                                                    \n",
      "Val loss: 4.0082 ACC: 0.50963                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79ee02c908e4a87a6748bd8b436ba12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 54', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0672/4.1847 ACC: 0.45243                                                                                                    \n",
      "Val loss: 4.0077 ACC: 0.50963                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9433638629e4ceb800f3894d66fdd4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 55', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0641/3.5197 ACC: 0.45319                                                                                                    \n",
      "Val loss: 4.0074 ACC: 0.50963                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1a3eb283cc4da1b857663b855459d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 56', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0667/4.1854 ACC: 0.45206                                                                                                    \n",
      "Val loss: 4.0055 ACC: 0.51333                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0055                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeab0814a3074ea6813e6d8a427e1bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 57', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.068/4.1837 ACC: 0.45149                                                                                                     \n",
      "Val loss: 4.0046 ACC: 0.51407                                                                                                    \n",
      "\n",
      "New Best Val loss: 4.0046                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898bb96a271b49ed89c532bef9de5865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 58', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0637/3.5187 ACC: 0.45356                                                                                                    \n",
      "Val loss: 4.0047 ACC: 0.51407                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6361e7dfe61c42ed9c22474bb14820b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 59', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.062/4.1854 ACC: 0.45704                                                                                                     \n",
      "Val loss: 4.0047 ACC: 0.51481                                                                                                    \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f8bec0dd9d47d8a0efac7342f4b260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch 60', max=11977.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0677/4.0133 ACC: 0.45062                                                                                                    \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.0673/4.0168 ACC: 0.45099                                                                                                    \r",
      "Train loss: 4.0681/4.1744 ACC: 0.45019                                                                                                    \r\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3417, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-23-3a7ec1ab9dd0>\", line 23, in <module>\n",
      "    loss.backward()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/tensor.py\", line 221, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 130, in backward\n",
      "    Variable._execution_engine.run_backward(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.8/inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python3.8/posixpath.py\", line 391, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/lib/python3.8/posixpath.py\", line 411, in _joinrealpath\n",
      "    name, _, rest = rest.partition(sep)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-3a7ec1ab9dd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2046\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2047\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1433\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1436\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1336\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m             )\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1193\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "best = 99999.\n",
    "counter = 1\n",
    "dl_val = DataLoader(list(zip(fold.X_val, y_val)), batch_size=batch_size,\n",
    "                         shuffle=False, collate_fn=collate_train, num_workers=4)\n",
    "for e in tqdm(range(nepochs), total=nepochs):\n",
    "    dl_train = DataLoader(list(zip(fold.X_train, y_train)), batch_size=batch_size,\n",
    "                             shuffle=True, collate_fn=collate_train, num_workers=4)\n",
    "    total_loss  = 0.\n",
    "    with tqdm(total=len(y_train)+len(y_val), smoothing=0., desc=f\"Epoch {e+1}\") as pbar:\n",
    "        total = 0\n",
    "        correct  = 0\n",
    "        ab.train()\n",
    "        for i, (terms_idx, docs_offsets, y) in enumerate(dl_train):\n",
    "            terms_idx    = terms_idx.to( device )\n",
    "            docs_offsets = docs_offsets.to( device )\n",
    "            y            = y.to( device )\n",
    "            \n",
    "            pred_docs,_ = ab( terms_idx, docs_offsets)\n",
    "            pred_docs = F.softmax(pred_docs)\n",
    "            loss = loss_func_cel(pred_docs, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total      += len(y)\n",
    "            y_pred      = pred_docs.argmax(axis=1)\n",
    "            correct    += (y_pred == y).sum().item()\n",
    "            \n",
    "            toprint  = f\"Train loss: {total_loss/(i+1):.5}/{loss.item():.5} \"\n",
    "            toprint += f'ACC: {correct/total:.5}'\n",
    "            \n",
    "            print(toprint, end=f\"{' '*100}\\r\")\n",
    "            \n",
    "            pbar.update( len(y) )\n",
    "            del pred_docs, loss\n",
    "            del terms_idx, docs_offsets, y\n",
    "            del y_pred\n",
    "            \n",
    "        total = 0\n",
    "        correct  = 0\n",
    "        ab.eval()\n",
    "        with torch.no_grad():\n",
    "            loss_total = 0.\n",
    "            print()\n",
    "            for i, (terms_idx, docs_offsets, y) in enumerate(dl_val):\n",
    "                terms_idx    = terms_idx.to( device )\n",
    "                docs_offsets = docs_offsets.to( device )\n",
    "                y            = y.to( device )\n",
    "\n",
    "                pred_docs,weights = ab( terms_idx, docs_offsets )\n",
    "                pred_docs   = F.softmax(pred_docs)\n",
    "\n",
    "                y_pred      = pred_docs.argmax(axis=1)\n",
    "                correct    += (y_pred == y).sum().item()\n",
    "                total      += len(y)\n",
    "                loss2       = loss_func_cel(pred_docs, y)\n",
    "                loss_total += loss2\n",
    "\n",
    "                print(f'Val loss: {loss_total.item()/(i+1):.5} ACC: {correct/total:.5}', end=f\"{' '*100}\\r\")\n",
    "   \n",
    "                pbar.update( len(y) )\n",
    "\n",
    "            del terms_idx, docs_offsets, y\n",
    "            del y_pred\n",
    "            scheduler.step(loss_total)\n",
    "            print()\n",
    "            #scheduler.step()\n",
    "\n",
    "            if best-(loss_total/(i+1)) > 0.0001 :\n",
    "                best = (loss_total/(i+1)).item()\n",
    "                counter = 1\n",
    "                print()\n",
    "                print(f'New Best Val loss: {best:.5}', end=f\"{' '*100}\\n\")\n",
    "                best_model = copy.deepcopy(ab).to('cpu')\n",
    "            elif counter > max_epochs:\n",
    "                print()\n",
    "                print(f'Best Val loss: {best:.5}', end=f\"{' '*100}\\n\")\n",
    "                break\n",
    "            else:\n",
    "                counter += 1\n",
    "            del pred_docs, loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3.8242 ACC: 0.70963                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "ab = copy.deepcopy(best_model).to(device)\n",
    "loss_total = 0\n",
    "correct_t = 0\n",
    "total_t = 0\n",
    "dl_test = DataLoader(list(zip(fold.X_test, y_test)), batch_size=batch_size,\n",
    "                         shuffle=False, collate_fn=collate_train, num_workers=2)\n",
    "for i, (terms_idx_t, docs_offsets_t, y_t) in enumerate(dl_test):\n",
    "    terms_idx_t    = terms_idx_t.to( device )\n",
    "    docs_offsets_t = docs_offsets_t.to( device )\n",
    "    y_t            = y_t.to( device )\n",
    "\n",
    "    pred_docs_t,weigths = ab( terms_idx_t, docs_offsets_t )\n",
    "    pred_docs_t = F.softmax(pred_docs_t)\n",
    "\n",
    "    y_pred_t    = pred_docs_t.argmax(axis=1)\n",
    "    correct_t  += (y_pred_t == y_t).sum().item()\n",
    "    total_t    += len(y_t)\n",
    "    loss_total += loss_func_cel(pred_docs_t, y_t)\n",
    "\n",
    "print(f'Test loss: {loss_total.item()/(i+1):.5} ACC: {correct_t/total_t:.5}', end=f\"{' '*100}\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nacm ####################################################################################\\nTrain loss: 1.6009/1.6089 ACC: 0.94886                                                                                                    \\nVal loss: 1.7718 ACC: 0.77475                                                                                                    \\nNew Best Val loss: 1.7718                                                                                                    \\nTest loss: 1.7678 ACC: 0.78557  79.92\\n\\nTrain loss: 1.6915/1.5888 ACC: 0.85292                                                                                                    \\nVal loss: 1.7657 ACC: 0.78076                                                                                                    \\nAdjusting learning rate of group 0 to 5.5342e-03.\\nNew Best Val loss: 1.7657\\nTest loss: 1.7627 ACC: 0.78196                                                                                                    \\n\\n\\n20ng ####################################################################################\\nTrain loss: 2.0907/2.0787 ACC: 0.98845                                                                                                    \\nVal loss: 2.1869 ACC: 0.90803                                                                                                    \\nNew Best Val loss: 2.1869                                                                                                    \\nTest loss: 2.178 ACC: 0.91068   92.65\\n\\nreut ####################################################################################\\nTrain loss: 3.7735/3.5191 ACC: 0.74734                                                                                                    \\nVal loss: 3.8554 ACC: 0.6763                                                                                                    \\nNew Best Val loss: 3.8554                                                                                                    \\nTest loss: 3.8493 ACC: 0.6837  72.67\\n\\nTrain loss: 3.7489/3.8717 ACC: 0.77265                                                                                                    \\nVal loss: 3.8084 ACC: 0.71037                                                                                                    \\nAdjusting learning rate of group 0 to 5.1046e-03.\\nNew Best Val loss: 3.8084 \\n\\nwebkb ####################################################################################\\nTrain loss: 1.2228/1.2037 ACC: 0.9504                                                                                                     \\nVal loss: 1.3787 ACC: 0.80316                                                                                                    \\nNew Best Val loss: 1.3787                                                                                                    \\nTest loss: 1.3857 ACC: 0.78858   81.53\\n\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "acm ####################################################################################\n",
    "Train loss: 1.6009/1.6089 ACC: 0.94886                                                                                                    \n",
    "Val loss: 1.7718 ACC: 0.77475                                                                                                    \n",
    "New Best Val loss: 1.7718                                                                                                    \n",
    "Test loss: 1.7678 ACC: 0.78557  79.92\n",
    "\n",
    "Train loss: 1.6915/1.5888 ACC: 0.85292                                                                                                    \n",
    "Val loss: 1.7657 ACC: 0.78076                                                                                                    \n",
    "Adjusting learning rate of group 0 to 5.5342e-03.\n",
    "New Best Val loss: 1.7657\n",
    "Test loss: 1.7627 ACC: 0.78196                                                                                                    \n",
    "\n",
    "\n",
    "20ng ####################################################################################\n",
    "Train loss: 2.0907/2.0787 ACC: 0.98845                                                                                                    \n",
    "Val loss: 2.1869 ACC: 0.90803                                                                                                    \n",
    "New Best Val loss: 2.1869                                                                                                    \n",
    "Test loss: 2.178 ACC: 0.91068   92.65\n",
    "\n",
    "reut ####################################################################################\n",
    "Train loss: 3.7735/3.5191 ACC: 0.74734                                                                                                    \n",
    "Val loss: 3.8554 ACC: 0.6763                                                                                                    \n",
    "New Best Val loss: 3.8554                                                                                                    \n",
    "Test loss: 3.8493 ACC: 0.6837  72.67\n",
    "\n",
    "Train loss: 3.7489/3.8717 ACC: 0.77265                                                                                                    \n",
    "Val loss: 3.8084 ACC: 0.71037                                                                                                    \n",
    "Adjusting learning rate of group 0 to 5.1046e-03.\n",
    "New Best Val loss: 3.8084 \n",
    "\n",
    "webkb ####################################################################################\n",
    "Train loss: 1.2228/1.2037 ACC: 0.9504                                                                                                     \n",
    "Val loss: 1.3787 ACC: 0.80316                                                                                                    \n",
    "New Best Val loss: 1.3787                                                                                                    \n",
    "Test loss: 1.3857 ACC: 0.78858   81.53\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBag(nn.Module):\n",
    "    def __init__(self, vocab_size, hiddens, nclass, drop=.5, initrange=.5):\n",
    "        super(AttentionBag, self).__init__()\n",
    "        self.hiddens    = hiddens\n",
    "        self.mask       = Mask()\n",
    "        self.dt_emb     = nn.Embedding(vocab_size, hiddens)\n",
    "        self.dt_dir_map = nn.Linear(hiddens, hiddens)\n",
    "        self.drop       = nn.Dropout(drop)\n",
    "        self.ma_term    = nn.MultiheadAttention(hiddens, 1)\n",
    "        self.fc         = nn.Linear(hiddens, nclass)\n",
    "        self.initrange  = initrange \n",
    "        self.init_weights()\n",
    "    def forward(self, terms_idx, docs_offsets):\n",
    "        n = terms_idx.shape[0]\n",
    "        batch_size = docs_offsets.shape[0]\n",
    "        \n",
    "        k         = [ terms_idx[ docs_offsets[i-1]:docs_offsets[i] ] for i in range(1, batch_size) ]\n",
    "        k.append( terms_idx[ docs_offsets[-1]: ] )\n",
    "        x_packed  = pad_sequence(k, batch_first=True, padding_value=0)\n",
    "\n",
    "        bx_packed = x_packed == 0\n",
    "        pad_mask  = bx_packed.logical_not()\n",
    "        pad_mask  = pad_mask.view(*bx_packed.shape, 1)\n",
    "        pad_mask  = pad_mask.logical_and(pad_mask.transpose(1, 2))\n",
    "        \n",
    "        dt_h      = self.dt_emb( x_packed )\n",
    "        dt_h      = self.drop(dt_h)\n",
    "        dir_dt_h  = self.dt_dir_map( dt_h )\n",
    "\n",
    "        weights = torch.bmm( dt_h, dir_dt_h.transpose( 1, 2 ) )\n",
    "        weights = self.mask(weights)\n",
    "        \n",
    "        weights_disc = (weights * pad_mask)\n",
    "        weights_disc = weights_disc.sum(axis=1)\n",
    "        weights_disc = F.softmax(weights_disc, dim=1)\n",
    "        weights_disc = weights_disc.view( *weights_disc.shape, 1 )\n",
    "        \n",
    "        attn_mask = weights != 0\n",
    "        attn_mask = attn_mask.logical_and( pad_mask ).logical_not()\n",
    "        \n",
    "        dt_h     = dt_h.transpose(0,1)\n",
    "        dir_dt_h = dir_dt_h.transpose(0,1)\n",
    "        docs_att, weigths_att = self.ma_term( dt_h, dir_dt_h, dt_h,\n",
    "                                  key_padding_mask=bx_packed, \n",
    "                                  attn_mask=attn_mask )\n",
    "\n",
    "        weigths_att = torch.where(torch.isnan(weigths_att), torch.zeros_like(weigths_att), weigths_att)\n",
    "        weigths_att = (weigths_att * pad_mask)\n",
    "        weigths_att = weigths_att.sum(axis=1)\n",
    "        weigths_att = F.softmax(weigths_att, dim=1)\n",
    "        weigths_att = weigths_att.view( *weigths_att.shape, 1 )\n",
    "        \n",
    "        weigths = weights_disc + weigths_att\n",
    "\n",
    "        docs_att = docs_att.transpose(0,1)\n",
    "        docs_att = torch.where(torch.isnan(docs_att), torch.zeros_like(docs_att), docs_att)\n",
    "        \n",
    "        docs_h = docs_att * weigths\n",
    "        docs_h = docs_h.sum(axis=1)\n",
    "        docs_h = docs_h / bx_packed.logical_not().sum(dim=1).view(batch_size, 1)\n",
    "        docs_h = torch.where(torch.isnan(docs_h), torch.zeros_like(docs_h), docs_h)\n",
    "        docs_h = self.drop(docs_h)\n",
    "        return self.fc(docs_h)\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.dt_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.dt_dir_map.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.fc.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.ma_term.in_proj_weight.data.uniform_(-self.initrange, self.initrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_t      = pred_docs_t.argmax(axis=1)\n",
    "correct_t     = (y_pred_t == y_t).sum().item()\n",
    "total_t       = len(y_t)\n",
    "correct_t/total_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0, 331, 365, 522, 832, 974], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_offsets_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 32 is out of bounds for dimension 0 with size 6",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-6de26dbd6e30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mterms_idx_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdocs_offsets_t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 32 is out of bounds for dimension 0 with size 6"
     ]
    }
   ],
   "source": [
    "terms_idx_t[:docs_offsets_t[batch_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_off_test  = docs_offsets_t[batch_size]\n",
    "batch_tidx_test = terms_idx_t[:batch_off_test]\n",
    "h_terms_test    = sc.tt_emb( batch_tidx_test )\n",
    "dirh_terms_test = sc.tt_dir_map( h_terms_test )\n",
    "\n",
    "W = torch.matmul( h_terms_test, dirh_terms_test.T )\n",
    "W = F.leaky_relu( W, negative_slope=sc.mask.negative_slope)\n",
    "W = F.sigmoid(W)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [ batch_tidx_test[ docs_offsets_t[i-1]:docs_offsets_t[i] ] for i in range(1, batch_size) ]\n",
    "k.append( batch_tidx_test[ docs_offsets_t[batch_size-1]:docs_offsets_t[batch_size] ] )\n",
    "x_packed = pad_sequence(k, batch_first=True, padding_value=0)\n",
    "tt_emb = sc.tt_emb( x_packed )\n",
    "len(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_packed = pad_sequence(k, batch_first=True, padding_value=0)\n",
    "tt_emb = sc.tt_emb( x_packed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_emb.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [terms_idx, terms_idx]\n",
    "torch.stack(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "F.softmax(pred_docs_t).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_t == F.softmax(pred_docs_t).argmax(axis=1)).sum().item()/y_t.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_idx_t, docs_offsets_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts = sc._get_shift_(docs_offsets_t, terms_idx_t.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipado = zip(docs_offsets_t, shifts)\n",
    "#next(zipado)\n",
    "start,size = next(zipado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sc.tt_emb( terms_idx_t[start:start+size] )\n",
    "w1 = sc.tt_dir_map( w )\n",
    "w = torch.matmul( w, w1.T )\n",
    "w = F.leaky_relu( w, negative_slope=sc.negative_slope)\n",
    "w = F.sigmoid(w)\n",
    "#w = F.tanh(w)\n",
    "#w = F.relu(w)\n",
    "#w = w.mean(axis=1)\n",
    "#w = F.softmax(w)\n",
    "w,w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.round().sum() / (w.shape[0]*w.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_mapper = { v:k for (k,v) in tokenizer.node_mapper.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_idx[start:start+size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold.X_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = w.mean(axis=1)\n",
    "bla = F.softmax(bla)\n",
    "#bla = bla/torch.clamp(bla.sum(), 0.0001)\n",
    "bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ (i, tid.item(),inv_mapper[tid.item()], wei.item()) for i, (tid, wei) in enumerate(zip(terms_idx[start:start+size], bla)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = nn.BatchNorm1d(num_features=1).to(device)\n",
    "\n",
    "bla2 = norm(bla.view(-1, 1)).squeeze()\n",
    "bla2 = F.sigmoid(bla2)\n",
    "bla2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = nn.MultiheadAttention(300, 300).to(device)\n",
    "ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = w.shape\n",
    "w_ = w.view(a,1,b)\n",
    "w1_ = w1.view(a,1,b)\n",
    "\n",
    "attn_output = ma(w_, w1_, w_, need_weights=False)\n",
    "\n",
    "attn_output.view(a,b)\n",
    "attn_output_weights.view(a,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output.view(a,b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output_weights.view(a,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(torch.Tensor([[0.0718, 0.0716, 0.0712, 0.0714, 0.0721, 0.0710, 0.0712, 0.0714, 0.0710,\n",
    "         0.0719, 0.0711, 0.0712, 0.0718, 0.0714],\n",
    "        [0.0722, 0.0709, 0.0710, 0.0709, 0.0728, 0.0723, 0.0709, 0.0709, 0.0719,\n",
    "         0.0712, 0.0709, 0.0707, 0.0725, 0.0707],\n",
    "        [0.0711, 0.0715, 0.0710, 0.0713, 0.0710, 0.0712, 0.0718, 0.0713, 0.0709,\n",
    "         0.0725, 0.0716, 0.0719, 0.0710, 0.0719],\n",
    "        [0.0721, 0.0717, 0.0714, 0.0713, 0.0717, 0.0714, 0.0711, 0.0710, 0.0713,\n",
    "         0.0717, 0.0710, 0.0712, 0.0720, 0.0711],\n",
    "        [0.0722, 0.0711, 0.0710, 0.0710, 0.0737, 0.0716, 0.0709, 0.0705, 0.0714,\n",
    "         0.0719, 0.0707, 0.0707, 0.0731, 0.0702],\n",
    "        [0.0714, 0.0716, 0.0708, 0.0711, 0.0718, 0.0713, 0.0712, 0.0717, 0.0712,\n",
    "         0.0724, 0.0713, 0.0712, 0.0716, 0.0714],\n",
    "        [0.0712, 0.0714, 0.0713, 0.0713, 0.0722, 0.0716, 0.0709, 0.0714, 0.0714,\n",
    "         0.0717, 0.0713, 0.0713, 0.0716, 0.0713],\n",
    "        [0.0716, 0.0707, 0.0712, 0.0714, 0.0717, 0.0715, 0.0714, 0.0715, 0.0712,\n",
    "         0.0721, 0.0711, 0.0714, 0.0717, 0.0715],\n",
    "        [0.0717, 0.0713, 0.0708, 0.0710, 0.0725, 0.0717, 0.0714, 0.0709, 0.0712,\n",
    "         0.0712, 0.0712, 0.0717, 0.0720, 0.0714],\n",
    "        [0.0709, 0.0712, 0.0713, 0.0712, 0.0713, 0.0713, 0.0714, 0.0719, 0.0712,\n",
    "         0.0724, 0.0715, 0.0715, 0.0717, 0.0713],\n",
    "        [0.0715, 0.0716, 0.0712, 0.0708, 0.0725, 0.0717, 0.0712, 0.0714, 0.0714,\n",
    "         0.0717, 0.0713, 0.0706, 0.0718, 0.0712],\n",
    "        [0.0726, 0.0711, 0.0713, 0.0706, 0.0737, 0.0721, 0.0709, 0.0707, 0.0714,\n",
    "         0.0708, 0.0706, 0.0705, 0.0730, 0.0707],\n",
    "        [0.0718, 0.0711, 0.0714, 0.0715, 0.0725, 0.0707, 0.0707, 0.0711, 0.0712,\n",
    "         0.0728, 0.0711, 0.0713, 0.0719, 0.0709],\n",
    "        [0.0712, 0.0716, 0.0713, 0.0712, 0.0717, 0.0707, 0.0708, 0.0721, 0.0709,\n",
    "         0.0728, 0.0713, 0.0716, 0.0711, 0.0715]]).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotTooSimpleClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_l, nclass, dropout1=0.1, dropout2=0.1, negative_slope=99,\n",
    "                 initrange = 0.5, scale_grad_by_freq=False, device='cuda:0'):\n",
    "        super(NotTooSimpleClassifier, self).__init__()\n",
    "        \n",
    "        self.dt_emb = nn.Embedding(vocab_size, hidden_l, scale_grad_by_freq=scale_grad_by_freq)\n",
    "        self.tt_emb = nn.Embedding(vocab_size, hidden_l, scale_grad_by_freq=scale_grad_by_freq)\n",
    "        \n",
    "        self.undirected_map = nn.Linear(hidden_l, hidden_l)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_l, nclass)\n",
    "        self.drop1 = nn.Dropout(dropout1)\n",
    "        self.drop2 = nn.Dropout(dropout2)\n",
    "        \n",
    "        self.norm = nn.BatchNorm1d(1)\n",
    "        \n",
    "        self.initrange = initrange\n",
    "        self.nclass = nclass\n",
    "        self.negative_slope = negative_slope\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "        #self.labls_emb = nn.Embedding(graph_builder.n_class, 300)\n",
    "    \n",
    "    def forward(self, terms_idxs, docs_offsets):\n",
    "        n = terms_idxs.shape[0]\n",
    "        weights = []\n",
    "        shifts = self._get_shift_(docs_offsets, n)\n",
    "        \n",
    "        terms_h1 = self.tt_emb(terms_idxs)\n",
    "        terms_h1 = self.drop1(terms_h1)\n",
    "        \n",
    "        terms_h2 = self.undirected_map( terms_h1 )\n",
    "        #terms_h2 = self.drop1( terms_h2 )\n",
    "        for start,size in zip(docs_offsets, shifts):\n",
    "            w  = terms_h1[start:start+size]\n",
    "            w1 = terms_h2[start:start+size]\n",
    "            w = torch.matmul( w, w1.T )\n",
    "            w = F.leaky_relu( w, negative_slope=self.negative_slope)\n",
    "            w = F.sigmoid(w-5.5)\n",
    "            w = w.mean(axis=1)\n",
    "            w = F.softmax(w)\n",
    "            #w = w / torch.clamp(w.sum(), 0.0001)\n",
    "            weights.append( w )\n",
    "        \n",
    "        weights = torch.cat(weights)\n",
    "        #weights = self.norm(weights.view(-1, 1)).squeeze()\n",
    "        #weights = F.sigmoid(weights)\n",
    "        \n",
    "        h_docs  = F.embedding_bag(self.dt_emb.weight, terms_idxs, docs_offsets, per_sample_weights=weights, mode='sum')\n",
    "        h_docs = self.drop2( h_docs )\n",
    "        pred_docs = self.fc( h_docs )\n",
    "        return pred_docs\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.dt_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.tt_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        \n",
    "    def _get_shift_(self, offsets, lenght):\n",
    "        shifts = offsets[1:] - offsets[:-1]\n",
    "        last = torch.LongTensor([lenght - offsets[-1]]).to( offsets.device )\n",
    "        return torch.cat([shifts, last])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
