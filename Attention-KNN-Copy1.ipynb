{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from TGA.utils import Dataset, Tokenizer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('X_train', 'y_train', 'X_test', 'y_test', 'X_val', 'y_val'), 15062)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset('/home/datasets/20ng/')\n",
    "fold = next(dataset.get_fold_instances(10, with_val=True))\n",
    "fold._fields, len(fold.X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15062/15062 [00:09<00:00, 1547.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99011, 15062)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(mindf=1, stopwords='keep', model='sample', k=128, verbose=True)\n",
    "tokenizer.fit(fold.X_train, fold.y_train)\n",
    "tokenizer.vocab_size, tokenizer.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tokenizer.le.transform( fold.y_train )\n",
    "y_val   = tokenizer.le.transform( fold.y_val )\n",
    "y_test  = tokenizer.le.transform( fold.y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_train(param):\n",
    "    X, y = zip(*param)\n",
    "    terms_ids, docs_offsets = tokenizer.transform(X, verbose=False)\n",
    "    return torch.LongTensor(terms_ids), torch.LongTensor(docs_offsets), torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mask(nn.Module):\n",
    "    def __init__(self, negative_slope=1000, kappa=2.):\n",
    "        super(Mask, self).__init__()\n",
    "        self.negative_slope = negative_slope\n",
    "        self.kappa = kappa\n",
    "        self.sig = nn.Sigmoid()\n",
    "    def forward(self, h):\n",
    "        w = F.leaky_relu( h, negative_slope=self.negative_slope)\n",
    "        w = self.sig(w-self.kappa)\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAttentionBag(nn.Module):\n",
    "    def __init__(self, vocab_size, hiddens, nclass, drop=.5, initrange=.5, negative_slope=99.):\n",
    "        super(SimpleAttentionBag, self).__init__()\n",
    "        self.hiddens        = hiddens\n",
    "        self.dt_emb         = nn.Embedding(vocab_size, hiddens)\n",
    "        self.tt_s_emb       = nn.Embedding(vocab_size, hiddens)\n",
    "        self.tt_t_emb       = nn.Embedding(vocab_size, hiddens)\n",
    "        self.fc             = nn.Linear(hiddens, nclass)\n",
    "        #self.fc             = nn.Sequential(\n",
    "        #    nn.Linear(hiddens, hiddens),\n",
    "        #    nn.Sigmoid(),\n",
    "        #    nn.Linear(hiddens, nclass)\n",
    "        #)\n",
    "        self.initrange      = initrange \n",
    "        self.negative_slope = negative_slope\n",
    "        self.drop           = nn.Dropout(drop)\n",
    "        self.norm           = nn.BatchNorm1d(hiddens)\n",
    "        self.drop_          = drop\n",
    "        self.sig            = nn.Sigmoid()\n",
    "        self.init_weights()\n",
    "    def forward(self, terms_idx, docs_offsets, return_mask=False):\n",
    "        n = terms_idx.shape[0]\n",
    "        batch_size = docs_offsets.shape[0]\n",
    "        \n",
    "        k         = [ terms_idx[ docs_offsets[i-1]:docs_offsets[i] ] for i in range(1, batch_size) ]\n",
    "        k.append( terms_idx[ docs_offsets[-1]: ] )\n",
    "        x_packed  = pad_sequence(k, batch_first=True, padding_value=0)\n",
    "\n",
    "        bx_packed = x_packed == 0\n",
    "        doc_sizes = bx_packed.logical_not().sum(dim=1).view(batch_size, 1)\n",
    "        pad_mask  = bx_packed.logical_not()\n",
    "        pad_mask  = pad_mask.view(*bx_packed.shape, 1)\n",
    "        pad_mask  = pad_mask.logical_and(pad_mask.transpose(1, 2))\n",
    "        \n",
    "        dt_h     = self.dt_emb( x_packed )\n",
    "        dt_h     = (bx_packed.logical_not().view(*bx_packed.shape, 1) * dt_h)\n",
    "        dt_h     = F.dropout( dt_h, p=self.drop_, training=self.training )\n",
    "        \n",
    "        tt_h     = self.tt_s_emb( x_packed )\n",
    "        #tt_dir_h = tt_h\n",
    "        tt_dir_h = self.tt_t_emb( x_packed )\n",
    "        \n",
    "        tt_h = F.tanh(tt_h)\n",
    "        tt_h = F.dropout( tt_h, p=self.drop_, training=self.training )\n",
    "        \n",
    "        tt_dir_h = self.norm(tt_dir_h.transpose( 1, 2 )).transpose( 1, 2 )\n",
    "        tt_dir_h = F.tanh(tt_dir_h)\n",
    "        tt_dir_h = F.dropout( tt_dir_h, p=self.drop_, training=self.training )\n",
    "        \n",
    "        co_weights = torch.bmm( tt_h, tt_dir_h.transpose( 1, 2 ) )\n",
    "        co_weights = F.leaky_relu( co_weights, negative_slope=self.negative_slope)\n",
    "        \n",
    "        co_weights[pad_mask.logical_not()] = float('-inf') # Set the 3D-pad mask values to -inf (=0 in sigmoid)\n",
    "        co_weights = F.sigmoid(co_weights)\n",
    "        \n",
    "        weights = co_weights.sum(axis=2) / doc_sizes\n",
    "        weights[bx_packed] = float('-inf') # Set the 2D-pad mask values to -inf  (=0 in softmax)\n",
    "        #weights[weights<.5] = float('-inf') # Set the 2D-pad mask values to -inf  (=0 in softmax)\n",
    "        weights = F.softmax(weights, dim=1)\n",
    "        weights = torch.where(torch.isnan(weights), torch.zeros_like(weights), weights)\n",
    "        weights = weights.view( *weights.shape, 1 )\n",
    "        \n",
    "        docs_h = dt_h * weights\n",
    "        docs_h = docs_h.sum(axis=1)\n",
    "        docs_h = F.dropout( docs_h, p=self.drop_, training=self.training )\n",
    "        docs_h = self.fc(docs_h)\n",
    "        return docs_h, weights, co_weights\n",
    "    \n",
    "    \"\"\"\n",
    "    target_h = target_h.sum(axis=1) / doc_sizes\n",
    "    target_h = target_h.view(*target_h.shape, 1).transpose(1,2)\n",
    "    target_h = self.tt_target_map( target_h )\n",
    "    target_h = (target_h - (dt_h/doc_sizes.view(*doc_sizes.shape, 1)))\n",
    "    target_h = target_h * F.tanh(self.norm(target_h.transpose( 1, 2 )).transpose( 1, 2 ))\n",
    "    target_h = F.dropout( target_h, p=self.drop_, training=self.training )\n",
    "        \"\"\"\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.dt_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.tt_s_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.tt_t_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        #self.fc.weight.data.uniform_(-self.initrange, self.initrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs = 1000\n",
    "max_epochs = 20\n",
    "drop=0.75\n",
    "max_drop=0.75\n",
    "device = torch.device('cuda:0')\n",
    "batch_size = 64\n",
    "k = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fcb20b78db0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc = SimpleClassifier(tokenizer.vocab_size, 300, tokenizer.n_class, dropout=drop).to( device )\n",
    "ab = SimpleAttentionBag(tokenizer.vocab_size, 300, tokenizer.n_class, drop=drop).to( device )\n",
    "#ab = AttentionBag(tokenizer.vocab_size, 300, tokenizer.n_class, drop=drop).to( device )\n",
    "#ab = NotTooSimpleClassifier(tokenizer.vocab_size, 300, tokenizer.n_class, dropout1=drop, dropout2=drop).to( device )\n",
    "tokenizer.k = k\n",
    "optimizer = optim.AdamW( ab.parameters(), lr=5e-3, weight_decay=5e-3)\n",
    "loss_func_cel = nn.CrossEntropyLoss().to( device )\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=.95,\n",
    "                                                       patience=5, verbose=True)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=.98, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_workers=16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16863f0a57e94be5811035899f939f61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164bb29847f84744b5368b84bec268d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.6564/2.348 Drop: 0.43351 ACC: 0.57801                                                                                                        \n",
      "Val loss: 2.3223 ACC: 0.83721                                                                                                    \n",
      "New Best Val loss: 2.3223                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d17701fd850643b9a1830d2cbed7d4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.2661/2.2662 Drop: 0.64444 ACC: 0.85925                                                                                                     \n",
      "Val loss: 2.2632 ACC: 0.85254                                                                                                    \n",
      "New Best Val loss: 2.2632                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef114c89ab2c4d6b9350693a6e4904c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.2186/2.2361 Drop: 0.66341 ACC: 0.88454                                                                                                     \n",
      "Val loss: 2.2418 ACC: 0.86416                                                                                                    \n",
      "New Best Val loss: 2.2418                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ef8554b9954c37a5030b28d3198320",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1889/2.18 Drop: 0.68432 ACC: 0.91243                                                                                                       \n",
      "Val loss: 2.2257 ACC: 0.87315                                                                                                    \n",
      "New Best Val loss: 2.2257                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad7e1034d184c178a1a817356461103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1691/2.1725 Drop: 0.69513 ACC: 0.92684                                                                                                     \n",
      "Val loss: 2.2152 ACC: 0.88108                                                                                                    \n",
      "New Best Val loss: 2.2152                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939b940a83394bba876491ad08361de7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1549/2.1602 Drop: 0.70255 ACC: 0.93673                                                                                                     \n",
      "Val loss: 2.2097 ACC: 0.88901                                                                                                    \n",
      "New Best Val loss: 2.2097                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d34e5ef29040edb389e4f79e80a1e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1469/2.1662 Drop: 0.70832 ACC: 0.94443                                                                                                     \n",
      "Val loss: 2.2068 ACC: 0.88953                                                                                                    \n",
      "New Best Val loss: 2.2068                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116eb0124a504368ae198c926ac6b450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1392/2.0985 Drop: 0.71246 ACC: 0.94994                                                                                                     \n",
      "Val loss: 2.2036 ACC: 0.89059                                                                                                    \n",
      "New Best Val loss: 2.2036                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2fea52b2ae8447ca19b9f1e80211d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1331/2.1279 Drop: 0.71599 ACC: 0.95465                                                                                                     \n",
      "Val loss: 2.2 ACC: 0.89376                                                                                                       \n",
      "New Best Val loss: 2.2                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97abc33e3b0049a6a05b5b5ac7af0510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1286/2.1272 Drop: 0.71848 ACC: 0.95797                                                                                                     \n",
      "Val loss: 2.1969 ACC: 0.89693                                                                                                    \n",
      "New Best Val loss: 2.1969                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07b3e54989643ef91c29c4755eba0f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1245/2.1372 Drop: 0.72122 ACC: 0.96163                                                                                                     \n",
      "Val loss: 2.1952 ACC: 0.89746                                                                                                    \n",
      "New Best Val loss: 2.1952                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2db5b36b8e940c3a83a074b3e710146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1199/2.1295 Drop: 0.72416 ACC: 0.96554                                                                                                     \n",
      "Val loss: 2.1946 ACC: 0.89693                                                                                                    \n",
      "New Best Val loss: 2.1946                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1442706f7886412a872c72ffa9dfa0b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1185/2.1264 Drop: 0.72456 ACC: 0.96607                                                                                                     \n",
      "Val loss: 2.193 ACC: 0.89958                                                                                                     \n",
      "New Best Val loss: 2.193                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27baa48d971f4601909725f1f4f65aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.116/2.079 Drop: 0.72575 ACC: 0.96767                                                                                                       \n",
      "Val loss: 2.1932 ACC: 0.89746                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "494007565ad541a8aae8113a72db5cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1138/2.0786 Drop: 0.7268 ACC: 0.96906                                                                                                      \n",
      "Val loss: 2.193 ACC: 0.89535                                                                                                     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd22dd3c548464098a5100e8cf7a4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1132/2.1441 Drop: 0.72695 ACC: 0.96926                                                                                                     \n",
      "Val loss: 2.1922 ACC: 0.89641                                                                                                    \n",
      "New Best Val loss: 2.1922                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6c95e543bf64b7c8d1fc5ffc83ee7dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1114/2.0799 Drop: 0.72824 ACC: 0.97099                                                                                                     \n",
      "Val loss: 2.1906 ACC: 0.89905                                                                                                    \n",
      "New Best Val loss: 2.1906                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d287778be6c403083f70b3a87b92685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1099/2.0789 Drop: 0.72924 ACC: 0.97231                                                                                                     \n",
      "Val loss: 2.1891 ACC: 0.89958                                                                                                    \n",
      "New Best Val loss: 2.1891                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b538bd3e10f849f3854d54b4c00d4aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1079/2.0842 Drop: 0.73058 ACC: 0.97411                                                                                                     \n",
      "Val loss: 2.188 ACC: 0.90275                                                                                                     \n",
      "New Best Val loss: 2.188                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9053db7f3f164d79b624263a7f167382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1067/2.1323 Drop: 0.73128 ACC: 0.97504                                                                                                     \n",
      "Val loss: 2.1878 ACC: 0.90169                                                                                                    \n",
      "New Best Val loss: 2.1878                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b4f43e86f842efa7f82159cc0538b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1051/2.1184 Drop: 0.73222 ACC: 0.9763                                                                                                      \n",
      "Val loss: 2.1877 ACC: 0.90275                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3fa86468a214986ab4a22bbbac4a07c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1047/2.0866 Drop: 0.73237 ACC: 0.9765                                                                                                      \n",
      "Val loss: 2.1877 ACC: 0.90222                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0a2629f0073412cb9e3fac5ed04cfc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1028/2.1037 Drop: 0.73402 ACC: 0.97869                                                                                                     \n",
      "Val loss: 2.1871 ACC: 0.90328                                                                                                    \n",
      "New Best Val loss: 2.1871                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa4a8fb49371459b96ce3bdc39adabb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1028/2.1241 Drop: 0.73387 ACC: 0.97849                                                                                                     \n",
      "Val loss: 2.1871 ACC: 0.90222                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "144e0fb4688e4d829a5d659c6fddc118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1021/2.0787 Drop: 0.73466 ACC: 0.97955                                                                                                     \n",
      "Val loss: 2.1861 ACC: 0.90381                                                                                                    \n",
      "New Best Val loss: 2.1861                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddf7e61200d845b494aad50df73f1d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1025/2.1242 Drop: 0.73382 ACC: 0.97842                                                                                                     \n",
      "Val loss: 2.1859 ACC: 0.90116                                                                                                    \n",
      "New Best Val loss: 2.1859                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99866c265f024a9a8de97c7be0d825f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1009/2.0789 Drop: 0.73476 ACC: 0.97968                                                                                                     \n",
      "Val loss: 2.1852 ACC: 0.90063                                                                                                    \n",
      "New Best Val loss: 2.1852                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6ce472cc9be45678949fe81bc9dcbfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1012/2.0817 Drop: 0.73431 ACC: 0.97909                                                                                                     \n",
      "Val loss: 2.1844 ACC: 0.90539                                                                                                    \n",
      "New Best Val loss: 2.1844                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e30f65ca9994ce1a8354ce05fca462b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0991/2.079 Drop: 0.73616 ACC: 0.98154                                                                                                      \n",
      "Val loss: 2.1845 ACC: 0.90275                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df6380f4670440068c19f51df0ad2c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1002/2.1353 Drop: 0.73536 ACC: 0.98048                                                                                                     \n",
      "Val loss: 2.1845 ACC: 0.90116                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe30c2deabf04a1993b0c9f966244a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0988/2.0803 Drop: 0.73646 ACC: 0.98194                                                                                                     \n",
      "Val loss: 2.1844 ACC: 0.90011                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1320f6e7c5c44a980a9d871b7cb8944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.099/2.1251 Drop: 0.73636 ACC: 0.98181                                                                                                      \n",
      "Val loss: 2.1847 ACC: 0.90169                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd7176397f54f1e80e857b1407f3662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0986/2.1278 Drop: 0.73651 ACC: 0.98201                                                                                                     \n",
      "Val loss: 2.1844 ACC: 0.90222                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9878658efaa4d6fb596c17bcadc8502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0979/2.0794 Drop: 0.73675 ACC: 0.98234                                                                                                     \n",
      "Val loss: 2.1832 ACC: 0.90275                                                                                                    \n",
      "New Best Val loss: 2.1832                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3741200e4620412780223e0f4a98e680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0982/2.1236 Drop: 0.73675 ACC: 0.98234                                                                                                     \n",
      "Val loss: 2.1832 ACC: 0.90275                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00c8e7f639b4daf9dcba1d57a6e25c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0968/2.1653 Drop: 0.7381 ACC: 0.98413                                                                                                      \n",
      "Val loss: 2.1831 ACC: 0.90433                                                                                                    \n",
      "New Best Val loss: 2.1831                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6461b351994a0c8be2035fc14e7e6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0957/2.0782 Drop: 0.7384 ACC: 0.98453                                                                                                      \n",
      "Val loss: 2.1837 ACC: 0.90222                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bea950b32e84a3988ee155712d04a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0965/2.1421 Drop: 0.73805 ACC: 0.98407                                                                                                     \n",
      "Val loss: 2.1828 ACC: 0.90328                                                                                                    \n",
      "New Best Val loss: 2.1828                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "154506014cdb49f89f9df8fa263b3fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0955/2.0789 Drop: 0.7383 ACC: 0.9844                                                                                                       \n",
      "Val loss: 2.1829 ACC: 0.90381                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222cf2561cb544d89aa3eb5cdc076fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0951/2.1641 Drop: 0.7388 ACC: 0.98506                                                                                                      \n",
      "Val loss: 2.1833 ACC: 0.90486                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f24069b0a24b49b5cefb40b9ead009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0959/2.1522 Drop: 0.7382 ACC: 0.98427                                                                                                      \n",
      "Val loss: 2.183 ACC: 0.90433                                                                                                     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8d10d68b474144adf81bb1270f6dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0955/2.1207 Drop: 0.73815 ACC: 0.9842                                                                                                      \n",
      "Val loss: 2.1831 ACC: 0.90486                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2d353fd67ad4872b0b5381331fb288c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0952/2.0782 Drop: 0.73825 ACC: 0.98433                                                                                                     \n",
      "Val loss: 2.1825 ACC: 0.90592                                                                                                    \n",
      "New Best Val loss: 2.1825                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782d70c1222b4525b4d89e4799f3c570",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.094/2.0786 Drop: 0.73929 ACC: 0.98573                                                                                                      \n",
      "Val loss: 2.183 ACC: 0.90275                                                                                                     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7bc3fbc4a794e53addf9bfd13c02098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0945/2.1266 Drop: 0.73905 ACC: 0.98539                                                                                                     \n",
      "Val loss: 2.1823 ACC: 0.90486                                                                                                    \n",
      "New Best Val loss: 2.1823                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1058d4cdd24d0c873d8d8044127996",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.094/2.0783 Drop: 0.73949 ACC: 0.98599                                                                                                      \n",
      "Val loss: 2.1835 ACC: 0.90328                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763123967b0a409da984fe9817cb8b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0939/2.0797 Drop: 0.73924 ACC: 0.98566                                                                                                     \n",
      "Val loss: 2.1829 ACC: 0.90433                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98ac8940e9bb4c329c15e122f181f5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0932/2.0808 Drop: 0.73994 ACC: 0.98659                                                                                                     \n",
      "Val loss: 2.1818 ACC: 0.90539                                                                                                    \n",
      "New Best Val loss: 2.1818                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e17d80371e4f59b7355243dfbed8f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0935/2.0786 Drop: 0.73929 ACC: 0.98573                                                                                                     \n",
      "Val loss: 2.1816 ACC: 0.90433                                                                                                    \n",
      "New Best Val loss: 2.1816                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2988666d43fc4047806d524290b73ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0935/2.0783 Drop: 0.73959 ACC: 0.98612                                                                                                     \n",
      "Val loss: 2.1819 ACC: 0.90486                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f205d1a8c8744eeca5fd3fea41ff3106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 51:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0932/2.0782 Drop: 0.73964 ACC: 0.98619                                                                                                     \n",
      "Val loss: 2.1827 ACC: 0.90222                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae586ee370454395a3d59be72bf417f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 52:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0928/2.0941 Drop: 0.73984 ACC: 0.98646                                                                                                     \n",
      "Val loss: 2.182 ACC: 0.90381                                                                                                     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f815454467824c429087383582b25186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 53:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0925/2.0782 Drop: 0.73999 ACC: 0.98666                                                                                                     \n",
      "Val loss: 2.182 ACC: 0.90381                                                                                                     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a46d3009204656920452e508f7cc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 54:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0931/2.1204 Drop: 0.73974 ACC: 0.98632                                                                                                     \n",
      "Val loss: 2.1819 ACC: 0.90592                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a2b85257514badb903b1043619f28d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 55:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.093/2.0782 Drop: 0.73994 ACC: 0.98659                                                                                                      \n",
      "Val loss: 2.1824 ACC: 0.90381                                                                                                    \n",
      "Epoch    55: reducing learning rate of group 0 to 4.7500e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66abc636cb344c394b0a240c8fa6a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 56:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0915/2.1194 Drop: 0.74114 ACC: 0.98818                                                                                                     \n",
      "Val loss: 2.1823 ACC: 0.90328                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0d9be91fcbd49cc8f0ed3ebc9f86b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 57:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0913/2.0786 Drop: 0.74134 ACC: 0.98845                                                                                                     \n",
      "Val loss: 2.1825 ACC: 0.90486                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa53ef0959884e4d8c633c0acc7e6508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 58:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.091/2.0783 Drop: 0.74129 ACC: 0.98838                                                                                                      \n",
      "Val loss: 2.1835 ACC: 0.90328                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce283a8ec7b449e7be4b91b837f09d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 59:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0912/2.0786 Drop: 0.74114 ACC: 0.98818                                                                                                     \n",
      "Val loss: 2.1837 ACC: 0.90222                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f7795252df41989976199d5f265a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 60:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0912/2.0782 Drop: 0.74084 ACC: 0.98778                                                                                                     \n",
      "Val loss: 2.1835 ACC: 0.90275                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9062e7c13cf41ee9fd182fac76f839a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 61:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0912/2.0896 Drop: 0.74124 ACC: 0.98831                                                                                                     \n",
      "Val loss: 2.1838 ACC: 0.90116                                                                                                    \n",
      "Epoch    61: reducing learning rate of group 0 to 4.5125e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2153308b2f2847aabe2ad7a13fa92a25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 62:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0913/2.0784 Drop: 0.74134 ACC: 0.98845                                                                                                     \n",
      "Val loss: 2.1837 ACC: 0.90011                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650d6cb0ff1e40f8a2aa67f6e7ed6c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 63:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0913/2.1235 Drop: 0.74104 ACC: 0.98805                                                                                                     \n",
      "Val loss: 2.1825 ACC: 0.90011                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912c8dc4581240af9063ef488c0788c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 64:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0905/2.1236 Drop: 0.74149 ACC: 0.98865                                                                                                     \n",
      "Val loss: 2.1816 ACC: 0.90169                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e788cbc91b8b4816822ffd72d49ebb65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 65:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0902/2.0784 Drop: 0.74198 ACC: 0.98931                                                                                                     \n",
      "Val loss: 2.1825 ACC: 0.90063                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae4581625d14328b81448de8816f03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 66:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0906/2.0793 Drop: 0.74153 ACC: 0.98871                                                                                                     \n",
      "Val loss: 2.1827 ACC: 0.90275                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3290291e9fdd4c13b2283fa962480faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 67:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0898/2.0784 Drop: 0.74188 ACC: 0.98918                                                                                                     \n",
      "Val loss: 2.1828 ACC: 0.90275                                                                                                    \n",
      "Epoch    67: reducing learning rate of group 0 to 4.2869e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a557367ede054cd9b15de11406193c11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 68:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0892/2.0786 Drop: 0.74278 ACC: 0.99037                                                                                                     \n",
      "Val loss: 2.1839 ACC: 0.90063                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f86df6cb3046a2ba4584eca279e052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 69:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.09/2.0782 Drop: 0.74193 ACC: 0.98924                                                                                                       \n",
      "Val loss: 2.1833 ACC: 0.90169                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7905c927abc6424e86ab5d24b876f50d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 70:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0898/2.1211 Drop: 0.74208 ACC: 0.98944                                                                                                     \n",
      "Val loss: 2.1835 ACC: 0.90381                                                                                                    \n",
      "Best Val loss: 2.1816                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "best = 99999.\n",
    "counter = 1\n",
    "loss_val = 1.\n",
    "eps = .9\n",
    "dl_val = DataLoader(list(zip(fold.X_val, y_val)), batch_size=batch_size,\n",
    "                         shuffle=False, collate_fn=collate_train, num_workers=num_workers)\n",
    "for e in tqdm(range(nepochs), total=nepochs):\n",
    "    dl_train = DataLoader(list(zip(fold.X_train, y_train)), batch_size=batch_size,\n",
    "                             shuffle=True, collate_fn=collate_train, num_workers=num_workers)\n",
    "    loss_train  = 0.\n",
    "    with tqdm(total=len(y_train)+len(y_val), smoothing=0., desc=f\"Epoch {e+1}\") as pbar:\n",
    "        total = 0\n",
    "        correct  = 0\n",
    "        ab.train()\n",
    "        tokenizer.model = 'sample'\n",
    "        #tokenizer.model = 'sample'\n",
    "        for i, (terms_idx, docs_offsets, y) in enumerate(dl_train):\n",
    "            terms_idx    = terms_idx.to( device )\n",
    "            docs_offsets = docs_offsets.to( device )\n",
    "            y            = y.to( device )\n",
    "            \n",
    "            pred_docs,_,_ = ab( terms_idx, docs_offsets)\n",
    "            pred_docs     = F.softmax(pred_docs)\n",
    "            loss          = loss_func_cel(pred_docs, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            total      += len(y)\n",
    "            y_pred      = pred_docs.argmax(axis=1)\n",
    "            correct    += (y_pred == y).sum().item()\n",
    "            #ab.drop_ =  np.power((correct/total),loss_val)\n",
    "            #ab.drop_ =  np.power((correct/total),4)\n",
    "            ab.drop_ =  (correct/total)*max_drop\n",
    "            \n",
    "            toprint  = f\"Train loss: {loss_train/(i+1):.5}/{loss.item():.5} \"\n",
    "            toprint += f'Drop: {ab.drop_:.5} '\n",
    "            toprint += f'ACC: {correct/total:.5} '\n",
    "            \n",
    "            print(toprint, end=f\"{' '*100}\\r\")\n",
    "            \n",
    "            pbar.update( len(y) )\n",
    "            del pred_docs, loss\n",
    "            del terms_idx, docs_offsets, y\n",
    "            del y_pred\n",
    "        loss_train = loss_train/(i+1)\n",
    "        print()\n",
    "        #print(ab.drop_)\n",
    "        total = 0\n",
    "        correct  = 0\n",
    "        ab.eval()\n",
    "        tokenizer.model = 'topk'\n",
    "        with torch.no_grad():\n",
    "            loss_val = 0.\n",
    "            for i, (terms_idx, docs_offsets, y) in enumerate(dl_val):\n",
    "                terms_idx    = terms_idx.to( device )\n",
    "                docs_offsets = docs_offsets.to( device )\n",
    "                y            = y.to( device )\n",
    "\n",
    "                pred_docs, weights, co_weights = ab( terms_idx, docs_offsets )\n",
    "                pred_docs   = F.softmax(pred_docs)\n",
    "\n",
    "                y_pred      = pred_docs.argmax(axis=1)\n",
    "                correct    += (y_pred == y).sum().item()\n",
    "                total      += len(y)\n",
    "                loss2       = loss_func_cel(pred_docs, y)\n",
    "                loss_val   += loss2\n",
    "\n",
    "                print(f'Val loss: {loss_val.item()/(i+1):.5} ACC: {correct/total:.5}', end=f\"{' '*100}\\r\")\n",
    "   \n",
    "                pbar.update( len(y) )\n",
    "            print()\n",
    "\n",
    "            del terms_idx, docs_offsets, y\n",
    "            del y_pred\n",
    "            \n",
    "            loss_val   = (loss_val/(i+1)).cpu()\n",
    "            scheduler.step(loss_val)\n",
    "\n",
    "            if best-loss_val > 0.0001 :\n",
    "                best = loss_val.item()\n",
    "                counter = 1\n",
    "                print(f'New Best Val loss: {best:.5}', end=f\"{' '*100}\\n\")\n",
    "                best_model = copy.deepcopy(ab).to('cpu')\n",
    "            elif counter > max_epochs:\n",
    "                print(f'Best Val loss: {best:.5}', end=f\"{' '*100}\\n\")\n",
    "                break\n",
    "            else:\n",
    "                counter += 1\n",
    "            del pred_docs, loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99011"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.1742 ACC: 0.90592                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "device_test = 'cpu'\n",
    "ab = copy.deepcopy(best_model).to(device_test)\n",
    "ab.eval()\n",
    "loss_total = 0\n",
    "correct_t = 0\n",
    "total_t = 0\n",
    "dl_test = DataLoader(list(zip(fold.X_test, y_test)), batch_size=128,\n",
    "                         shuffle=False, collate_fn=collate_train, num_workers=2)\n",
    "for i, (terms_idx_t, docs_offsets_t, y_t) in enumerate(dl_test):\n",
    "    terms_idx_t    = terms_idx_t.to( device_test )\n",
    "    docs_offsets_t = docs_offsets_t.to( device_test )\n",
    "    y_t            = y_t.to( device_test )\n",
    "\n",
    "    pred_docs_t,weigths,coweights = ab( terms_idx_t, docs_offsets_t )\n",
    "    sofmax_docs_t = F.softmax(pred_docs_t)\n",
    "\n",
    "    y_pred_t    = sofmax_docs_t.argmax(axis=1)\n",
    "    correct_t  += (y_pred_t == y_t).sum().item()\n",
    "    total_t    += len(y_t)\n",
    "    loss_total += loss_func_cel(sofmax_docs_t, y_t)\n",
    "\n",
    "    print(f'Test loss: {loss_total.item()/(i+1):.5} ACC: {correct_t/total_t:.5}', end=f\"{' '*100}\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 100, 0.99)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred_t == y_t).sum().item(), len(y_t), (y_pred_t == y_t).sum().item()/len(y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([100, 500]), torch.Size([100, 500, 500]), torch.Size([100, 20]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weigths[:,:,0].shape, coweights.shape, pred_docs_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0042, 0.0042, 0.0113,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0088, 0.0090, 0.0240,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0116, 0.0043, 0.0043,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0024, 0.0024, 0.0024,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0021, 0.0021, 0.0057,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0024, 0.0024, 0.0066,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weigths[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]], grad_fn=<RoundBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coweights.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2, 10028,  3892,  ...,     0,     0,     0],\n",
       "        [    2, 26923, 26921,  ...,     0,     0,     0],\n",
       "        [13319,  2861,   302,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [ 2561,   294,  2343,  ...,     0,     0,     0],\n",
       "        [    1,  3101, 66580,  ...,     0,     0,     0],\n",
       "        [    2,  2372, 33087,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = docs_offsets_t.shape[0]\n",
    "        \n",
    "k         = [ terms_idx_t[ docs_offsets_t[i-1]:docs_offsets_t[i] ] for i in range(1, batch_size) ]\n",
    "k.append( terms_idx_t[ docs_offsets_t[-1]: ] )\n",
    "x_packed  = pad_sequence(k, batch_first=True, padding_value=0)\n",
    "\n",
    "x_packed  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    2, 10028,  3892, 13110,   311,   313,   317,  1859, 13098,   327,\n",
       "         4429,  3404,  4435, 12628,  5468,  1885,   353,   332,  2343,   289,\n",
       "          288, 18155, 16620,  1260,   238,   236,  2801,  7421,   253,  1792,\n",
       "         3335,   266,  4876,  2322,  2836,  1815,   282,  2844, 57697, 21346,\n",
       "         1892,  5480,  9648,  2483, 21432,  4030,  1982,  3008,   448, 19392,\n",
       "         5059, 10689, 10701, 40914, 21460, 27605,  2011, 17387,  2035,  9647,\n",
       "          233, 18347,  4516,   364, 73583,  4975,  4980,   374,  7042,  2437,\n",
       "         1926,  1929, 32137,  7053,   401,  5525,  2965,  2968,  5534,   419,\n",
       "         2469,   229,  5347, 12508,    65,  1092,    68,    74,  4683,  8778,\n",
       "         2637,  2642, 11859,    93,    95,  4194,    99, 13924, 57445,   102,\n",
       "          100,  8254, 16997,  7741,  2105,  8194,     4,     8, 11273,  8206,\n",
       "           19, 11802,  2075, 25116, 10784,  7201, 21024, 28708,    37,  2090,\n",
       "         7219,  8759,    59,  8182,  4713,  3696,  7347,  3252,  3253, 28864,\n",
       "        99009,   194,   196,  4293,  7366,  6344,  3274,  1739,  1740, 58062,\n",
       "         1750, 26838,   218,   175,  5742,  8876,   170,   113, 15474,  2672,\n",
       "         3701,   120,  5754, 18047,  4740,  2181,   142,  8335,  4239,  2703,\n",
       "          150,   154, 18587,   157,  2732,  4087,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_packed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 18 166 0.2728988230228424 1.0\n",
      "1 18 79 0.25973400473594666 1.0\n",
      "2 18 164 0.2549821436405182 1.0\n",
      "3 18 38 0.0969529077410698 1.0\n",
      "4 18 108 0.2321673482656479 1.0\n",
      "5 18 176 0.22953253984451294 1.0\n",
      "6 19 45 0.15654321014881134 1.0\n",
      "7 19 71 0.18329696357250214 1.0\n",
      "8 19 190 0.27681440114974976 1.0\n",
      "9 19 337 0.24753233790397644 1.0\n",
      "10 19 157 0.3488174080848694 1.0\n",
      "11 19 214 0.2515285313129425 1.0\n",
      "12 19 279 0.18229468166828156 1.0\n",
      "13 19 118 0.19153979420661926 1.0\n",
      "14 19 500 0.4679720103740692 1.0\n",
      "15 19 79 0.17977888882160187 1.0\n",
      "16 19 108 0.2466563731431961 1.0\n",
      "17 19 276 0.2296917736530304 1.0\n",
      "18 19 98 0.2972719669342041 1.0\n",
      "19 19 51 0.24106113612651825 1.0\n",
      "20 19 36 0.10262345522642136 1.0\n",
      "21 19 94 0.24388863146305084 1.0\n",
      "22 19 109 0.195185586810112 1.0\n",
      "23 19 65 0.15976330637931824 1.0\n",
      "24 19 186 0.3242282271385193 1.0\n",
      "25 19 64 0.212890625 1.0\n",
      "26 19 80 0.23484374582767487 1.0\n",
      "27 19 500 0.3595759868621826 1.0\n",
      "28 19 182 0.33365535736083984 1.0\n",
      "29 19 256 0.2213897705078125 1.0\n",
      "30 19 441 0.211943581700325 1.0\n",
      "31 19 77 0.3369876742362976 1.0\n",
      "32 19 114 0.2098338007926941 1.0\n",
      "33 19 110 0.26892560720443726 1.0\n",
      "34 19 78 0.16831032931804657 1.0\n",
      "35 19 127 0.24341247975826263 1.0\n",
      "36 19 111 0.22408895194530487 1.0\n",
      "37 19 500 0.26270800828933716 1.0\n",
      "38 19 101 0.19939221441745758 1.0\n",
      "39 19 292 0.2523808479309082 1.0\n",
      "40 19 159 0.23337684571743011 1.0\n",
      "41 19 204 0.24889466166496277 1.0\n",
      "42 19 46 0.21739129722118378 1.0\n",
      "43 19 21 0.095238097012043 1.0\n",
      "44 19 73 0.10958904027938843 1.0\n",
      "45 19 94 0.14576731622219086 1.0\n",
      "46 19 151 0.16183499991893768 1.0\n",
      "47 19 61 0.2950819730758667 1.0\n",
      "48 19 37 0.40832725167274475 1.0\n",
      "49 19 139 0.19429636001586914 1.0\n",
      "50 19 190 0.2247091382741928 1.0\n",
      "51 19 42 0.1428571492433548 1.0\n",
      "52 19 111 0.14422529935836792 1.0\n",
      "53 19 54 0.2222222238779068 1.0\n",
      "54 19 13 0.08284023404121399 1.0\n",
      "55 19 126 0.22996976971626282 1.0\n",
      "56 19 292 0.2537178695201874 1.0\n",
      "57 19 78 0.24523340165615082 1.0\n",
      "58 19 172 0.2607828676700592 1.0\n",
      "59 19 152 0.37504327297210693 1.0\n",
      "60 19 96 0.228515625 1.0\n",
      "61 19 426 0.34491613507270813 1.0\n",
      "62 19 33 0.21579430997371674 1.0\n",
      "63 19 232 0.36362960934638977 1.0\n",
      "64 19 243 0.2881335914134979 1.0\n",
      "65 19 312 0.2437027394771576 1.0\n",
      "66 19 165 0.3756106495857239 1.0\n",
      "67 19 253 0.3029261529445648 1.0\n",
      "68 19 67 0.26843395829200745 1.0\n",
      "69 19 216 0.2768990099430084 1.0\n",
      "70 19 138 0.14692291617393494 1.0\n",
      "71 19 158 0.2446322739124298 1.0\n",
      "72 19 64 0.1796875 1.0\n",
      "73 19 480 0.22670139372348785 1.0\n",
      "74 19 30 0.23999999463558197 1.0\n",
      "75 19 66 0.12121212482452393 1.0\n",
      "76 19 124 0.1873699277639389 1.0\n",
      "77 19 78 0.2785996198654175 1.0\n",
      "78 19 500 0.40483999252319336 1.0\n",
      "79 19 246 0.22281710803508759 1.0\n",
      "81 19 101 0.16361141204833984 1.0\n",
      "82 19 172 0.1881084442138672 1.0\n",
      "83 19 200 0.2718000113964081 1.0\n",
      "84 19 165 0.21428833901882172 1.0\n",
      "85 19 135 0.16872428357601166 1.0\n",
      "86 19 400 0.32587501406669617 1.0\n",
      "87 19 308 0.26216477155685425 1.0\n",
      "88 19 423 0.3210826516151428 1.0\n",
      "89 19 261 0.269535094499588 1.0\n",
      "90 19 53 0.2830188572406769 1.0\n",
      "91 19 91 0.16857866942882538 1.0\n",
      "92 19 49 0.18575593829154968 1.0\n",
      "93 19 90 0.2756790220737457 1.0\n",
      "94 19 500 0.3760800063610077 1.0\n",
      "95 19 236 0.24305155873298645 1.0\n",
      "96 19 50 0.24160000681877136 1.0\n",
      "97 19 284 0.2744371294975281 1.0\n",
      "98 19 340 0.23608995974063873 1.0\n",
      "99 19 296 0.23269721865653992 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_t)):\n",
    "    if (y_pred_t == y_t)[i]: \n",
    "        #print(i, y_t[i].item(), sofmax_docs_t[i,y_t[i]].item())\n",
    "        n = (x_packed[i]!=0).sum()\n",
    "        print(i, y_t[i].item(), n.item(), ((coweights[i, :n, :n] > 0.5).sum()/(n*n)).item(), sofmax_docs_t[i,y_t[i]].item()/sofmax_docs_t[i].max().item())\n",
    "        #print(coweights[i, :n, :n] != 0)\n",
    "        #print(x_packed[i, :n], x_packed[i, :n].sum()/(n*n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse as sp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        ...,\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [False, False, False,  ..., False, False, False],\n",
       "        [ True,  True,  True,  ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 20\n",
    "n = (x_packed[i]!=0).sum()\n",
    "dt_h = ab.dt_emb( x_packed[i] )\n",
    "coweights[i, :n, :n] >= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = TSNE(n_components=2)\n",
    "dt_h_np = np.array(dt_h.tolist())\n",
    "x2 = pca.fit_transform(dt_h_np[:n,:])\n",
    "pos = { i: v for (i,v) in enumerate(x2) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0239, 0.0239, 0.0239, 0.0239, 0.0239, 0.0239, 0.0239, 0.0239, 0.0239,\n",
       "        0.0239, 0.0239, 0.0239, 0.0239, 0.0239, 0.0239, 0.0239, 0.0239, 0.0239,\n",
       "        0.0239, 0.0239, 0.0390, 0.0239, 0.0239, 0.0239, 0.0239, 0.0650, 0.0239,\n",
       "        0.0239, 0.0239, 0.0239, 0.0650, 0.0239, 0.0239, 0.0251, 0.0239, 0.0650],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weigths[i,:n,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_matrix = sp.csc_matrix(((coweights[i, :n, :n]>.5)*coweights[i, :n, :n]).tolist())\n",
    "G = nx.from_scipy_sparse_matrix(sp_matrix, create_using=nx.DiGraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_dict= { v:k for (k,v) in tokenizer.node_mapper.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "#pos=nx.spring_layout(G)\n",
    "#pos=nx.spiral_layout(G)\n",
    "\n",
    "doc_weigs = np.array(weigths[i,:n,0].tolist())\n",
    "doc_weigs /= doc_weigs.mean(axis=0)\n",
    "doc_weigs = (doc_weigs - doc_weigs.min(axis=0)) / (doc_weigs.max(axis=0) - doc_weigs.min(axis=0))\n",
    "\n",
    "node_sizes  = [ doc_weigs[nid]*600 for nid in G.nodes ]\n",
    "node_labels = { nid: inv_dict[nid] for nid in G.nodes }\n",
    "#edge_alphas = { nid: 1.-doc_weigs[nid] for nid in G.nodes }\n",
    "edge_widths = { nid: doc_weigs[nid]*3. for nid in G.nodes }\n",
    "\n",
    "ax = nx.draw_networkx_nodes(G, pos=pos, node_size=node_sizes)\n",
    "ax = nx.draw_networkx_labels(G, pos, labels=node_labels, font_size=10)\n",
    "ax = nx.draw_networkx_edges(G, pos=pos, edge_color='darkgray', width=edge_widths, alpha=0.1)\n",
    "#for nid, alpha in tqdm(edge_alphas.items(), total=len(edge_alphas)):\n",
    "#    ax = nx.draw_networkx_edges(G, pos=pos, nodelist=[nid], edge_color='darkgray', width=edge_widths, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.36731016, 0.        , 0.        , 0.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.99984272, 0.        , 0.        , 0.0291739 , 0.        ,\n",
       "       1.        ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_weigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'doc_weigs2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-ea1388f2c2ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoc_weigs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_weigs2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'doc_weigs2' is not defined"
     ]
    }
   ],
   "source": [
    "doc_weigs, doc_weigs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sp_matrix.nonzero()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "acm ####################################################################################\n",
    "Train loss: 1.6009/1.6089 ACC: 0.94886                                                                                                    \n",
    "Val loss: 1.7718 ACC: 0.77475                                                                                                    \n",
    "New Best Val loss: 1.7718                                                                                                    \n",
    "Test loss: 1.7678 ACC: 0.78557  79.92\n",
    "\n",
    "Train loss: 1.7209/1.6095 ACC: 0.82338                                                                                                    \n",
    "Val loss: 1.7595 ACC: 0.78236                                                                                                    \n",
    "New Best Val loss: 1.7595                                                                                             \n",
    "Test loss: 1.7585 ACC: 0.78557                                                                                                    \n",
    "\n",
    "20ng ####################################################################################\n",
    "Train loss: 2.0907/2.0787 ACC: 0.98845                                                                                                    \n",
    "Val loss: 2.1869 ACC: 0.90803                                                                                                    \n",
    "New Best Val loss: 2.1869                                                                                                    \n",
    "Test loss: 2.178 ACC: 0.91068   92.65\n",
    "\n",
    "Train loss: 2.1603/2.1249 ACC: 0.92511                                                                                                    \n",
    "Val loss: 2.1842 ACC: 0.90645                                                                                                    \n",
    "drop: 0.8436\n",
    "New Best Val loss: 2.1842                                                                                                   \n",
    "Test loss: 2.1705 ACC: 0.91226                                                                                                    \n",
    "\n",
    "reut ####################################################################################\n",
    "Train loss: 3.7735/3.5191 ACC: 0.74734            acm                                                                                        \n",
    "Val loss: 3.8554 ACC: 0.6763                                                                                                    \n",
    "New Best Val loss: 3.8554                                                                                                    \n",
    "Test loss: 3.8493 ACC: 0.6837  72.67\n",
    "\n",
    "Train loss: 3.7443/3.8521 ACC: 0.77727                                                                                                    \n",
    "Val loss: 3.808 ACC: 0.71037                                                                                                     \n",
    "New Best Val loss: 3.808\n",
    "Test loss: 3.8461 ACC: 0.70444                                                                                                    \n",
    "\n",
    "webkb ####################################################################################\n",
    "Train loss: 1.2228/1.2037 ACC: 0.9504                                                                                                     \n",
    "Val loss: 1.3787 ACC: 0.80316                                                                                                    \n",
    "New Best Val loss: 1.3787                                                                                                    \n",
    "Test loss: 1.3857 ACC: 0.78858   81.53\n",
    "\n",
    "Epoch: 45\n",
    "Train loss: 1.2392/1.2909 ACC: 0.9295                                                                                                     \n",
    "Val loss: 1.3838 ACC: 0.78736                                                                                                    \n",
    "New Best Val loss: 1.3838\n",
    "Test loss: 1.3814 ACC: 0.78372                                                                                                    \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_h = ab.dt_emb( x_packed )\n",
    "dt_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx_packed = x_packed == 0\n",
    "doc_sizes = bx_packed.logical_not().sum(dim=1).view(batch_size, 1)\n",
    "pad_mask  = bx_packed.logical_not()\n",
    "pad_mask  = pad_mask.view(*bx_packed.shape, 1)\n",
    "pad_mask  = pad_mask.logical_and(pad_mask.transpose(1, 2))\n",
    "pad_mask.shape, doc_sizes.shape, bx_packed.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_means = (bx_packed.logical_not().view(*bx_packed.shape, 1) * dt_h).sum(axis=1) / doc_sizes\n",
    "doc_means = doc_means.view(*doc_means.shape, 1).transpose(1,2)\n",
    "doc_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dt_h = dt_h/doc_sizes.view(*doc_sizes.shape, 1)\n",
    "n_dt_h = (doc_means - n_dt_h)\n",
    "n_dt_h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_t      = pred_docs_t.argmax(axis=1)\n",
    "correct_t     = (y_pred_t == y_t).sum().item()\n",
    "total_t       = len(y_t)\n",
    "correct_t/total_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_offsets_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_idx_t[:docs_offsets_t[batch_size]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_off_test  = docs_offsets_t[batch_size]\n",
    "batch_tidx_test = terms_idx_t[:batch_off_test]\n",
    "h_terms_test    = sc.tt_emb( batch_tidx_test )\n",
    "dirh_terms_test = sc.tt_dir_map( h_terms_test )\n",
    "\n",
    "W = torch.matmul( h_terms_test, dirh_terms_test.T )\n",
    "W = F.leaky_relu( W, negative_slope=sc.mask.negative_slope)\n",
    "W = F.sigmoid(W)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [ batch_tidx_test[ docs_offsets_t[i-1]:docs_offsets_t[i] ] for i in range(1, batch_size) ]\n",
    "k.append( batch_tidx_test[ docs_offsets_t[batch_size-1]:docs_offsets_t[batch_size] ] )\n",
    "x_packed = pad_sequence(k, batch_first=True, padding_value=0)\n",
    "tt_emb = sc.tt_emb( x_packed )\n",
    "len(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_packed = pad_sequence(k, batch_first=True, padding_value=0)\n",
    "tt_emb = sc.tt_emb( x_packed )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_emb.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [terms_idx, terms_idx]\n",
    "torch.stack(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "F.softmax(pred_docs_t).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_t == F.softmax(pred_docs_t).argmax(axis=1)).sum().item()/y_t.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_idx_t, docs_offsets_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shifts = sc._get_shift_(docs_offsets_t, terms_idx_t.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipado = zip(docs_offsets_t, shifts)\n",
    "#next(zipado)\n",
    "start,size = next(zipado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = sc.tt_emb( terms_idx_t[start:start+size] )\n",
    "w1 = sc.tt_dir_map( w )\n",
    "w = torch.matmul( w, w1.T )\n",
    "w = F.leaky_relu( w, negative_slope=sc.negative_slope)\n",
    "w = F.sigmoid(w)\n",
    "#w = F.tanh(w)\n",
    "#w = F.relu(w)\n",
    "#w = w.mean(axis=1)\n",
    "#w = F.softmax(w)\n",
    "w,w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.round().sum() / (w.shape[0]*w.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_mapper = { v:k for (k,v) in tokenizer.node_mapper.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_idx[start:start+size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold.X_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = w.mean(axis=1)\n",
    "bla = F.softmax(bla)\n",
    "#bla = bla/torch.clamp(bla.sum(), 0.0001)\n",
    "bla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ (i, tid.item(),inv_mapper[tid.item()], wei.item()) for i, (tid, wei) in enumerate(zip(terms_idx[start:start+size], bla)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = nn.BatchNorm1d(num_features=1).to(device)\n",
    "\n",
    "bla2 = norm(bla.view(-1, 1)).squeeze()\n",
    "bla2 = F.sigmoid(bla2)\n",
    "bla2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = nn.MultiheadAttention(300, 300).to(device)\n",
    "ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = w.shape\n",
    "w_ = w.view(a,1,b)\n",
    "w1_ = w1.view(a,1,b)\n",
    "\n",
    "attn_output = ma(w_, w1_, w_, need_weights=False)\n",
    "\n",
    "attn_output.view(a,b)\n",
    "attn_output_weights.view(a,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output.view(a,b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_output_weights.view(a,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(torch.Tensor([[0.0718, 0.0716, 0.0712, 0.0714, 0.0721, 0.0710, 0.0712, 0.0714, 0.0710,\n",
    "         0.0719, 0.0711, 0.0712, 0.0718, 0.0714],\n",
    "        [0.0722, 0.0709, 0.0710, 0.0709, 0.0728, 0.0723, 0.0709, 0.0709, 0.0719,\n",
    "         0.0712, 0.0709, 0.0707, 0.0725, 0.0707],\n",
    "        [0.0711, 0.0715, 0.0710, 0.0713, 0.0710, 0.0712, 0.0718, 0.0713, 0.0709,\n",
    "         0.0725, 0.0716, 0.0719, 0.0710, 0.0719],\n",
    "        [0.0721, 0.0717, 0.0714, 0.0713, 0.0717, 0.0714, 0.0711, 0.0710, 0.0713,\n",
    "         0.0717, 0.0710, 0.0712, 0.0720, 0.0711],\n",
    "        [0.0722, 0.0711, 0.0710, 0.0710, 0.0737, 0.0716, 0.0709, 0.0705, 0.0714,\n",
    "         0.0719, 0.0707, 0.0707, 0.0731, 0.0702],\n",
    "        [0.0714, 0.0716, 0.0708, 0.0711, 0.0718, 0.0713, 0.0712, 0.0717, 0.0712,\n",
    "         0.0724, 0.0713, 0.0712, 0.0716, 0.0714],\n",
    "        [0.0712, 0.0714, 0.0713, 0.0713, 0.0722, 0.0716, 0.0709, 0.0714, 0.0714,\n",
    "         0.0717, 0.0713, 0.0713, 0.0716, 0.0713],\n",
    "        [0.0716, 0.0707, 0.0712, 0.0714, 0.0717, 0.0715, 0.0714, 0.0715, 0.0712,\n",
    "         0.0721, 0.0711, 0.0714, 0.0717, 0.0715],\n",
    "        [0.0717, 0.0713, 0.0708, 0.0710, 0.0725, 0.0717, 0.0714, 0.0709, 0.0712,\n",
    "         0.0712, 0.0712, 0.0717, 0.0720, 0.0714],\n",
    "        [0.0709, 0.0712, 0.0713, 0.0712, 0.0713, 0.0713, 0.0714, 0.0719, 0.0712,\n",
    "         0.0724, 0.0715, 0.0715, 0.0717, 0.0713],\n",
    "        [0.0715, 0.0716, 0.0712, 0.0708, 0.0725, 0.0717, 0.0712, 0.0714, 0.0714,\n",
    "         0.0717, 0.0713, 0.0706, 0.0718, 0.0712],\n",
    "        [0.0726, 0.0711, 0.0713, 0.0706, 0.0737, 0.0721, 0.0709, 0.0707, 0.0714,\n",
    "         0.0708, 0.0706, 0.0705, 0.0730, 0.0707],\n",
    "        [0.0718, 0.0711, 0.0714, 0.0715, 0.0725, 0.0707, 0.0707, 0.0711, 0.0712,\n",
    "         0.0728, 0.0711, 0.0713, 0.0719, 0.0709],\n",
    "        [0.0712, 0.0716, 0.0713, 0.0712, 0.0717, 0.0707, 0.0708, 0.0721, 0.0709,\n",
    "         0.0728, 0.0713, 0.0716, 0.0711, 0.0715]]).sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotTooSimpleClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_l, nclass, dropout1=0.1, dropout2=0.1, negative_slope=99,\n",
    "                 initrange = 0.5, scale_grad_by_freq=False, device='cuda:0'):\n",
    "        super(NotTooSimpleClassifier, self).__init__()\n",
    "        \n",
    "        self.dt_emb = nn.Embedding(vocab_size, hidden_l, scale_grad_by_freq=scale_grad_by_freq)\n",
    "        self.tt_emb = nn.Embedding(vocab_size, hidden_l, scale_grad_by_freq=scale_grad_by_freq)\n",
    "        \n",
    "        self.undirected_map = nn.Linear(hidden_l, hidden_l)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_l, nclass)\n",
    "        self.drop1 = nn.Dropout(dropout1)\n",
    "        self.drop2 = nn.Dropout(dropout2)\n",
    "        \n",
    "        self.norm = nn.BatchNorm1d(1)\n",
    "        \n",
    "        self.initrange = initrange\n",
    "        self.nclass = nclass\n",
    "        self.negative_slope = negative_slope\n",
    "        \n",
    "        self.init_weights()\n",
    "        \n",
    "        #self.labls_emb = nn.Embedding(graph_builder.n_class, 300)\n",
    "    \n",
    "    def forward(self, terms_idxs, docs_offsets):\n",
    "        n = terms_idxs.shape[0]\n",
    "        weights = []\n",
    "        shifts = self._get_shift_(docs_offsets, n)\n",
    "        \n",
    "        terms_h1 = self.tt_emb(terms_idxs)\n",
    "        terms_h1 = self.drop1(terms_h1)\n",
    "        \n",
    "        terms_h2 = self.undirected_map( terms_h1 )\n",
    "        #terms_h2 = self.drop1( terms_h2 )\n",
    "        for start,size in zip(docs_offsets, shifts):\n",
    "            w  = terms_h1[start:start+size]\n",
    "            w1 = terms_h2[start:start+size]\n",
    "            w = torch.matmul( w, w1.T )\n",
    "            w = F.leaky_relu( w, negative_slope=self.negative_slope)\n",
    "            w = F.sigmoid(w-5.5)\n",
    "            w = w.mean(axis=1)\n",
    "            w = F.softmax(w)\n",
    "            #w = w / torch.clamp(w.sum(), 0.0001)\n",
    "            weights.append( w )\n",
    "        \n",
    "        weights = torch.cat(weights)\n",
    "        #weights = self.norm(weights.view(-1, 1)).squeeze()\n",
    "        #weights = F.sigmoid(weights)\n",
    "        \n",
    "        h_docs  = F.embedding_bag(self.dt_emb.weight, terms_idxs, docs_offsets, per_sample_weights=weights, mode='sum')\n",
    "        h_docs = self.drop2( h_docs )\n",
    "        pred_docs = self.fc( h_docs )\n",
    "        return pred_docs\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.dt_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.tt_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        \n",
    "    def _get_shift_(self, offsets, lenght):\n",
    "        shifts = offsets[1:] - offsets[:-1]\n",
    "        last = torch.LongTensor([lenght - offsets[-1]]).to( offsets.device )\n",
    "        return torch.cat([shifts, last])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
