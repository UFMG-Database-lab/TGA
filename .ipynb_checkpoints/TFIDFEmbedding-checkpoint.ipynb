{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b406ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from multiprocessing import Pool\n",
    "from collections import namedtuple\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import networkx as nx\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS as stop_words\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from nltk.corpus import stopwords as stopwords_by_lang\n",
    "\n",
    "import copy\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "import scipy.sparse as sp\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea4cb19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TGA.utils import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f80b142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('X_train', 'y_train', 'X_test', 'y_test', 'X_val', 'y_val'), 15062)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset('/home/Documents/datasets/20ng/')\n",
    "g = dataset.get_fold_instances(10, with_val=True)\n",
    "fold = next(g)\n",
    "fold._fields, len(fold.X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc81a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67f03afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "replace_patterns = [\n",
    "    ('<[^>]*>', ''),                                    # remove HTML tags\n",
    "    ('(\\D)\\d\\d:\\d\\d:\\d\\d(\\D)', '\\\\1 ParsedTime \\\\2'),\n",
    "    ('(\\D)\\d\\d:\\d\\d(\\D)', '\\\\1 ParsedTime \\\\2'),\n",
    "    ('(\\D)\\d:\\d\\d:\\d\\d(\\D)', '\\\\1 ParsedTime \\\\2'),\n",
    "    ('(\\D)\\d:\\d\\d(\\D)', '\\\\1 ParsedTime \\\\2'),\n",
    "    ('(\\D)\\d\\d\\d\\-\\d\\d\\d\\d(\\D)', '\\\\1 ParsedPhoneNum \\\\2'),\n",
    "    ('(\\D)\\d\\d\\d\\D\\d\\d\\d\\-\\d\\d\\d\\d(\\D)', '\\\\1 ParsedPhoneNum \\\\2'),\n",
    "    ('(\\D\\D)\\d\\d\\d\\D\\D\\d\\d\\d\\-\\d\\d\\d\\d(\\D)', '\\\\1 ParsedPhoneNum \\\\2'),\n",
    "    ('(\\D)\\d\\d\\d\\d\\d\\-\\d\\d\\d\\d(\\D)', '\\\\1 ParsedZipcodePlusFour \\\\2'),\n",
    "    ('(\\D)\\d(\\D)', '\\\\1ParsedOneDigit\\\\2'),\n",
    "    ('(\\D)\\d\\d(\\D)', '\\\\1ParsedTwoDigits\\\\2'),\n",
    "    ('(\\D)\\d\\d\\d(\\D)', '\\\\1ParsedThreeDigits\\\\2'),\n",
    "    ('(\\D)\\d\\d\\d\\d(\\D)', '\\\\1ParsedFourDigits\\\\2'),\n",
    "    ('(\\D)\\d\\d\\d\\d\\d(\\D)', '\\\\1ParsedFiveDigits\\\\2'),\n",
    "    ('(\\D)\\d\\d\\d\\d\\d\\d(\\D)', '\\\\1ParsedSixDigits\\\\2'),\n",
    "    ('\\d+', 'ParsedDigits')\n",
    "]\n",
    "\n",
    "compiled_replace_patterns = [(re.compile(p[0]), p[1]) for p in replace_patterns]\n",
    "\n",
    "def generate_preprocessor(replace_patterns):\n",
    "    compiled_replace_patterns = [(re.compile(p[0]), p[1]) for p in replace_patterns]\n",
    "    def preprocessor(text):\n",
    "        for pattern, replace in compiled_replace_patterns:\n",
    "            text = re.sub(pattern, replace, text)\n",
    "        text = text.lower()\n",
    "        return text\n",
    "    return preprocessor\n",
    "\n",
    "generated_patters=generate_preprocessor(replace_patterns)\n",
    "\n",
    "def preprocessor(text):\n",
    "    # For each pattern, replace it with the appropriate string\n",
    "    for pattern, replace in compiled_replace_patterns:\n",
    "        text = re.sub(pattern, replace, text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "class Tokenizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, mindf=2, lan='english', stopwords='nltk', model='topk', k=500, verbose=False):\n",
    "        super(Tokenizer, self).__init__()\n",
    "        self.mindf = mindf\n",
    "        self.le = LabelEncoder()\n",
    "        self.verbose = verbose\n",
    "        self.lan = lan\n",
    "        if stopwords == 'nltk':\n",
    "            self.stopwordsSet = stopwords_by_lang.words(lan)\n",
    "        elif stopwords == 'scikit':\n",
    "            self.stopwordsSet = stop_words\n",
    "        else:\n",
    "            self.stopwordsSet = []\n",
    "        self.model =  model\n",
    "        self.k     = k\n",
    "        self.analyzer = TfidfVectorizer(preprocessor=preprocessor, min_df=mindf)#.build_analyzer()\n",
    "        self.local_analyzer = self.analyzer.build_analyzer()\n",
    "        self.analyzer.set_params( analyzer=self.local_analyzer )\n",
    "        self.node_mapper      = {}\n",
    "        \n",
    "    def analyzer_doc(self, doc):\n",
    "        return self.local_analyzer(doc)\n",
    "    def fit(self, X, y):\n",
    "        self.N = len(X)\n",
    "        y = self.le.fit_transform( y )\n",
    "        self.n_class = len(self.le.classes_)\n",
    "        docs_in_terms = []\n",
    "        \n",
    "        with Pool(processes=18) as p:\n",
    "            #docs = map(self.local_analyzer, X)\n",
    "            for doc_in_terms in tqdm(p.imap(self.analyzer_doc, X), total=self.N, disable=not self.verbose):\n",
    "                doc_in_terms = list(set(map( self._filter_fit_, list(doc_in_terms) ))) \n",
    "                docs_in_terms.extend(doc_in_terms)\n",
    "        \n",
    "        self.term_freqs       = Counter(docs_in_terms)\n",
    "        self.term_freqs       = { term:v for (term,v) in self.term_freqs.items() if v >= self.mindf }\n",
    "        self.node_mapper      = { term: self.node_mapper.setdefault(term, len(self.node_mapper)+1)\n",
    "                                 for term in self.term_freqs.keys() }\n",
    "        self.node_mapper['<BLANK>'] = 0\n",
    "        self.term_freqs['<BLANK>']  = self.N\n",
    "        \n",
    "        self.node_mapper['<UNK>']   = len(self.node_mapper)\n",
    "        self.term_freqs['<UNK>']  = self.N\n",
    "        self.vocab_size = len(self.node_mapper)\n",
    "        \n",
    "        self.term_array = [ term for (term,term_id) in sorted(self.node_mapper.items(), key=lambda x: x[1]) ]\n",
    "        \n",
    "        self.fi_ = np.array([ np.log2( (self.N+1)/(self.term_freqs[term]+1) ) for term in self.term_array ])\n",
    "            \n",
    "        return self\n",
    "    def _filter_transform_(self, term):\n",
    "        if term in self.stopwordsSet:\n",
    "            return '<STPW>'\n",
    "        if term not in self.node_mapper:\n",
    "            return '<UNK>'\n",
    "        return term\n",
    "    def _filter_fit_(self, term):\n",
    "        if term in self.stopwordsSet:\n",
    "            return '<STPW>'\n",
    "        return term\n",
    "    def _model_(self, doc):\n",
    "        doc_counter = Counter(doc)\n",
    "        doc = np.array(list(doc_counter.keys()))\n",
    "        if len(doc) > self.k:\n",
    "            weigths = np.array([ self.fi_[t] for t in doc ])\n",
    "            weigths = softmax(weigths)\n",
    "            if self.model == 'topk':\n",
    "                doc = doc[(-weigths).argsort()[:self.k]]\n",
    "            elif self.model == 'sample':\n",
    "                doc = np.random.choice(doc, size=self.k, replace=False, p=weigths)\n",
    "        TFs = np.array([ doc_counter[tid] for tid in doc ])\n",
    "        DFs = np.array([ self.term_freqs[self.term_array[tid]] for tid in doc ])\n",
    "        return doc, TFs, DFs\n",
    "    def transform(self, X, verbose=None):\n",
    "        verbose = verbose if verbose is not None else self.verbose\n",
    "        n = len(X)\n",
    "        terms_ = []\n",
    "        for i,doc_in_terms in tqdm(enumerate(map(self.analyzer_doc, X)), total=n, disable=not verbose):\n",
    "            doc_in_terms = map( self._filter_transform_, doc_in_terms )\n",
    "            #doc_in_terms = filter( lambda x: x != '<STPW>', doc_in_terms )\n",
    "            doc_tids = [ self.node_mapper[tid] for tid in doc_in_terms ]\n",
    "            doc_tids, TFs, DFs = self._model_(doc_tids)\n",
    "            terms_.append( (doc_tids, TFs, DFs) )\n",
    "        doc_tids, TFs, DFs = list(zip(*terms_))\n",
    "        return list(doc_tids), list(TFs), list(DFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1066fc30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d2364922c914a708c1baf6ce2d6ec2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15062 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(99011, 15062)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(mindf=1, verbose=True, stopwords=None)\n",
    "tokenizer.fit(fold.X_train, fold.y_train)\n",
    "tokenizer.vocab_size, tokenizer.N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88ea1fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f1c896e19f4fd1bb870bae46a4cb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1892 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_tids, TFs, DFs =  tokenizer.transform( fold.X_val )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81776f8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1960ac28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1,  1,  1,  ...,  0,  0,  0],\n",
       "        [ 7,  2,  2,  ...,  0,  0,  0],\n",
       "        [ 1,  1,  1,  ...,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 2,  1, 15,  ...,  0,  0,  0],\n",
       "        [ 4,  1,  2,  ...,  0,  0,  0],\n",
       "        [ 2,  2,  1,  ...,  1,  1,  2]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequence(list(map(torch.LongTensor, TFs)), batch_first=True, padding_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3698a1ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'beef'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.term_array[15749]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9afbeaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tokenizer.le.transform( fold.y_train )\n",
    "y_val   = tokenizer.le.transform( fold.y_val )\n",
    "y_test  = tokenizer.le.transform( fold.y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f26c0aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionTFIDF_V1(nn.Module):\n",
    "    def __init__(self, vocab_size, hiddens, nclass, maxF=20, drop=.5, initrange=.5, negative_slope=99.):\n",
    "        super(AttentionTFIDF_V1, self).__init__()\n",
    "        self.hiddens        = hiddens\n",
    "        self.maxF           = maxF\n",
    "        self.value_emb      = nn.Embedding(vocab_size, hiddens, scale_grad_by_freq=True, padding_idx=0)\n",
    "        self.query_emb      = nn.Embedding(vocab_size, hiddens, scale_grad_by_freq=True, padding_idx=0)\n",
    "        self.key_emb        = nn.Embedding(vocab_size, hiddens, scale_grad_by_freq=True, padding_idx=0)\n",
    "        self.TF_emb         = nn.Embedding(maxF, hiddens, scale_grad_by_freq=True, padding_idx=0)\n",
    "        self.DF_emb         = nn.Embedding(maxF, hiddens, scale_grad_by_freq=True, padding_idx=0)\n",
    "        self.fc             = nn.Linear(hiddens, nclass)\n",
    "        self.initrange      = initrange \n",
    "        self.negative_slope = negative_slope\n",
    "        self.drop_          = drop\n",
    "        self.init_weights()\n",
    "    def forward(self, doc_tids, TFs, DFs):\n",
    "        batch_size = doc_tids.size(0)\n",
    "        bx_packed  = doc_tids == 0\n",
    "        pad_mask   = bx_packed.logical_not()\n",
    "        doc_sizes  = pad_mask.sum(dim=1).view(batch_size, 1)\n",
    "        pad_mask   = pad_mask.view(*bx_packed.shape, 1)\n",
    "        pad_mask   = pad_mask.logical_and(pad_mask.transpose(1, 2))\n",
    "        \n",
    "        TFs     = torch.clamp( TFs, max=self.maxF-1 )\n",
    "        h_TFs   = self.TF_emb( TFs )\n",
    "        h_TFs   = F.dropout( h_TFs, p=self.drop_, training=self.training )\n",
    "        \n",
    "        DFs     = torch.clamp( DFs, max=self.maxF-1 )\n",
    "        h_DFs   = self.DF_emb( DFs )\n",
    "        h_DFs   = F.dropout( h_DFs, p=self.drop_, training=self.training )\n",
    "        \n",
    "        h_query = self.query_emb( doc_tids )\n",
    "        h_query = h_query + h_TFs + h_DFs\n",
    "        h_query = torch.tanh( h_query )\n",
    "        h_query = F.dropout( h_query, p=self.drop_, training=self.training )\n",
    "        \n",
    "        h_key = self.key_emb( doc_tids )\n",
    "        h_key = h_key + h_TFs + h_DFs\n",
    "        h_key = torch.tanh( h_key )\n",
    "        h_key = F.dropout( h_key, p=self.drop_, training=self.training )\n",
    "        \n",
    "        co_weights = torch.bmm( h_key, h_query.transpose( 1, 2 ) )\n",
    "        co_weights = F.leaky_relu( co_weights, negative_slope=self.negative_slope)\n",
    "        \n",
    "        #co_weights[pad_mask.logical_not()] = 0 # Set the 3D-pad mask values to \n",
    "        co_weights[pad_mask.logical_not()] = float('-inf') # Set the 3D-pad mask values to -inf (=0 in sigmoid)\n",
    "        co_weights = torch.sigmoid(co_weights)\n",
    "        \n",
    "        weights = co_weights.sum(axis=2) / doc_sizes\n",
    "        weights[bx_packed] = float('-inf') # Set the 2D-pad mask values to -inf  (=0 in softmax)\n",
    "        \n",
    "        weights = torch.softmax(weights, dim=1)\n",
    "        weights = torch.where(torch.isnan(weights), torch.zeros_like(weights), weights)\n",
    "        weights = weights.view( *weights.shape, 1 )\n",
    "        \n",
    "        h_value = self.value_emb( doc_tids )\n",
    "        h_value = h_value + h_TFs + h_DFs\n",
    "        h_value = F.dropout( h_value, p=self.drop_, training=self.training )\n",
    "        \n",
    "        docs_h = h_value * weights\n",
    "        docs_h = docs_h.sum(axis=1)\n",
    "        docs_h = F.dropout( docs_h, p=self.drop_, training=self.training )\n",
    "        docs_h = self.fc(docs_h)\n",
    "        return docs_h, weights, co_weights\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.TF_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.DF_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.query_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.key_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.value_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.fc.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02686300",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionTFIDF_V2(nn.Module):\n",
    "    def __init__(self, vocab_size, hiddens, nclass,\n",
    "                 maxF=20, drop=.5, initrange=.5, negative_slope=99.):\n",
    "        super(AttentionTFIDF_V2, self).__init__()\n",
    "        self.hiddens        = hiddens\n",
    "        self.maxF           = maxF\n",
    "        self.query_emb      = nn.Embedding(vocab_size, hiddens, scale_grad_by_freq=True, padding_idx=0)\n",
    "        self.key_term_emb   = nn.Embedding(vocab_size, hiddens, scale_grad_by_freq=True, padding_idx=0)\n",
    "        self.key_clss_emb   = nn.Embedding(hiddens*nclass, hiddens, scale_grad_by_freq=True, padding_idx=0)\n",
    "        self.value_emb      = nn.Embedding(hiddens*nclass, hiddens, scale_grad_by_freq=True, padding_idx=0)\n",
    "        self.TF_emb         = nn.Embedding(maxF, hiddens, scale_grad_by_freq=True, padding_idx=0)\n",
    "        self.DF_emb         = nn.Embedding(maxF, hiddens, scale_grad_by_freq=True, padding_idx=0)\n",
    "        self.fc             = nn.Linear(hiddens, nclass)\n",
    "        self.initrange      = initrange \n",
    "        self.negative_slope = negative_slope\n",
    "        self.drop_          = drop\n",
    "        self.init_weights()\n",
    "    def forward(self, doc_tids, TFs, DFs):\n",
    "        batch_size = doc_tids.size(0)\n",
    "        bx_packed  = doc_tids == 0\n",
    "        pad_mask   = bx_packed.logical_not()\n",
    "        doc_sizes  = pad_mask.sum(dim=1).view(batch_size, 1)\n",
    "        pad_mask   = pad_mask.view(*bx_packed.shape, 1)\n",
    "        pad_mask   = pad_mask.logical_and(pad_mask.transpose(1, 2))\n",
    "        \n",
    "        TFs     = torch.clamp( TFs, max=self.maxF-1 )\n",
    "        h_TFs   = self.TF_emb( TFs )\n",
    "        h_TFs   = F.dropout( h_TFs, p=self.drop_, training=self.training )\n",
    "        \n",
    "        DFs     = torch.clamp( DFs, max=self.maxF-1 )\n",
    "        h_DFs   = self.DF_emb( DFs )\n",
    "        h_DFs   = F.dropout( h_DFs, p=self.drop_, training=self.training )\n",
    "        \n",
    "        h_query = self.query_emb( doc_tids )\n",
    "        h_query = h_query + h_TFs + h_DFs\n",
    "        h_query = torch.tanh( h_query )\n",
    "        h_query = F.dropout( h_query, p=self.drop_, training=self.training )\n",
    "        \n",
    "        h_key = self.key_term_emb( doc_tids )\n",
    "        h_key = h_key + h_TFs + h_DFs\n",
    "        h_key = torch.tanh( h_key )\n",
    "        h_key = F.dropout( h_key, p=self.drop_, training=self.training )\n",
    "        \n",
    "        co_weights = torch.bmm( h_key, h_query.transpose( 1, 2 ) )\n",
    "        co_weights = F.leaky_relu( co_weights, negative_slope=self.negative_slope)\n",
    "        \n",
    "        #co_weights[pad_mask.logical_not()] = 0 # Set the 3D-pad mask values to \n",
    "        co_weights[pad_mask.logical_not()] = float('-inf') # Set the 3D-pad mask values to -inf (=0 in sigmoid)\n",
    "        co_weights = torch.sigmoid(co_weights)\n",
    "        \n",
    "        \n",
    "        \n",
    "        h_clss_key = self.key_clss_emb.weights\n",
    "        h_clss_key = h_clss_key\n",
    "        h_clss_key = torch.tanh( h_clss_key )\n",
    "        h_clss_key = F.dropout( h_clss_key, p=self.drop_, training=self.training )\n",
    "        \n",
    "        co_weights = torch.bmm( h_key, h_query.transpose( 1, 2 ) )\n",
    "        co_weights = F.leaky_relu( co_weights, negative_slope=self.negative_slope)\n",
    "        \n",
    "        weights = co_weights.sum(axis=2) / doc_sizes\n",
    "        weights[bx_packed] = float('-inf') # Set the 2D-pad mask values to -inf  (=0 in softmax)\n",
    "        \n",
    "        weights = torch.softmax(weights, dim=1)\n",
    "        weights = torch.where(torch.isnan(weights), torch.zeros_like(weights), weights)\n",
    "        weights = weights.view( *weights.shape, 1 )\n",
    "        \n",
    "        h_value = self.value_emb( doc_tids )\n",
    "        h_value = h_value + h_TFs + h_DFs\n",
    "        h_value = F.dropout( h_value, p=self.drop_, training=self.training )\n",
    "        \n",
    "        docs_h = h_value * weights\n",
    "        docs_h = docs_h.sum(axis=1)\n",
    "        docs_h = F.dropout( docs_h, p=self.drop_, training=self.training )\n",
    "        docs_h = self.fc(docs_h)\n",
    "        return docs_h, weights, co_weights\n",
    "    \n",
    "    def init_weights(self):\n",
    "        self.TF_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.DF_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.query_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.key_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.value_emb.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.fc.weight.data.uniform_(-self.initrange, self.initrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e62d1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nepochs = 1000\n",
    "max_epochs = 30\n",
    "drop=0.8\n",
    "max_drop=.7 # default .8\n",
    "device = torch.device('cuda:0')\n",
    "batch_size = 16 # default 32\n",
    "k = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75973e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_train(param):\n",
    "    X, y = zip(*param)\n",
    "    doc_tids, TFs, DFs = tokenizer.transform(X, verbose=False)\n",
    "    doc_tids = pad_sequence(list(map(torch.LongTensor, doc_tids)), batch_first=True, padding_value=0)\n",
    "    \n",
    "    TFs = pad_sequence(list(map(torch.tensor, TFs)), batch_first=True, padding_value=0)\n",
    "    TFs = torch.LongTensor(torch.log2(TFs+1).round().long())\n",
    "    \n",
    "    DFs = pad_sequence(list(map(torch.tensor, DFs)), batch_first=True, padding_value=0)\n",
    "    DFs = torch.LongTensor(torch.log2(DFs+1).round().long())\n",
    "    \n",
    "    return doc_tids, TFs, DFs, torch.LongTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e53a2b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f468814b070>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "282a450c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a0756a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc = SimpleClassifier(tokenizer.vocab_size, 300, tokenizer.n_class, dropout=drop).to( device )\n",
    "ab = AttentionTFIDF_V1(tokenizer.vocab_size, 300, tokenizer.n_class, drop=drop).to( device )\n",
    "#ab = AttentionBag(tokenizer.vocab_size, 300, tokenizer.n_class, drop=drop).to( device )\n",
    "#ab = NotTooSimpleClassifier(tokenizer.vocab_size, 300, tokenizer.n_class, dropout1=drop, dropout2=drop).to( device )\n",
    "tokenizer.k = k\n",
    "optimizer = optim.AdamW( ab.parameters(), lr=5e-3, weight_decay=5e-3)\n",
    "loss_func_cel = nn.CrossEntropyLoss().to( device )\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=.95,\n",
    "                                                       patience=10, verbose=True)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=.98, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8736bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e497917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9c178d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2c6b5068b74eff978a7277ad81da5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50ca2c855104a65aa3b8aa42f08ecc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.6758/2.735 Drop: 0.30785 ACC: 0.43978                                                                                                        \n",
      "Val loss: 2.3923 ACC: 0.71459                                                                                                    \n",
      "New Best Val loss: 2.3923                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ef1133ff45416b8c1a2aedbf723085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.312/2.2466 Drop: 0.55802 ACC: 0.79717                                                                                                      \n",
      "Val loss: 2.2595 ACC: 0.84408                                                                                                    \n",
      "New Best Val loss: 2.2595                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36a20e4c0a5413ea6d836f132cba5d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.23/2.1862 Drop: 0.60487 ACC: 0.8641                                                                                                        \n",
      "Val loss: 2.2277 ACC: 0.86258                                                                                                    \n",
      "New Best Val loss: 2.2277                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a341e079524dc3adc5548d3dbd64de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.2016/2.0793 Drop: 0.62085 ACC: 0.88693                                                                                                     \n",
      "Val loss: 2.2239 ACC: 0.86734                                                                                                    \n",
      "New Best Val loss: 2.2239                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19f64136b3a450598d7b27646125678",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.184/2.0793 Drop: 0.63187 ACC: 0.90267                                                                                                      \n",
      "Val loss: 2.2129 ACC: 0.87685                                                                                                    \n",
      "New Best Val loss: 2.2129                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65dbf3345444cb39d3bfb39844d0fd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1679/2.0846 Drop: 0.64488 ACC: 0.92126                                                                                                     \n",
      "Val loss: 2.2048 ACC: 0.88425                                                                                                    \n",
      "New Best Val loss: 2.2048                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9da790816804ab9899e4da4f248a7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.155/2.3243 Drop: 0.65264 ACC: 0.93235                                                                                                      \n",
      "Val loss: 2.1992 ACC: 0.88953                                                                                                    \n",
      "New Best Val loss: 2.1992                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7946f632efa461ca9b47f4d983059de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1446/2.079 Drop: 0.65896 ACC: 0.94138                                                                                                      \n",
      "Val loss: 2.1967 ACC: 0.88584                                                                                                    \n",
      "New Best Val loss: 2.1967                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cba6fe9de2ca4986b1d40256bc79014e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1368/2.094 Drop: 0.66338 ACC: 0.94768                                                                                                      \n",
      "Val loss: 2.1947 ACC: 0.88953                                                                                                    \n",
      "New Best Val loss: 2.1947                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88705aaa1db84911a8de472ec47f1cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1336/2.0782 Drop: 0.66514 ACC: 0.95021                                                                                                     \n",
      "Val loss: 2.1956 ACC: 0.89218                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "684566bf4a5b40168f7c79121de75941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 11:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1312/2.1328 Drop: 0.66677 ACC: 0.95253                                                                                                     \n",
      "Val loss: 2.1938 ACC: 0.89112                                                                                                    \n",
      "New Best Val loss: 2.1938                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa43f0586a74c36aee0d906ca01c63c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 12:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1274/2.0884 Drop: 0.66928 ACC: 0.95611                                                                                                     \n",
      "Val loss: 2.189 ACC: 0.89429                                                                                                     \n",
      "New Best Val loss: 2.189                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b11c1792ce934d27a688598e9a63d851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 13:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1232/2.2436 Drop: 0.67193 ACC: 0.9599                                                                                                      \n",
      "Val loss: 2.1893 ACC: 0.89429                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0ad1000cd3425f9ce96824cae2fd7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 14:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1207/2.1161 Drop: 0.67304 ACC: 0.96149                                                                                                     \n",
      "Val loss: 2.1901 ACC: 0.89271                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49ede5756044fdb86aeb970f2d2148d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 15:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1211/2.098 Drop: 0.67244 ACC: 0.96063                                                                                                      \n",
      "Val loss: 2.1858 ACC: 0.89746                                                                                                    \n",
      "New Best Val loss: 2.1858                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bfd30ac27c148b3ae4896120d7f164c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 16:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1183/2.0782 Drop: 0.67449 ACC: 0.96355                                                                                                     \n",
      "Val loss: 2.1884 ACC: 0.89482                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aee57c08f734cd98e2df29016682b7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 17:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1167/2.0782 Drop: 0.67532 ACC: 0.96475                                                                                                     \n",
      "Val loss: 2.1875 ACC: 0.89799                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d583807310746079f61112b47676452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 18:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1182/2.0782 Drop: 0.6737 ACC: 0.96242                                                                                                      \n",
      "Val loss: 2.1887 ACC: 0.89376                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "878bb576f12349028b1c34bed5b0006f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 19:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1151/2.0782 Drop: 0.67653 ACC: 0.96647                                                                                                     \n",
      "Val loss: 2.1916 ACC: 0.89006                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "178e0c2965204e939d516cb0c0189462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 20:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1147/2.2206 Drop: 0.67639 ACC: 0.96627                                                                                                     \n",
      "Val loss: 2.1871 ACC: 0.89641                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb55d54ff0f4249bd98f51fa0ca97bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 21:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1142/2.0782 Drop: 0.67658 ACC: 0.96654                                                                                                     \n",
      "Val loss: 2.1855 ACC: 0.89746                                                                                                    \n",
      "New Best Val loss: 2.1855                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acb7381eeaac435ca72f9e90065b7b85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 22:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1152/2.3091 Drop: 0.67634 ACC: 0.96621                                                                                                     \n",
      "Val loss: 2.189 ACC: 0.89271                                                                                                     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1020502cf0d24ab7806d27a5b7d846d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 23:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1126/2.0869 Drop: 0.67806 ACC: 0.96866                                                                                                     \n",
      "Val loss: 2.1864 ACC: 0.89905                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03563eab82b940b78a03a4cffd7d05c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 24:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.11/2.0782 Drop: 0.67955 ACC: 0.97079                                                                                                       \n",
      "Val loss: 2.1846 ACC: 0.89746                                                                                                    \n",
      "New Best Val loss: 2.1846                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a880b7d5104252a056b3f0576cbc82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 25:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1105/2.0782 Drop: 0.67885 ACC: 0.96979                                                                                                     \n",
      "Val loss: 2.1855 ACC: 0.89852                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48a8f8a5a8c74f5eb1834832f55e14b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 26:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1107/2.2584 Drop: 0.67913 ACC: 0.97019                                                                                                                                                                                                         \n",
      "Val loss: 2.1917 ACC: 0.89112                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9b5376d52247b8b52bd48fac436a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 27:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1094/2.079 Drop: 0.68025 ACC: 0.97178                                                                                                      \n",
      "Val loss: 2.1863 ACC: 0.89693                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fa0d2231a1f4b2f847012103c6910d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 28:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1079/2.2447 Drop: 0.68127 ACC: 0.97324                                                                                                     \n",
      "Val loss: 2.1888 ACC: 0.89218                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1157d028445242a5bd5f339c449d8abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 29:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1075/2.0782 Drop: 0.68095 ACC: 0.97278                                                                                                     \n",
      "Val loss: 2.189 ACC: 0.89641                                                                                                     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff65f0a3ff54560807711d6bbd20d54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 30:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1073/2.0782 Drop: 0.68132 ACC: 0.97331                                                                                                     \n",
      "Val loss: 2.1886 ACC: 0.89376                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43f0fbb5c304aafb89c744e5c77a208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 31:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1069/2.2448 Drop: 0.6815 ACC: 0.97358                                                                                                      \n",
      "Val loss: 2.1838 ACC: 0.89958                                                                                                    \n",
      "New Best Val loss: 2.1838                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c1f776df0ad4ddabe986ba156f1b3c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 32:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1095/2.0783 Drop: 0.67946 ACC: 0.97065                                                                                                     \n",
      "Val loss: 2.1847 ACC: 0.89641                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c178c25fc6ae4792b49beff77ede1f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 33:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1065/2.0851 Drop: 0.68169 ACC: 0.97384                                                                                                                                                                                                         \n",
      "Val loss: 2.184 ACC: 0.89905                                                                                                     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3602bb9e4026454ea93eb668c0b1e760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 34:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1063/2.0784 Drop: 0.68201 ACC: 0.97431                                                                                                                                                                                                         \n",
      "Val loss: 2.1845 ACC: 0.89588                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f90213861e040ef9ec06aa3e017122c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 35:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.106/2.079 Drop: 0.68266 ACC: 0.97524                                                                                                       \n",
      "Val loss: 2.1847 ACC: 0.89535                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9614f25122944aae81ca27765e882b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 36:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1057/2.0783 Drop: 0.68299 ACC: 0.9757                                                                                                      \n",
      "Val loss: 2.1861 ACC: 0.89905                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bbf0249e044190a9ac454c2bb40d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 37:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1061/2.0782 Drop: 0.68174 ACC: 0.97391                                                                                                     \n",
      "Val loss: 2.1812 ACC: 0.90063                                                                                                    \n",
      "New Best Val loss: 2.1812                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f81338e8a714c23850580f899ff33bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 38:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1047/2.211 Drop: 0.68322 ACC: 0.97603                                                                                                      \n",
      "Val loss: 2.1864 ACC: 0.89641                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8b37d3bcf34489a60d8f177e8aa32c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 39:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1049/2.0795 Drop: 0.68285 ACC: 0.9755                                                                                                      \n",
      "Val loss: 2.1855 ACC: 0.90063                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e040d09e21b04fbf93c2d4f3a43945ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 40:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1047/2.099 Drop: 0.68341 ACC: 0.9763                                                                                                       \n",
      "Val loss: 2.1878 ACC: 0.90011                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a36ea43b1f84b89939da9250e308868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 41:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1059/2.0954 Drop: 0.68225 ACC: 0.97464                                                                                                     \n",
      "Val loss: 2.1872 ACC: 0.89641                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc0ca161ca5e40fcb7269387dc208428",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 42:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1038/2.0787 Drop: 0.68378 ACC: 0.97683                                                                                                     \n",
      "Val loss: 2.1872 ACC: 0.89535                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b55d70f97e6f49e59831629bee1c16e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 43:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1026/2.0783 Drop: 0.68457 ACC: 0.97796                                                                                                     \n",
      "Val loss: 2.1881 ACC: 0.89429                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2332df052144404a3a1ca06db8528bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 44:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1041/2.0782 Drop: 0.6835 ACC: 0.97643                                                                                                      \n",
      "Val loss: 2.1904 ACC: 0.89482                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e7ff98196194828a3b89ecd53aefbac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 45:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.103/2.0782 Drop: 0.68429 ACC: 0.97756                                                                                                      \n",
      "Val loss: 2.192 ACC: 0.88953                                                                                                     \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "766c6ed3587f4aaa91201ab8455d6168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 46:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1034/2.0782 Drop: 0.68378 ACC: 0.97683                                                                                                     \n",
      "Val loss: 2.1896 ACC: 0.89482                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a73148917eba4ccf83ad32b2cbdffde3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 47:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1029/2.0782 Drop: 0.68452 ACC: 0.97789                                                                                                     \n",
      "Val loss: 2.1846 ACC: 0.90063                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1299c7f985eb4607bccebe4f09987fe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 48:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.103/2.0782 Drop: 0.68406 ACC: 0.97723                                                                                                      \n",
      "Val loss: 2.1862 ACC: 0.89799                                                                                                    \n",
      "Epoch    48: reducing learning rate of group 0 to 4.7500e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66262812c75a49fcbec8b63126b282ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 49:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1021/2.0782 Drop: 0.68485 ACC: 0.97836                                                                                                     \n",
      "Val loss: 2.1824 ACC: 0.90275                                                                                                                                                                                                        \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3518127e637f4c7dbbf9e9a35dc7605a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 50:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1033/2.2445 Drop: 0.68392 ACC: 0.97703                                                                                                     \n",
      "Val loss: 2.1844 ACC: 0.89852                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdff2426d49840b39cfe1a5cde300eb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 51:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.103/2.0782 Drop: 0.68383 ACC: 0.9769                                                                                                       \n",
      "Val loss: 2.1838 ACC: 0.90169                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d91c9ad9e94bedaeab322ccd3a051b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 52:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1006/2.2453 Drop: 0.68555 ACC: 0.97935                                                                                                     \n",
      "Val loss: 2.1817 ACC: 0.90539                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec89c2ea34834096a48fb2c71af65e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 53:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.101/2.1659 Drop: 0.68564 ACC: 0.97948                                                                                                      \n",
      "Val loss: 2.1849 ACC: 0.89746                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25621c50d91a4af3a0257ab261ec4b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 54:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1012/2.2416 Drop: 0.68545 ACC: 0.97922                                                                                                     \n",
      "Val loss: 2.1841 ACC: 0.89958                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec66c7d0db64b1cba0b6a7738bd4aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 55:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1015/2.0791 Drop: 0.68508 ACC: 0.97869                                                                                                                                                                                                         \n",
      "Val loss: 2.1854 ACC: 0.89905                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10523bc14ea4788afa3fe83ddab4eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 56:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1007/2.0782 Drop: 0.68587 ACC: 0.97982                                                                                                     \n",
      "Val loss: 2.1835 ACC: 0.90169                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345b5d48dda1464f8f15ef39fdbcaae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 57:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1013/2.4007 Drop: 0.68559 ACC: 0.97942                                                                                                     \n",
      "Val loss: 2.1848 ACC: 0.90116                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "839f9217f984460b853a9711b7177e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 58:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1001/2.0783 Drop: 0.6861 ACC: 0.98015                                                                                                      \n",
      "Val loss: 2.1845 ACC: 0.89958                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c77256ad034ac5adf6990c7a19dee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 59:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1003/2.0864 Drop: 0.68578 ACC: 0.97968                                                                                                     \n",
      "Val loss: 2.189 ACC: 0.89482                                                                                                     \n",
      "Epoch    59: reducing learning rate of group 0 to 4.5125e-03.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8378c410401345f2b2e5e2f697520fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 60:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0993/2.0786 Drop: 0.68703 ACC: 0.98148                                                                                                     \n",
      "Val loss: 2.1846 ACC: 0.89799                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91c3e2e90119433fabc3a7d8f3992463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 61:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0992/2.0782 Drop: 0.68648 ACC: 0.98068                                                                                                     \n",
      "Val loss: 2.1873 ACC: 0.89799                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e8425898024404b71d00d5ab7bdb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 62:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0989/2.0786 Drop: 0.68708 ACC: 0.98154                                                                                                     \n",
      "Val loss: 2.1856 ACC: 0.89905                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16bd6b4113bb4934ae2ab5ae3edb9066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 63:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1001/2.0782 Drop: 0.68634 ACC: 0.98048                                                                                                     \n",
      "Val loss: 2.1864 ACC: 0.89852                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d222c4f16504228a00c71ea195b1815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 64:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0995/2.2159 Drop: 0.68662 ACC: 0.98088                                                                                                                                                                                                                                                                                                             \n",
      "Val loss: 2.1875 ACC: 0.89588                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8320a8f70174a6b9842f5f61621874d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 65:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.1001/2.0782 Drop: 0.68662 ACC: 0.98088                                                                                                                                                                                                         \n",
      "Val loss: 2.1847 ACC: 0.90063                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ce439bd9a14a789f34d3a577b0bfec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 66:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0981/2.1074 Drop: 0.68731 ACC: 0.98187                                                                                                     \n",
      "Val loss: 2.1867 ACC: 0.89588                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472d966610594814867fede727ae789f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 67:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0993/2.1232 Drop: 0.68671 ACC: 0.98101                                                                                                     \n",
      "Val loss: 2.1888 ACC: 0.89323                                                                                                    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c08dfea865429fac66241d5209244c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 68:   0%|          | 0/16954 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.0999/2.1734 Drop: 0.68629 ACC: 0.98041                                                                                                     \n",
      "Val loss: 2.1847 ACC: 0.89852                                                                                                    \n",
      "Best Val loss: 2.1812                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "best = 99999.\n",
    "counter = 1\n",
    "loss_val = 1.\n",
    "eps = .9\n",
    "dl_val = DataLoader(list(zip(fold.X_val, y_val)), batch_size=batch_size,\n",
    "                         shuffle=False, collate_fn=collate_train, num_workers=num_workers)\n",
    "for e in tqdm(range(nepochs), total=nepochs):\n",
    "    dl_train = DataLoader(list(zip(fold.X_train, y_train)), batch_size=batch_size,\n",
    "                             shuffle=True, collate_fn=collate_train, num_workers=num_workers)\n",
    "    loss_train  = 0.\n",
    "    with tqdm(total=len(y_train)+len(y_val), smoothing=0., desc=f\"Epoch {e+1}\") as pbar:\n",
    "        total = 0\n",
    "        correct  = 0\n",
    "        ab.train()\n",
    "        tokenizer.model = 'sample'\n",
    "        tokenizer.k = k\n",
    "        for i, (doc_tids, TFs, DFs, y) in enumerate(dl_train):\n",
    "            doc_tids = doc_tids.to( device )\n",
    "            TFs      = TFs.to( device )\n",
    "            DFs      = DFs.to( device )\n",
    "            y        = y.to( device )\n",
    "            \n",
    "            pred_docs,_,_ = ab( doc_tids, TFs, DFs )\n",
    "            pred_docs     = torch.softmax(pred_docs, dim=1)\n",
    "            loss          = loss_func_cel(pred_docs, y)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            loss_train += loss.item()\n",
    "            total      += len(y)\n",
    "            y_pred      = pred_docs.argmax(axis=1)\n",
    "            correct    += (y_pred == y).sum().item()\n",
    "            #ab.drop_ =  np.power((correct/total),loss_val)\n",
    "            #ab.drop_ =  np.power((correct/total),4)\n",
    "            ab.drop_ =  (correct/total)*max_drop\n",
    "            \n",
    "            toprint  = f\"Train loss: {loss_train/(i+1):.5}/{loss.item():.5} \"\n",
    "            toprint += f'Drop: {ab.drop_:.5} '\n",
    "            toprint += f'ACC: {correct/total:.5} '\n",
    "            \n",
    "            print(toprint, end=f\"{' '*100}\\r\")\n",
    "            \n",
    "            pbar.update( len(y) )\n",
    "            del doc_tids, TFs\n",
    "            del DFs, y, pred_docs\n",
    "            del loss, y_pred\n",
    "        loss_train = loss_train/(i+1)\n",
    "        print()\n",
    "        #print(ab.drop_)\n",
    "        total = 0\n",
    "        correct  = 0\n",
    "        ab.eval()\n",
    "        tokenizer.model = 'topk'\n",
    "        tokenizer.k = 512\n",
    "        with torch.no_grad():\n",
    "            loss_val = 0.\n",
    "            for i, (doc_tids, TFs, DFs, y) in enumerate(dl_val):\n",
    "                doc_tids = doc_tids.to( device )\n",
    "                TFs      = TFs.to( device )\n",
    "                DFs      = DFs.to( device )\n",
    "                y        = y.to( device )\n",
    "\n",
    "                pred_docs,_,_ = ab( doc_tids, TFs, DFs )\n",
    "                pred_docs     = torch.softmax(pred_docs, dim=1)\n",
    "                loss          = loss_func_cel(pred_docs, y)\n",
    "\n",
    "                loss_val   += loss.item()\n",
    "                total      += len(y)\n",
    "                y_pred      = pred_docs.argmax(axis=1)\n",
    "                correct    += (y_pred == y).sum().item()\n",
    "                \n",
    "                print(f'Val loss: {loss_val/(i+1):.5} ACC: {correct/total:.5}', end=f\"{' '*100}\\r\")\n",
    "                pbar.update( len(y) )\n",
    "                \n",
    "                del doc_tids, TFs, DFs, y\n",
    "                del pred_docs, loss\n",
    "            print()\n",
    "            loss_val   = (loss_val/(i+1))\n",
    "            scheduler.step(loss_val)\n",
    "\n",
    "            if best-loss_val > 0.0001 :\n",
    "                best = loss_val\n",
    "                counter = 1\n",
    "                print(f'New Best Val loss: {best:.5}', end=f\"{' '*100}\\n\")\n",
    "                best_model = copy.deepcopy(ab).to('cpu')\n",
    "            elif counter > max_epochs:\n",
    "                print(f'Best Val loss: {best:.5}', end=f\"{' '*100}\\n\")\n",
    "                break\n",
    "            else:\n",
    "                counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51f311b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 2.1734 ACC: 0.90539                                                                                                    \r"
     ]
    }
   ],
   "source": [
    "device_test = 'cpu'\n",
    "ab = copy.deepcopy(best_model).to(device_test)\n",
    "ab.eval()\n",
    "loss_total = 0\n",
    "correct_t = 0\n",
    "total_t = 0\n",
    "dl_test = DataLoader(list(zip(fold.X_test, y_test)), batch_size=128,\n",
    "                         shuffle=False, collate_fn=collate_train, num_workers=num_workers)\n",
    "tokenizer.k = 256\n",
    "for i, (docs_tids_t, TFs_t, DFs_t, y_t) in enumerate(dl_test):\n",
    "    docs_tids_t = docs_tids_t.to( device_test )\n",
    "    TFs_t       = TFs_t.to( device_test )\n",
    "    DFs_t       = DFs_t.to( device_test )\n",
    "    y_t         = y_t.to( device_test )\n",
    "\n",
    "    pred_docs_t,weigths,coweights = ab( docs_tids_t, TFs_t, DFs_t )\n",
    "    sofmax_docs_t = torch.softmax(pred_docs_t, dim=1)\n",
    "\n",
    "    y_pred_t    = sofmax_docs_t.argmax(axis=1)\n",
    "    correct_t  += (y_pred_t == y_t).sum().item()\n",
    "    total_t    += len(y_t)\n",
    "    loss_total += loss_func_cel(sofmax_docs_t, y_t)\n",
    "\n",
    "    print(f'Test loss: {loss_total.item()/(i+1):.5} ACC: {correct_t/total_t:.5}', end=f\"{' '*100}\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41c4eea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = torch.FloatTensor([[1,0,0],[0,1,0],[0,0,1]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
