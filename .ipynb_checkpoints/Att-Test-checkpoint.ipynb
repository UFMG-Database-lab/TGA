{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_idx_sample = [ 1, 2, 3, 4, 5, 3, 4, 6, 1, 4, 5, 7 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 5, 9]), tensor([1, 2, 3, 4, 5, 3, 4, 6, 1, 4, 5, 7]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_idx_sample = torch.LongTensor(term_idx_sample)\n",
    "docs_offsets_sample = torch.LongTensor([ 0, 5, 9 ])\n",
    "docs_offsets_sample, term_idx_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mask(nn.Module):\n",
    "    def __init__(self, negative_slope=1000, kappa=0.):\n",
    "        super(Mask, self).__init__()\n",
    "        self.negative_slope = negative_slope\n",
    "        self.kappa = kappa\n",
    "        self.sig = nn.Sigmoid()\n",
    "    def forward(self, h):\n",
    "        w = F.leaky_relu( h, negative_slope=self.negative_slope)\n",
    "        w = self.sig(w-self.kappa)\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionBag(nn.Module):\n",
    "    def __init__(self, vocab_size, hiddens):\n",
    "        super(AttentionBag, self).__init__()\n",
    "        self.hiddens    = hiddens\n",
    "        self.mask       = Mask()\n",
    "        self.dt_emb     = nn.Embedding(vocab_size, hiddens)\n",
    "        self.dt_dir_map = nn.Linear(hiddens, hiddens)\n",
    "        self.ma_term    = nn.MultiheadAttention(hiddens, 1)\n",
    "    def forward(self, terms_idx, docs_offsets, return_mask=False):\n",
    "        n = terms_idx.shape[0]\n",
    "        batch_size = docs_offsets.shape[0]\n",
    "        \n",
    "        k         = [ terms_idx[ docs_offsets[i-1]:docs_offsets[i] ] for i in range(1, batch_size) ]\n",
    "        k.append( terms_idx[ docs_offsets[-1]: ] )\n",
    "        x_packed  = pad_sequence(k, batch_first=True, padding_value=0)\n",
    "\n",
    "        bx_packed = x_packed == 0\n",
    "        pad_mask  = bx_packed.logical_not()\n",
    "        pad_mask  = pad_mask.view(*bx_packed.shape, 1)\n",
    "        pad_mask  = pad_mask.logical_and(pad_mask.transpose(1, 2))\n",
    "        \n",
    "        dt_h      = self.dt_emb( x_packed )\n",
    "        dir_dt_h  = self.dt_dir_map( dt_h )\n",
    "\n",
    "        weights = torch.bmm( dt_h, dir_dt_h.transpose( 1, 2 ) )\n",
    "        weights = self.mask(weights)\n",
    "        \n",
    "        weights_disc = (weights * pad_mask)\n",
    "        weights_disc = weights_disc.sum(axis=1)\n",
    "        weights_disc = F.softmax(weights_disc, dim=1)\n",
    "        weights_disc = weights_disc.view( *weights_disc.shape, 1 )\n",
    "        \n",
    "        attn_mask = weights != 0\n",
    "        attn_mask = attn_mask.logical_and( pad_mask ).logical_not()\n",
    "        \n",
    "        dt_h     = dt_h.transpose(0,1)\n",
    "        dir_dt_h = dir_dt_h.transpose(0,1)\n",
    "        docs_att, weigths_att = self.ma_term( dt_h, dir_dt_h, dt_h,\n",
    "                                  key_padding_mask=bx_packed, \n",
    "                                  attn_mask=attn_mask )\n",
    "\n",
    "        weigths_att = torch.where(torch.isnan(weigths_att), torch.zeros_like(weigths_att), weigths_att)\n",
    "        weigths_att = (weigths_att * pad_mask)\n",
    "        weigths_att = F.softmax(weigths_att.sum(axis=1), dim=1)\n",
    "        weigths_att = weigths_att.view( *weigths_att.shape, 1 )\n",
    "        \n",
    "        weigths = weigths_att + weights_disc\n",
    "\n",
    "        docs_att = docs_att.transpose(0,1)\n",
    "        docs_att = torch.where(torch.isnan(docs_att), torch.zeros_like(docs_att), docs_att)\n",
    "        \n",
    "        docs_h = docs_att * weigths\n",
    "        docs_h = docs_h.sum(axis=1)\n",
    "        docs_h = docs_h / bx_packed.logical_not().sum(dim=1).view(batch_size, 1)\n",
    "        docs_h = torch.where(torch.isnan(docs_h), torch.zeros_like(docs_h), docs_h)\n",
    "        if return_mask:\n",
    "            return docs_h, bx_packed, pad_mask, attn_mask\n",
    "        return docs_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttentionBag(\n",
       "  (mask): Mask(\n",
       "    (sig): Sigmoid()\n",
       "  )\n",
       "  (dt_emb): Embedding(8, 10)\n",
       "  (dt_dir_map): Linear(in_features=10, out_features=10, bias=True)\n",
       "  (ma_term): MultiheadAttention(\n",
       "    (out_proj): _LinearWithBias(in_features=10, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att = AttentionBag(len(set(term_idx_sample.tolist()))+1, 10)\n",
    "att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0115, -0.1640,  0.0684, -0.0876, -0.1101,  0.0051,  0.1153, -0.1482,\n",
       "           0.0171, -0.0103],\n",
       "         [ 0.0094, -0.1155, -0.0052, -0.0195, -0.0078, -0.0547,  0.0899, -0.0682,\n",
       "           0.0090,  0.0051],\n",
       "         [ 0.0467, -0.0305,  0.0470, -0.1557, -0.0030,  0.1063, -0.0692, -0.1062,\n",
       "           0.0078,  0.0341]], grad_fn=<SWhereBackward>),\n",
       " tensor([[False, False, False, False, False],\n",
       "         [False, False, False, False,  True],\n",
       "         [False, False, False,  True,  True]]),\n",
       " tensor([[[ True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True]],\n",
       " \n",
       "         [[ True,  True,  True,  True, False],\n",
       "          [ True,  True,  True,  True, False],\n",
       "          [ True,  True,  True,  True, False],\n",
       "          [ True,  True,  True,  True, False],\n",
       "          [False, False, False, False, False]],\n",
       " \n",
       "         [[ True,  True,  True, False, False],\n",
       "          [ True,  True,  True, False, False],\n",
       "          [ True,  True,  True, False, False],\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False]]]),\n",
       " tensor([[[False, False, False, False,  True],\n",
       "          [ True,  True, False, False,  True],\n",
       "          [ True, False, False, False,  True],\n",
       "          [ True,  True,  True,  True, False],\n",
       "          [False, False, False,  True,  True]],\n",
       " \n",
       "         [[False, False, False,  True,  True],\n",
       "          [ True,  True,  True,  True,  True],\n",
       "          [ True, False,  True,  True,  True],\n",
       "          [False, False,  True, False,  True],\n",
       "          [ True,  True,  True,  True,  True]],\n",
       " \n",
       "         [[ True, False, False,  True,  True],\n",
       "          [ True,  True, False,  True,  True],\n",
       "          [ True, False, False,  True,  True],\n",
       "          [ True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True]]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att(term_idx_sample, docs_offsets_sample, return_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4, 5],\n",
       "        [3, 4, 6, 1, 0],\n",
       "        [4, 5, 7, 0, 0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "k = [ term_idx_sample[ docs_offsets_sample[i-1]:docs_offsets_sample[i] ] for i in range(1, batch_size) ]\n",
    "k.append( term_idx_sample[ docs_offsets_sample[-1]: ] )\n",
    "x_packed   = pad_sequence(k, batch_first=True, padding_value=0)\n",
    "\n",
    "dt_h     = dt_emb( x_packed )\n",
    "dir_dt_h = dt_dir_map( dt_h )\n",
    "\n",
    "bx_packed = x_packed == 0\n",
    "x_packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "batched_dt     = dt_h.transpose(0,1)\n",
    "#batched_dir_dt = dt_h.transpose(0,1)\n",
    "batched_dir_dt = dir_dt_h.transpose(0,1)\n",
    "\n",
    "weights = torch.bmm( dt_h, dir_dt_h.transpose( 2, 1 ) )\n",
    "weights = mask(weights)\n",
    "attn_mask = weights != 0\n",
    "\n",
    "pad_mask = bx_packed.logical_not()\n",
    "pad_mask = pad_mask.view(*bx_packed.shape, 1)\n",
    "pad_mask = pad_mask.logical_and(pad_mask.transpose(2,1))\n",
    "\n",
    "attn_mask_old = attn_mask\n",
    "attn_mask = attn_mask.logical_and( pad_mask ).logical_not()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ True,  True,  True,  True,  True],\n",
       "         [ True,  True,  True,  True, False],\n",
       "         [ True,  True,  True, False, False]]),\n",
       " tensor([[[ True, False, False, False,  True],\n",
       "          [ True, False, False,  True,  True],\n",
       "          [ True,  True,  True,  True,  True],\n",
       "          [ True, False,  True,  True,  True],\n",
       "          [ True, False,  True, False,  True]],\n",
       " \n",
       "         [[ True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True],\n",
       "          [False, False, False,  True, False],\n",
       "          [False, False, False,  True, False],\n",
       "          [ True, False,  True,  True,  True]],\n",
       " \n",
       "         [[ True,  True,  True,  True,  True],\n",
       "          [False,  True, False,  True,  True],\n",
       "          [ True,  True, False,  True,  True],\n",
       "          [False,  True,  True,  True,  True],\n",
       "          [False,  True,  True,  True,  True]]]),\n",
       " tensor([[[ True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True],\n",
       "          [ True,  True,  True,  True,  True]],\n",
       " \n",
       "         [[ True,  True,  True,  True, False],\n",
       "          [ True,  True,  True,  True, False],\n",
       "          [ True,  True,  True,  True, False],\n",
       "          [ True,  True,  True,  True, False],\n",
       "          [False, False, False, False, False]],\n",
       " \n",
       "         [[ True,  True,  True, False, False],\n",
       "          [ True,  True,  True, False, False],\n",
       "          [ True,  True,  True, False, False],\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False]]]),\n",
       " tensor([[[ True, False, False, False,  True],\n",
       "          [ True, False, False,  True,  True],\n",
       "          [ True,  True,  True,  True,  True],\n",
       "          [ True, False,  True,  True,  True],\n",
       "          [ True, False,  True, False,  True]],\n",
       " \n",
       "         [[ True,  True,  True,  True, False],\n",
       "          [ True,  True,  True,  True, False],\n",
       "          [False, False, False,  True, False],\n",
       "          [False, False, False,  True, False],\n",
       "          [False, False, False, False, False]],\n",
       " \n",
       "         [[ True,  True,  True, False, False],\n",
       "          [False,  True, False, False, False],\n",
       "          [ True,  True, False, False, False],\n",
       "          [False, False, False, False, False],\n",
       "          [False, False, False, False, False]]]))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx_packed.logical_not(), attn_mask_old, pad_mask, attn_mask.logical_not()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de pesos de co-ocorrÃªncias\n",
    "$(N, L, S)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.9142, 0.0000, 0.0000, 0.0000, 0.9766],\n",
       "          [0.7897, 0.0000, 0.0000, 0.5455, 0.7037],\n",
       "          [0.9130, 0.5700, 0.8687, 0.7904, 0.7713],\n",
       "          [0.9163, 0.0000, 0.9870, 0.9730, 0.7838],\n",
       "          [0.8055, 0.0000, 0.5633, 0.0000, 0.9841]],\n",
       " \n",
       "         [[0.8687, 0.7904, 0.9405, 0.9130, 0.7198],\n",
       "          [0.9870, 0.9730, 0.9108, 0.9163, 0.7433],\n",
       "          [0.0000, 0.0000, 0.0000, 0.9840, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.9142, 0.0000],\n",
       "          [0.5805, 0.0000, 0.9363, 0.9426, 0.5807]],\n",
       " \n",
       "         [[0.9730, 0.7838, 0.6593, 0.7433, 0.7433],\n",
       "          [0.0000, 0.9841, 0.0000, 0.6082, 0.6082],\n",
       "          [0.8349, 0.5034, 0.0000, 0.6175, 0.6175],\n",
       "          [0.0000, 0.8724, 0.5710, 0.5807, 0.5807],\n",
       "          [0.0000, 0.8724, 0.5710, 0.5807, 0.5807]]], grad_fn=<SigmoidBackward>),\n",
       " tensor([[0.4569, 0.0105, 0.0670, 0.0600, 0.4055],\n",
       "         [0.1046, 0.0953, 0.1041, 0.6797, 0.0163],\n",
       "         [0.3092, 0.4914, 0.0980, 0.0507, 0.0507]], grad_fn=<SoftmaxBackward>))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_disc = (weights * pad_mask)\n",
    "weights_disc = weights_disc.sum(axis=1)\n",
    "weights_disc = F.softmax(weights_disc, dim=1)\n",
    "weights, weights_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6162, 0.6537, 0.0000, 3.7412, 1.2287],\n",
       "        [0.0000, 3.2439, 0.6063, 1.6162, 0.0000],\n",
       "        [1.2826, 0.5478, 1.4665, 0.0000, 0.0000]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 5])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "key_padding_mask: $(N,S)$ where $N$ is the batch size, $S$ is the source sequence length. If a $BoolTensor$ is provided, the positions with the value of $True$ will be ignored while the position with the value of $False$ will be unchanged.\n",
    "\n",
    "attn_mask: 3D mask $(N*num\\_heads, L, S)$ where $N$ is the batch size, $L$ is the target sequence length, $S$ is the source sequence length. If a $BoolTensor$ is provided, positions with $True$ is not allowed to attend while $False$ values will be unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5]), torch.Size([3, 5, 5]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx_packed.shape, attn_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "attn_output: $(L,N,E)$ where $L$ is the target sequence length, $N$ is the batch size, $E$ is the embedding dimension.\n",
    "\n",
    "attn_output_weights: $(N,L,S)$ where $N$ is the batch size, $L$ is the target sequence length, $S$ is the source sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 3, 10]), torch.Size([3, 5, 5]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_att, att_weights = ma_term( batched_dt, batched_dir_dt, batched_dt,\n",
    "                                  key_padding_mask=bx_packed, \n",
    "                                  attn_mask=attn_mask )\n",
    "docs_att.shape, att_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 10])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_att, att_weights = ma_term( batched_dt, batched_dir_dt, batched_dt,\n",
    "                                  key_padding_mask=bx_packed, \n",
    "                                  attn_mask=attn_mask )\n",
    "docs_att.shape, att_weights.shape\n",
    "docs_att = docs_att.transpose(1,0)\n",
    "docs_att.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-727.,   52.,  166.,  421.,  472.,   61.,  200., -246.,  205.,  -34.],\n",
       "         [-483.,   95.,  128.,  131.,   38., -163.,  188., -161.,   56., -112.],\n",
       "         [-443.,  123.,  107.,   55.,   33., -131.,  176.,  -90.,   48., -158.],\n",
       "         [-518.,   25.,  181.,  303.,  143.,  -34.,   66., -195.,   54., -161.],\n",
       "         [-613.,   65.,  152.,  406.,  331.,   55.,  125., -247.,  147., -125.]],\n",
       "\n",
       "        [[-322.,  -74.,  224.,  120.,  -81.,  -94.,  -93.,  -36.,  -54., -138.],\n",
       "         [-412., -159.,  292.,  248.,   57.,   -8., -160.,  -47.,  -45., -122.],\n",
       "         [-641., -287.,  426.,  499.,  258.,   72., -213., -135.,  -60., -151.],\n",
       "         [-641., -287.,  426.,  499.,  258.,   72., -213., -135.,  -60., -151.],\n",
       "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.]],\n",
       "\n",
       "        [[-484., -131.,  244., -106.,  -81., -196.,  443.,  140.,  175., -265.],\n",
       "         [-789.,  296.,  -20.,  365.,  625.,   53.,  496., -326.,  394.,   50.],\n",
       "         [-272.,  406., -116., -260., -290., -427.,  494., -150.,   91., -110.],\n",
       "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.],\n",
       "         [   0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.]]],\n",
       "       grad_fn=<RoundBackward>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_att = torch.where(torch.isnan(docs_att), torch.zeros_like(docs_att), docs_att)\n",
    "(docs_att*1000).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5, 10]), torch.Size([3, 5, 1]), torch.Size([3, 5, 1]))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_weights = torch.where(torch.isnan(att_weights), torch.zeros_like(att_weights), att_weights)\n",
    "weigths_att = F.softmax(att_weights.sum(axis=1), dim=1)\n",
    "\n",
    "weigths_att  = weigths_att.view( *weigths_att.shape, 1 )\n",
    "weights_disc = weights_disc.view( *weights_disc.shape, 1 )\n",
    "\n",
    "docs_att.shape, weigths_att.shape, weights_disc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 1])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_weights = torch.where(torch.isnan(att_weights), torch.zeros_like(att_weights), att_weights)\n",
    "weigths_att = F.softmax(att_weights.sum(axis=1), dim=1)\n",
    "\n",
    "weigths_att  = weigths_att.view( *weigths_att.shape, 1 )\n",
    "weights_disc = weights_disc.view( *weights_disc.shape, 1 )\n",
    "weigths = weigths_att + weights_disc\n",
    "weigths.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-25.,   3.,   6.,  15.,  14.,   1.,   6.,  -9.,   6.,  -4.],\n",
       "        [-29., -12.,  19.,  22.,  10.,   2., -10.,  -6.,  -3.,  -7.],\n",
       "        [-37.,  11.,   2.,   9.,  18.,  -5.,  28., -10.,  17.,  -3.]],\n",
       "       grad_fn=<RoundBackward>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_weights = torch.where(torch.isnan(att_weights), torch.zeros_like(att_weights), att_weights)\n",
    "weigths_att = F.softmax(att_weights.sum(axis=1), dim=1)\n",
    "\n",
    "weigths_att  = weigths_att.view( *weigths_att.shape, 1 )\n",
    "weights_disc = weights_disc.view( *weights_disc.shape, 1 )\n",
    "weigths = weigths_att + weights_disc\n",
    "\n",
    "docs_h =  docs_att * weigths\n",
    "docs_h =  docs_h.sum(axis=1)\n",
    "docs_h /= bx_packed.logical_not().sum(dim=1).view(batch_size, 1)\n",
    "docs_h = torch.where(torch.isnan(docs_h), torch.zeros_like(docs_h), docs_h)\n",
    "(docs_h*100).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5],\n",
       "        [4],\n",
       "        [3]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bx_packed.logical_not().sum(dim=1).view(batch_size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.3931],\n",
       "          [0.0657],\n",
       "          [0.1015],\n",
       "          [0.0928],\n",
       "          [0.3469]],\n",
       " \n",
       "         [[0.0680],\n",
       "          [0.0607],\n",
       "          [0.0747],\n",
       "          [0.7513],\n",
       "          [0.0454]],\n",
       " \n",
       "         [[0.1625],\n",
       "          [0.5375],\n",
       "          [0.1332],\n",
       "          [0.0834],\n",
       "          [0.0834]]], grad_fn=<ViewBackward>),\n",
       " tensor([[[0.4569],\n",
       "          [0.0105],\n",
       "          [0.0670],\n",
       "          [0.0600],\n",
       "          [0.4055]],\n",
       " \n",
       "         [[0.1046],\n",
       "          [0.0953],\n",
       "          [0.1041],\n",
       "          [0.6797],\n",
       "          [0.0163]],\n",
       " \n",
       "         [[0.3092],\n",
       "          [0.4914],\n",
       "          [0.0980],\n",
       "          [0.0507],\n",
       "          [0.0507]]], grad_fn=<ViewBackward>))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weigths_att, weights_disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
